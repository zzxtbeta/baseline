sbgnn.py --lr 5e-3 --seed 2023 --dataset_name house1to10-3 --gnn_layer 2 --epoch 2000 --agg AttentionAggregator
#!/usr/bin/env python3
#-*- coding: utf-8 -*-
"""
@author: huangjunjie
@file: sbgnn.py
@time: 2021/03/28
"""


import os
import sys
import time
import random
import argparse
import subprocess

from collections import defaultdict

import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F


from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, roc_auc_score


from tqdm import tqdm

import logging
# https://docs.python.org/3/howto/logging.html#logging-advanced-tutorial


BASE_DIR = os.path.dirname(os.path.abspath(__file__))

parser = argparse.ArgumentParser()
parser.add_argument('--dirpath', default=BASE_DIR, help='Current Dir')
parser.add_argument('--device', type=str, default='cpu', help='Devices')
parser.add_argument('--dataset_name', type=str, default='house1to10-1')
parser.add_argument('--a_emb_size', type=int, default=32, help='Embeding A Size')
parser.add_argument('--b_emb_size', type=int, default=32, help='Embeding B Size')
parser.add_argument('--weight_decay', type=float, default=1e-5, help='Weight Decay')
parser.add_argument('--lr', type=float, default=0.005, help='Learning Rate')
parser.add_argument('--seed', type=int, default=2023, help='Random seed')
parser.add_argument('--epoch', type=int, default=2000, help='Epoch')
parser.add_argument('--gnn_layer_num', type=int, default=2, help='GNN Layer')
parser.add_argument('--batch_size', type=int, default=500, help='Batch Size')
parser.add_argument('--dropout', type=float, default=0.5, help='Dropout')
parser.add_argument('--agg', type=str, default='AttentionAggregator', choices=['AttentionAggregator', 'MeanAggregator'], help='Aggregator')
args = parser.parse_args()


# TODO

exclude_hyper_params = ['dirpath', 'device']
hyper_params = dict(vars(args))
for exclude_p in exclude_hyper_params:
    del hyper_params[exclude_p]

hyper_params = "~".join([f"{k}-{v}" for k,v in hyper_params.items()])

from torch.utils.tensorboard import SummaryWriter
# https://pytorch.org/docs/stable/tensorboard.html
tb_writer = SummaryWriter(comment=hyper_params)


def setup_seed(seed):
    os.environ['PYTHONHASHSEED'] = str(seed)  # 为了禁止hash随机化，使得实验可复现
    torch.manual_seed(seed)
    os.environ["CUBLAS_WORKSPACE_CONFIG"] = ":16:8"
    np.random.seed(seed)
    random.seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
# setup seed
setup_seed(args.seed)

from common import DATA_EMB_DIC

# args.device = 'cpu'
args.device = torch.device(args.device)

class MeanAggregator(nn.Module):
    def __init__(self, a_dim, b_dim):
        super(MeanAggregator, self).__init__()

        self.out_mlp_layer = nn.Sequential(
            nn.Linear(b_dim, b_dim)
        )

    def forward(self, edge_dic_list: dict, feature_a, feature_b, node_num_a, node_num_b):

        edges = []
        for node in range(node_num_a):
            neighs = np.array(edge_dic_list[node]).reshape(-1, 1)
            a = np.array([node]).repeat(len(neighs)).reshape(-1, 1)
            edges.append(np.concatenate([a, neighs], axis=1))

        edges = np.vstack(edges)
        edges = torch.LongTensor(edges).to(args.device)
        matrix = torch.sparse_coo_tensor(edges.t(), torch.ones(edges.shape[0]), torch.Size([node_num_a, node_num_b]), device=args.device)
        row_sum = torch.spmm(matrix, torch.ones(size=(node_num_b, 1)).to(args.device))
        row_sum = torch.where(row_sum == 0, torch.ones(row_sum.shape).to(args.device), row_sum)

        new_emb = feature_b
        new_emb = self.out_mlp_layer(new_emb)
        output_emb = torch.spmm(matrix, new_emb)
        output_emb = output_emb.div(row_sum)

        return output_emb


class AttentionAggregator(nn.Module):
    def __init__(self, a_dim, b_dim):
        super(AttentionAggregator, self).__init__()

        self.out_mlp_layer = nn.Sequential(
            nn.Linear(b_dim, b_dim),
        )

        self.a = nn.Parameter(torch.FloatTensor(a_dim + b_dim, 1))
        nn.init.kaiming_normal_(self.a.data)

    def forward(self, edge_dic_list: dict, feature_a, feature_b, node_num_a, node_num_b):

        edges = []
        for node in range(node_num_a):
            neighs = np.array(edge_dic_list[node]).reshape(-1, 1)
            a = np.array([node]).repeat(len(neighs)).reshape(-1, 1)
            edges.append(np.concatenate([a, neighs], axis=1))

        edges = np.vstack(edges)
        edges = torch.LongTensor(edges).to(args.device)

        new_emb = feature_b
        new_emb = self.out_mlp_layer(new_emb)

        edge_h_2 = torch.cat([feature_a[edges[:, 0]], new_emb[edges[:, 1]] ], dim=1)
        edges_h = torch.exp(F.elu(torch.einsum("ij,jl->il", [edge_h_2, self.a]), 0.1))

        matrix = torch.sparse_coo_tensor(edges.t(), edges_h[:, 0], torch.Size([node_num_a, node_num_b]), device=args.device)
        row_sum = torch.sparse.mm(matrix, torch.ones(size=(node_num_b, 1)).to(args.device))
        row_sum = torch.where(row_sum == 0, torch.ones(row_sum.shape).to(args.device), row_sum)

        output_emb = torch.sparse.mm(matrix, new_emb)
        output_emb = output_emb.div(row_sum)
        return output_emb



class SBGNNLayer(nn.Module):
    def __init__(self, edgelist_a_b_pos, edgelist_a_b_neg, edgelist_b_a_pos, edgelist_b_a_neg,\
                    edgelist_a_a_pos, edgelist_a_a_neg, edgelist_b_b_pos, edgelist_b_b_neg, \
        dataset_name=args.dataset_name, emb_size_a=32, emb_size_b=32, aggregator=MeanAggregator):
        super(SBGNNLayer, self).__init__()
        #
        self.set_a_num, self.set_b_num = DATA_EMB_DIC[dataset_name]

        # self.feature_a = feature_a
        # self.feature_b = feature_b
        self.edgelist_a_b_pos, self.edgelist_a_b_neg, self.edgelist_b_a_pos, self.edgelist_b_a_neg = \
            edgelist_a_b_pos, edgelist_a_b_neg, edgelist_b_a_pos, edgelist_b_a_neg
        self.edgelist_a_a_pos, self.edgelist_a_a_neg, self.edgelist_b_b_pos, self.edgelist_b_b_neg = \
            edgelist_a_a_pos, edgelist_a_a_neg, edgelist_b_b_pos, edgelist_b_b_neg

        self.agg_a_from_b_pos = aggregator(emb_size_b, emb_size_a)
        self.agg_a_from_b_neg = aggregator(emb_size_b, emb_size_a)
        self.agg_a_from_a_pos = aggregator(emb_size_a, emb_size_a)
        self.agg_a_from_a_neg = aggregator(emb_size_a, emb_size_a)

        self.agg_b_from_a_pos = aggregator(emb_size_a, emb_size_b)
        self.agg_b_from_a_neg = aggregator(emb_size_a, emb_size_b)
        self.agg_b_from_b_pos = aggregator(emb_size_b, emb_size_b)
        self.agg_b_from_b_neg = aggregator(emb_size_b, emb_size_b)

        self.update_func = nn.Sequential(
            nn.Dropout(args.dropout),
            nn.Linear(emb_size_a * 5, emb_size_a * 2),
            nn.PReLU(),
            nn.Linear(emb_size_b * 2, emb_size_b)

        )



    def forward(self, feature_a, feature_b):
        # assert feature_a.size()[0] == self.set_a_num, 'set_b_num error'
        # assert feature_b.size()[0] == self.set_b_num, 'set_b_num error'

        node_num_a, node_num_b = self.set_a_num, self.set_b_num

        m_a_from_b_pos = self.agg_a_from_b_pos(self.edgelist_a_b_pos, feature_a, feature_b, node_num_a, node_num_b)
        m_a_from_b_neg = self.agg_a_from_b_neg(self.edgelist_a_b_neg, feature_a, feature_b, node_num_a, node_num_b)
        m_a_from_a_pos = self.agg_a_from_a_pos(self.edgelist_a_a_pos, feature_a, feature_a, node_num_a, node_num_a)
        m_a_from_a_neg = self.agg_a_from_a_neg(self.edgelist_a_a_neg, feature_a, feature_a, node_num_a, node_num_a)

        new_feature_a = torch.cat([feature_a, m_a_from_b_pos, m_a_from_b_neg, m_a_from_a_pos, m_a_from_a_neg], dim=1)
        new_feature_a = self.update_func(new_feature_a)

        m_b_from_a_pos = self.agg_b_from_a_pos(self.edgelist_b_a_pos, feature_b, feature_a, node_num_b, node_num_a)
        m_b_from_a_neg = self.agg_b_from_a_neg(self.edgelist_b_a_neg, feature_b, feature_a, node_num_b, node_num_a)
        m_b_from_b_pos = self.agg_b_from_b_pos(self.edgelist_b_b_pos, feature_b, feature_b, node_num_b, node_num_b)
        m_b_from_b_neg = self.agg_b_from_b_neg(self.edgelist_b_b_neg, feature_b, feature_b, node_num_b, node_num_b)

        new_feature_b = torch.cat([feature_b, m_b_from_a_pos, m_b_from_a_neg, m_b_from_b_pos, m_b_from_b_neg], dim=1)
        new_feature_b = self.update_func(new_feature_b)

        return new_feature_a, new_feature_b



class SBGNN(nn.Module):
    def __init__(self, edgelists,
                    dataset_name=args.dataset_name, layer_num=1, emb_size_a=32, emb_size_b=32, aggregator=AttentionAggregator):
        super(SBGNN, self).__init__()

        # assert edgelists must compelte
        assert len(edgelists) == 8, 'must 8 edgelists'
        edgelist_a_b_pos, edgelist_a_b_neg, edgelist_b_a_pos, edgelist_b_a_neg,\
                    edgelist_a_a_pos, edgelist_a_a_neg, edgelist_b_b_pos, edgelist_b_b_neg = edgelists

        self.set_a_num, self.set_b_num = DATA_EMB_DIC[dataset_name]

        self.features_a = nn.Embedding(self.set_a_num, emb_size_a)
        self.features_b = nn.Embedding(self.set_b_num, emb_size_b)
        self.features_a.weight.requires_grad = True
        self.features_b.weight.requires_grad = True
        # features_a = features_a.to(args.device)
        # features_b = features_b.to(args.device)

        self.layers = nn.ModuleList(
            [SBGNNLayer(edgelist_a_b_pos, edgelist_a_b_neg, edgelist_b_a_pos, edgelist_b_a_neg,\
                    edgelist_a_a_pos, edgelist_a_a_neg, edgelist_b_b_pos, edgelist_b_b_neg, \
                    dataset_name=dataset_name, emb_size_a=32, emb_size_b=32, aggregator=aggregator) for _ in range(layer_num)]
        )
        # self.mlp = nn.Sequential(
        #     nn.Linear(emb_size_a * 3, 30),
        #     nn.PReLU(),
        #     nn.Linear(30, 1),
        #     nn.Sigmoid()
        # )
        # def init_weights(m):
        #     if type(m) == nn.Linear:
        #         torch.nn.init.xavier_uniform_(m.weight)
        #         m.bias.data.fill_(0.01)
        # self.apply(init_weights)


    def get_embeddings(self):
        emb_a = self.features_a(torch.arange(self.set_a_num).to(args.device))
        emb_b = self.features_b(torch.arange(self.set_b_num).to(args.device))
        for m in self.layers:
            emb_a, emb_b = m(emb_a, emb_b)
        return emb_a, emb_b

    def forward(self, edge_lists):
        embedding_a, embedding_b = self.get_embeddings()

        #### with mlp
        # emb_concat = torch.cat([embedding_a[edge_lists[:, 0]], embedding_b[edge_lists[:, 1]], embedding_a[edge_lists[:, 0]] * embedding_b[edge_lists[:, 1]] ], dim=1)
        # y = self.mlp(emb_concat).squeeze(-1)
        # return y

        ## without mlp
        y = torch.einsum("ij, ij->i", [embedding_a[edge_lists[:, 0]] , embedding_b[edge_lists[:, 1]] ])
        return torch.sigmoid(y)

    def loss(self, pred_y, y):
        assert y.min() >= 0, 'must 0~1'
        assert pred_y.size() == y.size(), 'must be same length'
        pos_ratio = y.sum() /  y.size()[0]
        weight = torch.where(y > 0.5, 1./pos_ratio, 1./(1-pos_ratio))
        # weight = torch.where(y > 0.5, (1-pos_ratio), pos_ratio)
        return F.binary_cross_entropy(pred_y, y, weight=weight)


# =========== function
def load_data(dataset_name):
    train_file_path = os.path.join('datasets', f'{dataset_name}_training.txt')
    val_file_path = os.path.join('datasets', f'{dataset_name}_val.txt')
    test_file_path = os.path.join('datasets', f'{dataset_name}_test.txt')

    train_edgelist = []
    with open(train_file_path) as f:
        for ind, line in enumerate(f):
            if ind == 0: continue
            a, b, s = map(int, line.split('\t'))
            train_edgelist.append((a, b, s))

    val_edgelist = []
    with open(val_file_path) as f:
        for ind, line in enumerate(f):
            if ind == 0: continue
            a, b, s = map(int, line.split('\t'))
            val_edgelist.append((a, b, s))

    test_edgelist = []
    with open(test_file_path) as f:
        for ind, line in enumerate(f):
            if ind == 0: continue
            a, b, s = map(int, line.split('\t'))
            test_edgelist.append((a, b, s))

    return np.array(train_edgelist), np.array(val_edgelist), np.array(test_edgelist)


# ============= load data
def load_edgelists(edge_lists):
    edgelist_a_b_pos, edgelist_a_b_neg = defaultdict(list), defaultdict(list)
    edgelist_b_a_pos, edgelist_b_a_neg = defaultdict(list), defaultdict(list)
    edgelist_a_a_pos, edgelist_a_a_neg = defaultdict(list), defaultdict(list)
    edgelist_b_b_pos, edgelist_b_b_neg = defaultdict(list), defaultdict(list)

    for a, b, s in edge_lists:
        if s == 1:
            edgelist_a_b_pos[a].append(b)
            edgelist_b_a_pos[b].append(a)
        elif s== -1:
            edgelist_a_b_neg[a].append(b)
            edgelist_b_a_neg[b].append(a)
        else:
            print(a, b, s)
            raise Exception("s must be -1/1")

    edge_list_a_a = defaultdict(lambda: defaultdict(int))
    edge_list_b_b = defaultdict(lambda: defaultdict(int))
    for a, b, s in edge_lists:
        for b2 in edgelist_a_b_pos[a]:
            edge_list_b_b[b][b2] += 1 * s
        for b2 in edgelist_a_b_neg[a]:
            edge_list_b_b[b][b2] -= 1 * s
        for a2 in edgelist_b_a_pos[b]:
            edge_list_a_a[a][a2] += 1 * s
        for a2 in edgelist_b_a_neg[b]:
            edge_list_a_a[a][a2] -= 1 * s

    for a1 in edge_list_a_a:
        for a2 in edge_list_a_a[a1]:
            v = edge_list_a_a[a1][a2]
            if a1 == a2: continue
            if v > 0:
                edgelist_a_a_pos[a1].append(a2)
            elif v < 0:
                edgelist_a_a_neg[a1].append(a2)

    for b1 in edge_list_b_b:
        for b2 in edge_list_b_b[b1]:
            v = edge_list_b_b[b1][b2]
            if b1 == b2: continue
            if v > 0:
                edgelist_b_b_pos[b1].append(b2)
            elif v < 0:
                edgelist_b_b_neg[b1].append(b2)

    return edgelist_a_b_pos, edgelist_a_b_neg, edgelist_b_a_pos, edgelist_b_a_neg,\
                    edgelist_a_a_pos, edgelist_a_a_neg, edgelist_b_b_pos, edgelist_b_b_neg


@torch.no_grad()
def test_and_val(pred_y, y, mode='val', epoch=0):
    preds = pred_y.cpu().numpy()
    y = y.cpu().numpy()

    preds[preds >= 0.5]  = 1
    preds[preds < 0.5] = 0
    test_y = y

    auc = roc_auc_score(test_y, preds)
    f1 = f1_score(test_y, preds)
    macro_f1 = f1_score(test_y, preds, average='macro')
    micro_f1 = f1_score(test_y, preds, average='micro')
    pos_ratio = np.sum(test_y) /  len(test_y)
    res = {
        f'{mode}_auc': auc,
        f'{mode}_f1' : f1,
        f'{mode}_pos_ratio': pos_ratio,
        f'{mode}_epoch': epoch,
        f'{mode}_macro_f1' : macro_f1,
        f'{mode}_micro_f1' : micro_f1,
    }
    for k, v in res.items():
        mode ,_, metric = k.partition('_')
        tb_writer.add_scalar(f'{metric}/{mode}', v, epoch)
    # tb_writer.add_scalar( f'{mode}_auc', auc, epoch)
    # tb_writer.add_scalar( f'{mode}_f1', auc, epoch)
    return res



def run():
    train_edgelist, val_edgelist, test_edgelist  = load_data(args.dataset_name)

    set_a_num, set_b_num = DATA_EMB_DIC[args.dataset_name]
    train_y = np.array([i[-1] for i in train_edgelist])
    val_y   = np.array([i[-1] for i in val_edgelist])
    test_y  = np.array([i[-1] for i in test_edgelist])

    train_y = torch.from_numpy( (train_y + 1)/2 ).float().to(args.device)
    val_y = torch.from_numpy( (val_y + 1)/2 ).float().to(args.device)
    test_y = torch.from_numpy( (test_y + 1)/2 ).float().to(args.device)
    # get edge lists
    edgelists = load_edgelists(train_edgelist)

    if args.agg == 'MeanAggregator':
        agg = MeanAggregator
    else:
        agg = AttentionAggregator

    model = SBGNN(edgelists, dataset_name=args.dataset_name, layer_num=args.gnn_layer_num, aggregator=agg)
    model = model.to(args.device)

    print(model.train())
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)

    res_best = {'val_auc': 0}
    for epoch in tqdm(range(1, args.epoch + 2)):
        # train
        model.train()
        optimizer.zero_grad()
        pred_y = model(train_edgelist)
        loss = model.loss(pred_y, train_y)
        loss.backward()
        optimizer.step()
        print('loss', loss)


        res_cur = {}
        # if epoch % 5 == 0:
        if True:
        # val/test
            model.eval()
            pred_y = model(train_edgelist)
            res = test_and_val(pred_y, train_y, mode='train', epoch=epoch)
            res_cur.update(res)
            pred_val_y = model(val_edgelist)
            res = test_and_val(pred_val_y, val_y, mode='val', epoch=epoch)
            res_cur.update(res)
            pred_test_y = model(test_edgelist)
            res = test_and_val(pred_test_y, test_y, mode='test', epoch=epoch)
            res_cur.update(res)
            if res_cur['val_auc'] > res_best['val_auc']:
                res_best = res_cur
                print(res_best)
    print('Done! Best Results:')
    print(res_best)
    print_list = ['test_auc', 'test_f1', 'test_macro_f1', 'test_micro_f1']
    for i in print_list:
        print(i, res_best[i], end=' ')



def main():
    print(" ".join(sys.argv))
    this_fpath = os.path.abspath(__file__)
    t = subprocess.run(f'cat {this_fpath}', shell=True, stdout=subprocess.PIPE)
    print(str(t.stdout, 'utf-8'))
    print('=' * 20)
    run()

if __name__ == "__main__":
    main()

====================
SBGNN(
  (features_a): Embedding(515, 32)
  (features_b): Embedding(1281, 32)
  (layers): ModuleList(
    (0-1): 2 x SBGNNLayer(
      (agg_a_from_b_pos): AttentionAggregator(
        (out_mlp_layer): Sequential(
          (0): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (agg_a_from_b_neg): AttentionAggregator(
        (out_mlp_layer): Sequential(
          (0): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (agg_a_from_a_pos): AttentionAggregator(
        (out_mlp_layer): Sequential(
          (0): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (agg_a_from_a_neg): AttentionAggregator(
        (out_mlp_layer): Sequential(
          (0): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (agg_b_from_a_pos): AttentionAggregator(
        (out_mlp_layer): Sequential(
          (0): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (agg_b_from_a_neg): AttentionAggregator(
        (out_mlp_layer): Sequential(
          (0): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (agg_b_from_b_pos): AttentionAggregator(
        (out_mlp_layer): Sequential(
          (0): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (agg_b_from_b_neg): AttentionAggregator(
        (out_mlp_layer): Sequential(
          (0): Linear(in_features=32, out_features=32, bias=True)
        )
      )
      (update_func): Sequential(
        (0): Dropout(p=0.5, inplace=False)
        (1): Linear(in_features=160, out_features=64, bias=True)
        (2): PReLU(num_parameters=1)
        (3): Linear(in_features=64, out_features=32, bias=True)
      )
    )
  )
)
  0%|          | 0/2001 [00:00<?, ?it/s]  0%|          | 1/2001 [00:06<3:34:45,  6.44s/it]  0%|          | 2/2001 [00:12<3:32:39,  6.38s/it]  0%|          | 3/2001 [00:18<3:28:56,  6.27s/it]  0%|          | 4/2001 [00:25<3:27:22,  6.23s/it]  0%|          | 5/2001 [00:31<3:25:48,  6.19s/it]  0%|          | 6/2001 [00:37<3:26:50,  6.22s/it]  0%|          | 7/2001 [00:43<3:29:49,  6.31s/it]  0%|          | 8/2001 [00:50<3:35:11,  6.48s/it]  0%|          | 9/2001 [00:56<3:30:07,  6.33s/it]  0%|          | 10/2001 [01:02<3:28:03,  6.27s/it]  1%|          | 11/2001 [01:08<3:24:08,  6.16s/it]  1%|          | 12/2001 [01:14<3:21:38,  6.08s/it]  1%|          | 13/2001 [01:20<3:19:44,  6.03s/it]  1%|          | 14/2001 [01:26<3:19:36,  6.03s/it]  1%|          | 15/2001 [01:32<3:19:34,  6.03s/it]  1%|          | 16/2001 [01:38<3:19:13,  6.02s/it]  1%|          | 17/2001 [01:44<3:18:11,  5.99s/it]  1%|          | 18/2001 [01:50<3:16:57,  5.96s/it]  1%|          | 19/2001 [01:56<3:17:08,  5.97s/it]  1%|          | 20/2001 [02:02<3:18:32,  6.01s/it]  1%|          | 21/2001 [02:08<3:18:47,  6.02s/it]  1%|          | 22/2001 [02:14<3:18:29,  6.02s/it]loss tensor(1.4009, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.5, 'train_f1': 0.7010835437626091, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 1, 'train_macro_f1': 0.35054177188130453, 'train_micro_f1': 0.5397449084550504, 'val_auc': 0.5, 'val_f1': 0.7105903161618395, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 1, 'val_macro_f1': 0.35529515808091977, 'val_micro_f1': 0.5510973936899863, 'test_auc': 0.5, 'test_f1': 0.694980694980695, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 1, 'test_macro_f1': 0.3474903474903475, 'test_micro_f1': 0.5325443786982249}
loss tensor(1.3866, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(1.3887, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(1.3863, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.5009630521530087, 'train_f1': 0.701290710894135, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 4, 'train_macro_f1': 0.3533618996465776, 'train_micro_f1': 0.5405677844065008, 'val_auc': 0.5006437886576252, 'val_f1': 0.7106980860714681, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 4, 'val_macro_f1': 0.35725380494049597, 'val_micro_f1': 0.5516117969821673, 'test_auc': 0.5012626739719126, 'test_f1': 0.6953963309103496, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 4, 'test_macro_f1': 0.35071021364794586, 'test_micro_f1': 0.5336924843239425}
loss tensor(1.3823, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.5952517773492969, 'train_f1': 0.717122649435559, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 5, 'train_macro_f1': 0.567003557926206, 'train_micro_f1': 0.6190495782760749, 'val_auc': 0.5954021819170616, 'val_f1': 0.7265193370165746, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 5, 'val_macro_f1': 0.568935344183963, 'val_micro_f1': 0.6265432098765432, 'test_auc': 0.5900151143019081, 'test_f1': 0.7101220953131154, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 5, 'test_macro_f1': 0.5571657427456025, 'test_micro_f1': 0.6099973505254791}
loss tensor(1.3730, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.6899478442605016, 'train_f1': 0.7058972733037414, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 6, 'train_macro_f1': 0.6889904052927583, 'train_micro_f1': 0.6899094836453404, 'val_auc': 0.681011574172012, 'val_f1': 0.7026075827867542, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 6, 'val_macro_f1': 0.679587552708729, 'val_micro_f1': 0.681241426611797, 'test_auc': 0.6837930600163739, 'test_f1': 0.6984153742414025, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 6, 'test_macro_f1': 0.6832829978237248, 'test_micro_f1': 0.6840060054755807}
loss tensor(1.3291, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(1.2625, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.7053356110058262, 'train_f1': 0.6366108383867553, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 8, 'train_macro_f1': 0.6826611967156542, 'train_micro_f1': 0.6893437564287184, 'val_auc': 0.7056420463756018, 'val_f1': 0.6353547364248909, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 8, 'val_macro_f1': 0.6786625601133218, 'val_micro_f1': 0.6844993141289437, 'test_auc': 0.7026082666834604, 'test_f1': 0.633500208594076, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 8, 'test_macro_f1': 0.6821965738942197, 'test_micro_f1': 0.6896582177868056}
loss tensor(1.2379, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.726824468131837, 'train_f1': 0.7532057605050306, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 9, 'train_macro_f1': 0.7273205672886895, 'train_micro_f1': 0.7297778234931084, 'val_auc': 0.7277052077831755, 'val_f1': 0.7588969342166076, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 9, 'val_macro_f1': 0.7281822772764848, 'val_micro_f1': 0.7316529492455418, 'test_auc': 0.7294991288284316, 'test_f1': 0.7530311660834892, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 9, 'test_macro_f1': 0.7299963207070916, 'test_micro_f1': 0.7319614943036298}
loss tensor(1.0702, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.7571763890498602, 'train_f1': 0.7840619832407424, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 10, 'train_macro_f1': 0.7581338972172744, 'train_micro_f1': 0.7609133923061099, 'val_auc': 0.7573444436891121, 'val_f1': 0.7885348376276873, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 10, 'val_macro_f1': 0.7584202101948427, 'val_micro_f1': 0.7621742112482853, 'test_auc': 0.762638285366417, 'test_f1': 0.7860022577003709, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 10, 'test_macro_f1': 0.7634618863667806, 'test_micro_f1': 0.7656098207188907}
loss tensor(1.1128, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.7581209096993445, 'train_f1': 0.7902092798365172, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 11, 'train_macro_f1': 0.7595565768243959, 'train_micro_f1': 0.7634643077556058, 'val_auc': 0.758883617937756, 'val_f1': 0.7945328927605887, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 11, 'val_macro_f1': 0.7606304096244014, 'val_micro_f1': 0.7654320987654321, 'test_auc': 0.7605590192497428, 'test_f1': 0.7900552486187845, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 11, 'test_macro_f1': 0.7617076563863769, 'test_micro_f1': 0.7650799258147134}
loss tensor(1.0155, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.753985018998309, 'train_f1': 0.7884862875890446, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 12, 'train_macro_f1': 0.7554949570688796, 'train_micro_f1': 0.7599465130631557, 'val_auc': 0.7595615153907918, 'val_f1': 0.7969543147208122, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 12, 'val_macro_f1': 0.7615460256648765, 'val_micro_f1': 0.766803840877915, 'test_auc': 0.7577429309150452, 'test_f1': 0.7891391352114887, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 12, 'test_macro_f1': 0.7589036077955857, 'test_micro_f1': 0.7626953987459154}
loss tensor(1.0614, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.7640568225949134, 'train_f1': 0.785576060791995, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 13, 'train_macro_f1': 0.7644619471238661, 'train_micro_f1': 0.7663546595350751, 'val_auc': 0.7664220182613974, 'val_f1': 0.790292470441817, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 13, 'val_macro_f1': 0.7664220182613974, 'val_micro_f1': 0.7688614540466392, 'test_auc': 0.7654722169742006, 'test_f1': 0.7840694911087439, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 13, 'test_macro_f1': 0.7658736807262574, 'test_micro_f1': 0.7672878212487856}
loss tensor(1.0409, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.7655320187762529, 'train_f1': 0.7846979150814184, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 14, 'train_macro_f1': 0.765613313000711, 'train_micro_f1': 0.7671672495371322, 'val_auc': 0.7671164353052417, 'val_f1': 0.7885248471547265, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 14, 'val_macro_f1': 0.7666370687996906, 'val_micro_f1': 0.7686899862825788, 'test_auc': 0.769204609862082, 'test_f1': 0.7867882671925067, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 14, 'test_macro_f1': 0.769527785147566, 'test_micro_f1': 0.7708204539433012}
loss tensor(1.0724, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(1.0472, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(1.0141, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.7718734710029609, 'train_f1': 0.785149589210975, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 17, 'train_macro_f1': 0.7710278332795206, 'train_micro_f1': 0.7718987862579716, 'val_auc': 0.7744460232472239, 'val_f1': 0.7907124681933843, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 17, 'val_macro_f1': 0.7729604007633588, 'val_micro_f1': 0.7743484224965707, 'test_auc': 0.7752524298339526, 'test_f1': 0.7874173847569647, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 17, 'test_macro_f1': 0.7748926444966906, 'test_micro_f1': 0.7755895080808973}
loss tensor(0.9812, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.9800, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.9766, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.9562, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.9616, grad_fn=<BinaryCrossEntropyBackward0>)
loss   1%|          | 23/2001 [02:20<3:18:06,  6.01s/it]  1%|          | 24/2001 [02:26<3:16:41,  5.97s/it]  1%|          | 25/2001 [02:32<3:16:58,  5.98s/it]  1%|▏         | 26/2001 [02:38<3:17:12,  5.99s/it]  1%|▏         | 27/2001 [02:44<3:16:54,  5.99s/it]  1%|▏         | 28/2001 [02:50<3:17:45,  6.01s/it]  1%|▏         | 29/2001 [02:56<3:18:14,  6.03s/it]  1%|▏         | 30/2001 [03:02<3:18:36,  6.05s/it]  2%|▏         | 31/2001 [03:08<3:17:59,  6.03s/it]  2%|▏         | 32/2001 [03:14<3:18:28,  6.05s/it]  2%|▏         | 33/2001 [03:21<3:19:28,  6.08s/it]  2%|▏         | 34/2001 [03:27<3:18:17,  6.05s/it]  2%|▏         | 35/2001 [03:32<3:17:27,  6.03s/it]  2%|▏         | 36/2001 [03:38<3:16:27,  6.00s/it]  2%|▏         | 37/2001 [03:44<3:16:22,  6.00s/it]  2%|▏         | 38/2001 [03:50<3:16:24,  6.00s/it]  2%|▏         | 39/2001 [03:56<3:16:29,  6.01s/it]  2%|▏         | 40/2001 [04:02<3:16:28,  6.01s/it]  2%|▏         | 41/2001 [04:08<3:15:56,  6.00s/it]  2%|▏         | 42/2001 [04:14<3:15:38,  5.99s/it]  2%|▏         | 43/2001 [04:20<3:15:18,  5.98s/it]  2%|▏         | 44/2001 [04:26<3:15:14,  5.99s/it]  2%|▏         | 45/2001 [04:32<3:15:19,  5.99s/it]  2%|▏         | 46/2001 [04:38<3:15:48,  6.01s/it]  2%|▏         | 47/2001 [04:45<3:16:21,  6.03s/it]  2%|▏         | 48/2001 [04:50<3:15:24,  6.00s/it]  2%|▏         | 49/2001 [04:56<3:14:38,  5.98s/it]  2%|▏         | 50/2001 [05:02<3:14:33,  5.98s/it]  3%|▎         | 51/2001 [05:08<3:13:33,  5.96s/it]  3%|▎         | 52/2001 [05:14<3:14:26,  5.99s/it]  3%|▎         | 53/2001 [05:20<3:15:38,  6.03s/it]  3%|▎         | 54/2001 [05:27<3:16:02,  6.04s/it]  3%|▎         | 55/2001 [05:33<3:17:11,  6.08s/it]  3%|▎         | 56/2001 [05:39<3:17:13,  6.08s/it]  3%|▎         | 57/2001 [05:45<3:16:35,  6.07s/it]  3%|▎         | 58/2001 [05:51<3:16:05,  6.06s/it]  3%|▎         | 59/2001 [05:57<3:16:10,  6.06s/it]  3%|▎         | 60/2001 [06:03<3:17:26,  6.10s/it]  3%|▎         | 61/2001 [06:09<3:17:45,  6.12s/it]  3%|▎         | 62/2001 [06:15<3:18:46,  6.15s/it]tensor(0.9369, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.7777020458117201, 'train_f1': 0.7914448834490954, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 23, 'train_macro_f1': 0.7770011060888999, 'train_micro_f1': 0.7779366385517383, 'val_auc': 0.779827725625522, 'val_f1': 0.7965752338671317, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 23, 'val_macro_f1': 0.7785377569372993, 'val_micro_f1': 0.7800068587105624, 'test_auc': 0.7773789281440897, 'test_f1': 0.7890768973027308, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 23, 'test_macro_f1': 0.7769628042733302, 'test_micro_f1': 0.7776207718802436}
loss tensor(0.9346, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.7872441662096921, 'train_f1': 0.8027771127603543, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 24, 'train_macro_f1': 0.7869909559802438, 'train_micro_f1': 0.7881608722485085, 'val_auc': 0.7876416109239419, 'val_f1': 0.8059795436664043, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 24, 'val_macro_f1': 0.7868662080735487, 'val_micro_f1': 0.7885802469135802, 'test_auc': 0.786511535151248, 'test_f1': 0.8000996181304999, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 24, 'test_macro_f1': 0.7864649034048726, 'test_micro_f1': 0.7873355117901616}
loss tensor(0.9256, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.795969637676619, 'train_f1': 0.8113037991625398, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 25, 'train_macro_f1': 0.79579860810105, 'train_micro_f1': 0.7969759308784201, 'val_auc': 0.79824314745981, 'val_f1': 0.8159673110168161, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 25, 'val_macro_f1': 0.7975327971797908, 'val_micro_f1': 0.7992112482853223, 'test_auc': 0.7950689590024561, 'test_f1': 0.8092561983471074, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 25, 'test_macro_f1': 0.7952027246239615, 'test_micro_f1': 0.7961670935264505}
loss tensor(0.9188, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8929, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.9026, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8956, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8769, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.7999903138055948, 'train_f1': 0.8102763721292332, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 30, 'train_macro_f1': 0.7988118335340755, 'train_micro_f1': 0.7994651306315573, 'val_auc': 0.7988048135473005, 'val_f1': 0.811450503758196, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 30, 'val_macro_f1': 0.7967805096872665, 'val_micro_f1': 0.7978395061728396, 'test_auc': 0.7979700652853875, 'test_f1': 0.807141654034024, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 30, 'test_macro_f1': 0.7972767312130759, 'test_micro_f1': 0.7977567782389826}
loss tensor(0.8781, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8765, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8648, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8719, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8641, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8613, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8595, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8509, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8525, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8054266946744385, 'train_f1': 0.8171157322814855, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 39, 'train_macro_f1': 0.8046217321671374, 'train_micro_f1': 0.805420695330179, 'val_auc': 0.8008904415983739, 'val_f1': 0.8147086914995225, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 39, 'val_macro_f1': 0.7992161071767401, 'val_micro_f1': 0.8004115226337448, 'test_auc': 0.8022839389550138, 'test_f1': 0.8126622560924546, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 39, 'test_macro_f1': 0.801847242011664, 'test_micro_f1': 0.8024375165592158}
loss tensor(0.8459, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8456, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8492, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8351, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.807263262840599, 'train_f1': 0.8189443574727971, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 43, 'train_macro_f1': 0.8064795887498113, 'train_micro_f1': 0.8072824521703353, 'val_auc': 0.8012648064260495, 'val_f1': 0.815873015873016, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 43, 'val_macro_f1': 0.7998082454458294, 'val_micro_f1': 0.8010973936899864, 'test_auc': 0.8027310703864643, 'test_f1': 0.8127463312368973, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 43, 'test_macro_f1': 0.8022317608987397, 'test_micro_f1': 0.8027907798286674}
loss tensor(0.8279, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8374, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8338, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8298, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8091269749405163, 'train_f1': 0.8191318718708988, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 47, 'train_macro_f1': 0.8079825343520478, 'train_micro_f1': 0.8086299115408351, 'val_auc': 0.8029836757919776, 'val_f1': 0.8170402161818471, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 47, 'val_macro_f1': 0.8014104859059245, 'val_micro_f1': 0.8026406035665294, 'test_auc': 0.8032821126435334, 'test_f1': 0.812547304684215, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 47, 'test_macro_f1': 0.8026474319794854, 'test_micro_f1': 0.8031440430981188}
loss tensor(0.8384, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.810772747240423, 'train_f1': 0.8243288574522939, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 48, 'train_macro_f1': 0.8104530539661501, 'train_micro_f1': 0.8114688335733387, 'val_auc': 0.8048415949510426, 'val_f1': 0.8223477715003139, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 48, 'val_macro_f1': 0.8042199930819786, 'val_micro_f1': 0.8058984910836763, 'test_auc': 0.8053834204504902, 'test_f1': 0.8175170350673093, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 48, 'test_macro_f1': 0.805290745200447, 'test_micro_f1': 0.8060584650710942}
loss tensor(0.8255, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8223, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8199, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8043, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8195, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8058, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8126, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8067, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.814348283128345, 'train_f1': 0.8260068489847103, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 56, 'train_macro_f1': 0.8136533831814216, 'train_micro_f1': 0.8144723307961325, 'val_auc': 0.8053589314890972, 'val_f1': 0.8210958471498501, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 56, 'val_macro_f1': 0.8042826825319688, 'val_micro_f1': 0.8057270233196158, 'test_auc': 0.807994835946848, 'test_f1': 0.8179304566401341, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 56, 'test_macro_f1': 0.8075274540692968, 'test_micro_f1': 0.8080897288704407}
loss tensor(0.8052, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8133738153102217, 'train_f1': 0.8208980104137046, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 57, 'train_macro_f1': 0.8116754947860171, 'train_micro_f1': 0.8121271343344991, 'val_auc': 0.8078797735080908, 'val_f1': 0.8183279742765274, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 57, 'val_macro_f1': 0.8053800047723563, 'val_micro_f1': 0.806241426611797, 'test_auc': 0.8068707097424271, 'test_f1': 0.8131961567893886, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 57, 'test_macro_f1': 0.8056793829422368, 'test_micro_f1': 0.8059701492537313}
loss tensor(0.8060, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8047, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8003, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.8074, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7953, grad_fn=<BinaryCrossEntropyBackward0>)
loss   3%|▎         | 63/2001 [06:22<3:19:06,  6.16s/it]  3%|▎         | 64/2001 [06:28<3:18:55,  6.16s/it]  3%|▎         | 65/2001 [06:34<3:16:51,  6.10s/it]  3%|▎         | 66/2001 [06:40<3:15:17,  6.06s/it]  3%|▎         | 67/2001 [06:46<3:13:58,  6.02s/it]  3%|▎         | 68/2001 [06:52<3:15:35,  6.07s/it]  3%|▎         | 69/2001 [06:58<3:14:48,  6.05s/it]  3%|▎         | 70/2001 [07:04<3:14:26,  6.04s/it]  4%|▎         | 71/2001 [07:10<3:14:36,  6.05s/it]  4%|▎         | 72/2001 [07:16<3:13:46,  6.03s/it]  4%|▎         | 73/2001 [07:22<3:14:01,  6.04s/it]  4%|▎         | 74/2001 [07:28<3:12:28,  5.99s/it]  4%|▎         | 75/2001 [07:34<3:12:26,  5.99s/it]  4%|▍         | 76/2001 [07:40<3:13:21,  6.03s/it]  4%|▍         | 77/2001 [07:46<3:13:43,  6.04s/it]  4%|▍         | 78/2001 [07:52<3:13:08,  6.03s/it]  4%|▍         | 79/2001 [07:58<3:12:35,  6.01s/it]  4%|▍         | 80/2001 [08:04<3:11:56,  5.99s/it]  4%|▍         | 81/2001 [08:10<3:11:24,  5.98s/it]  4%|▍         | 82/2001 [08:16<3:10:55,  5.97s/it]  4%|▍         | 83/2001 [08:22<3:12:23,  6.02s/it]  4%|▍         | 84/2001 [08:28<3:12:39,  6.03s/it]  4%|▍         | 85/2001 [08:34<3:12:11,  6.02s/it]  4%|▍         | 86/2001 [08:40<3:12:08,  6.02s/it]  4%|▍         | 87/2001 [08:46<3:12:00,  6.02s/it]  4%|▍         | 88/2001 [08:52<3:11:36,  6.01s/it]  4%|▍         | 89/2001 [08:58<3:11:05,  6.00s/it]  4%|▍         | 90/2001 [09:04<3:10:15,  5.97s/it]  5%|▍         | 91/2001 [09:10<3:09:53,  5.97s/it]  5%|▍         | 92/2001 [09:16<3:09:32,  5.96s/it]  5%|▍         | 93/2001 [09:22<3:09:33,  5.96s/it]  5%|▍         | 94/2001 [09:28<3:10:09,  5.98s/it]  5%|▍         | 95/2001 [09:34<3:09:36,  5.97s/it]  5%|▍         | 96/2001 [09:40<3:09:11,  5.96s/it]  5%|▍         | 97/2001 [09:46<3:08:40,  5.95s/it]  5%|▍         | 98/2001 [09:52<3:08:58,  5.96s/it]  5%|▍         | 99/2001 [09:58<3:09:00,  5.96s/it]  5%|▍         | 100/2001 [10:04<3:09:02,  5.97s/it]  5%|▌         | 101/2001 [10:10<3:09:04,  5.97s/it]  5%|▌         | 102/2001 [10:16<3:08:43,  5.96s/it]  5%|▌         | 103/2001 [10:21<3:08:34,  5.96s/it]  5%|▌         | 104/2001 [10:27<3:08:28,  5.96s/it]  5%|▌         | 105/2001 [10:33<3:08:15,  5.96s/it]  5%|▌         | 106/2001 [10:39<3:08:07,  5.96s/it]  5%|▌         | 107/2001 [10:45<3:08:10,  5.96s/it]  5%|▌         | 108/2001 [10:51<3:08:26,  5.97s/it]  5%|▌         | 109/2001 [10:57<3:08:47,  5.99s/it]  5%|▌         | 110/2001 [11:03<3:09:08,  6.00s/it]  6%|▌         | 111/2001 [11:09<3:09:04,  6.00s/it]  6%|▌         | 112/2001 [11:15<3:10:08,  6.04s/it]  6%|▌         | 113/2001 [11:22<3:09:54,  6.04s/it]  6%|▌         | 114/2001 [11:28<3:09:36,  6.03s/it]  6%|▌         | 115/2001 [11:34<3:09:45,  6.04s/it]  6%|▌         | 116/2001 [11:40<3:10:34,  6.07s/it]  6%|▌         | 117/2001 [11:46<3:10:53,  6.08s/it]  6%|▌         | 118/2001 [11:52<3:10:41,  6.08s/it]  6%|▌         | 119/2001 [11:58<3:11:00,  6.09s/it]  6%|▌         | 120/2001 [12:04<3:10:35,  6.08s/it]  6%|▌         | 121/2001 [12:10<3:09:58,  6.06s/it]  6%|▌         | 122/2001 [12:16<3:10:05,  6.07s/it]  6%|▌         | 123/2001 [12:22<3:10:02,  6.07s/it]  6%|▌         | 124/2001 [12:28<3:09:31,  6.06s/it]  6%|▌         | 125/2001 [12:34<3:08:34,  6.03s/it]  6%|▋         | 126/2001 [12:40<3:07:46,  6.01s/it]  6%|▋         | 127/2001 [12:46<3:07:58,  6.02s/it]  6%|▋         | 128/2001 [12:52<3:08:30,  6.04s/it]  6%|▋         | 129/2001 [12:58<3:08:12,  6.03s/it]  6%|▋         | 130/2001 [13:04<3:08:31,  6.05s/it]  7%|▋         | 131/2001 [13:11<3:08:49,  6.06s/it]  7%|▋         | 132/2001 [13:17<3:08:53,  6.06s/it]tensor(0.8009, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7984, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7954, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7963, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7962, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7914, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8157393869480508, 'train_f1': 0.8283883856963108, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 68, 'train_macro_f1': 0.8152924248275193, 'train_micro_f1': 0.8162209421929644, 'val_auc': 0.80801751599548, 'val_f1': 0.8246579650888505, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 68, 'val_macro_f1': 0.807239444372889, 'val_micro_f1': 0.8088134430727023, 'test_auc': 0.8067153683061484, 'test_f1': 0.8181288011330502, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 68, 'test_macro_f1': 0.8065087301728391, 'test_micro_f1': 0.8072065706968118}
loss tensor(0.7917, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7950, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8167354561142796, 'train_f1': 0.8242476505923741, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 70, 'train_macro_f1': 0.8150656065999655, 'train_micro_f1': 0.8155214976342317, 'val_auc': 0.8090889124784948, 'val_f1': 0.8199036918138043, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 70, 'val_macro_f1': 0.8067129795101411, 'val_micro_f1': 0.8076131687242798, 'test_auc': 0.8089667695278882, 'test_f1': 0.8156509930402309, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 70, 'test_macro_f1': 0.8078623153713673, 'test_micro_f1': 0.8081780446878036}
loss tensor(0.7907, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7903, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7881, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7863, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7830, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7876, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7930, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7854, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7870, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7824, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7822, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7875, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7799, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8172929863978066, 'train_f1': 0.8256559994531303, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 83, 'train_macro_f1': 0.8158419394695002, 'train_micro_f1': 0.8163649454844683, 'val_auc': 0.8096327516694294, 'val_f1': 0.8216682646212847, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 83, 'val_macro_f1': 0.8076154863616968, 'val_micro_f1': 0.8086419753086419, 'test_auc': 0.8107427000020992, 'test_f1': 0.8176655081800458, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 83, 'test_macro_f1': 0.8096991933931844, 'test_micro_f1': 0.8100326768524243}
loss tensor(0.7873, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7858, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7794, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7850, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8170679784595242, 'train_f1': 0.8265232696085105, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 87, 'train_macro_f1': 0.8158838482930437, 'train_micro_f1': 0.8164986628265789, 'val_auc': 0.8113718248514544, 'val_f1': 0.8245586130109751, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 87, 'val_macro_f1': 0.809712819616888, 'val_micro_f1': 0.8108710562414266, 'test_auc': 0.808755799063753, 'test_f1': 0.8175084175084175, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 87, 'test_macro_f1': 0.8080668596923473, 'test_micro_f1': 0.8085313079572551}
loss tensor(0.7824, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.817856327154366, 'train_f1': 0.8272589365591816, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 88, 'train_macro_f1': 0.8166686368748486, 'train_micro_f1': 0.8172803949804567, 'val_auc': 0.8115982264377155, 'val_f1': 0.8246339910884786, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 88, 'val_macro_f1': 0.8099006386669159, 'val_micro_f1': 0.8110425240054869, 'test_auc': 0.8094632323613997, 'test_f1': 0.8178676780446692, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 88, 'test_macro_f1': 0.808711225164622, 'test_micro_f1': 0.8091495186787954}
loss tensor(0.7786, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7802, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7809, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7773, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7780, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7805, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7835, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7758, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7824, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7825, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7741, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7815, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7774, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7830, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8186046119924201, 'train_f1': 0.8266538942758836, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 102, 'train_macro_f1': 0.8170887774757034, 'train_micro_f1': 0.8175889734622506, 'val_auc': 0.8121155629757703, 'val_f1': 0.8233787029623698, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 102, 'val_macro_f1': 0.809917806915767, 'val_micro_f1': 0.8108710562414266, 'test_auc': 0.8098809748724731, 'test_f1': 0.8170731707317074, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 102, 'test_macro_f1': 0.8088872035610927, 'test_micro_f1': 0.8092378344961583}
loss tensor(0.7723, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7798, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7774, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7715, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7767, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7686, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7726, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7696, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8190213480791131, 'train_f1': 0.8269462073281638, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 110, 'train_macro_f1': 0.8174784412211731, 'train_micro_f1': 0.8179695535897963, 'val_auc': 0.812773256612709, 'val_f1': 0.824075556267008, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 110, 'val_macro_f1': 0.8105978667434357, 'val_micro_f1': 0.811556927297668, 'test_auc': 0.8117471713164137, 'test_f1': 0.8185210312075983, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 110, 'test_macro_f1': 0.8106793473708896, 'test_micro_f1': 0.811004150843416}
loss tensor(0.7736, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7679, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7746, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7692, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7712, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7761, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7662, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7881, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7739, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7728, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7711, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7703, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7654, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7691, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7660, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7670, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7634, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7671, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7665, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7685, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7655, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7687, grad_fn=<BinaryCrossEntropyBackward0>)
loss   7%|▋         | 133/2001 [13:23<3:08:28,  6.05s/it]  7%|▋         | 134/2001 [13:29<3:07:52,  6.04s/it]  7%|▋         | 135/2001 [13:35<3:07:31,  6.03s/it]  7%|▋         | 136/2001 [13:41<3:06:57,  6.01s/it]  7%|▋         | 137/2001 [13:47<3:06:57,  6.02s/it]  7%|▋         | 138/2001 [13:53<3:07:48,  6.05s/it]  7%|▋         | 139/2001 [13:59<3:07:43,  6.05s/it]  7%|▋         | 140/2001 [14:05<3:07:38,  6.05s/it]  7%|▋         | 141/2001 [14:11<3:07:22,  6.04s/it]  7%|▋         | 142/2001 [14:17<3:06:59,  6.04s/it]  7%|▋         | 143/2001 [14:23<3:05:46,  6.00s/it]  7%|▋         | 144/2001 [14:29<3:04:04,  5.95s/it]  7%|▋         | 145/2001 [14:35<3:04:35,  5.97s/it]  7%|▋         | 146/2001 [14:41<3:04:17,  5.96s/it]  7%|▋         | 147/2001 [14:47<3:04:46,  5.98s/it]  7%|▋         | 148/2001 [14:53<3:04:51,  5.99s/it]  7%|▋         | 149/2001 [14:59<3:04:33,  5.98s/it]  7%|▋         | 150/2001 [15:05<3:04:07,  5.97s/it]  8%|▊         | 151/2001 [15:11<3:04:05,  5.97s/it]  8%|▊         | 152/2001 [15:17<3:04:10,  5.98s/it]  8%|▊         | 153/2001 [15:22<3:03:47,  5.97s/it]  8%|▊         | 154/2001 [15:28<3:02:32,  5.93s/it]  8%|▊         | 155/2001 [15:34<3:02:22,  5.93s/it]  8%|▊         | 156/2001 [15:40<3:02:48,  5.94s/it]  8%|▊         | 157/2001 [15:46<3:02:54,  5.95s/it]  8%|▊         | 158/2001 [15:52<3:03:43,  5.98s/it]  8%|▊         | 159/2001 [15:58<3:03:29,  5.98s/it]  8%|▊         | 160/2001 [16:04<3:03:58,  6.00s/it]  8%|▊         | 161/2001 [16:10<3:03:25,  5.98s/it]  8%|▊         | 162/2001 [16:16<3:02:31,  5.96s/it]  8%|▊         | 163/2001 [16:22<3:01:53,  5.94s/it]  8%|▊         | 164/2001 [16:28<3:01:07,  5.92s/it]  8%|▊         | 165/2001 [16:34<3:02:02,  5.95s/it]  8%|▊         | 166/2001 [16:40<3:02:07,  5.95s/it]  8%|▊         | 167/2001 [16:46<3:03:22,  6.00s/it]  8%|▊         | 168/2001 [16:52<3:04:37,  6.04s/it]  8%|▊         | 169/2001 [16:58<3:05:38,  6.08s/it]  8%|▊         | 170/2001 [17:04<3:05:29,  6.08s/it]  9%|▊         | 171/2001 [17:10<3:05:50,  6.09s/it]  9%|▊         | 172/2001 [17:17<3:05:47,  6.09s/it]  9%|▊         | 173/2001 [17:23<3:04:58,  6.07s/it]  9%|▊         | 174/2001 [17:29<3:05:41,  6.10s/it]  9%|▊         | 175/2001 [17:35<3:04:52,  6.07s/it]  9%|▉         | 176/2001 [17:41<3:03:38,  6.04s/it]  9%|▉         | 177/2001 [17:47<3:02:41,  6.01s/it]  9%|▉         | 178/2001 [17:53<3:01:31,  5.97s/it]  9%|▉         | 179/2001 [17:58<3:01:17,  5.97s/it]  9%|▉         | 180/2001 [18:04<3:01:20,  5.97s/it]  9%|▉         | 181/2001 [18:10<3:00:44,  5.96s/it]  9%|▉         | 182/2001 [18:16<3:00:53,  5.97s/it]  9%|▉         | 183/2001 [18:22<3:00:07,  5.94s/it]  9%|▉         | 184/2001 [18:28<2:59:09,  5.92s/it]  9%|▉         | 185/2001 [18:34<2:59:34,  5.93s/it]  9%|▉         | 186/2001 [18:40<3:00:15,  5.96s/it]  9%|▉         | 187/2001 [18:46<3:00:04,  5.96s/it]  9%|▉         | 188/2001 [18:52<3:00:02,  5.96s/it]  9%|▉         | 189/2001 [18:58<2:59:57,  5.96s/it]  9%|▉         | 190/2001 [19:04<2:59:54,  5.96s/it] 10%|▉         | 191/2001 [19:10<3:00:00,  5.97s/it] 10%|▉         | 192/2001 [19:16<3:00:25,  5.98s/it] 10%|▉         | 193/2001 [19:22<3:01:18,  6.02s/it] 10%|▉         | 194/2001 [19:28<3:01:18,  6.02s/it] 10%|▉         | 195/2001 [19:34<3:00:59,  6.01s/it] 10%|▉         | 196/2001 [19:40<3:00:37,  6.00s/it] 10%|▉         | 197/2001 [19:46<2:59:45,  5.98s/it] 10%|▉         | 198/2001 [19:52<2:58:15,  5.93s/it] 10%|▉         | 199/2001 [19:58<2:56:40,  5.88s/it] 10%|▉         | 200/2001 [20:03<2:56:54,  5.89s/it] 10%|█         | 201/2001 [20:09<2:56:34,  5.89s/it] 10%|█         | 202/2001 [20:15<2:57:33,  5.92s/it] 10%|█         | 203/2001 [20:21<2:58:15,  5.95s/it] 10%|█         | 204/2001 [20:27<2:58:39,  5.97s/it] 10%|█         | 205/2001 [20:33<2:58:47,  5.97s/it] 10%|█         | 206/2001 [20:39<2:58:32,  5.97s/it] 10%|█         | 207/2001 [20:45<2:58:33,  5.97s/it] 10%|█         | 208/2001 [20:51<2:59:21,  6.00s/it] 10%|█         | 209/2001 [20:57<2:58:26,  5.97s/it] 10%|█         | 210/2001 [21:03<2:58:09,  5.97s/it] 11%|█         | 211/2001 [21:09<2:58:15,  5.97s/it] 11%|█         | 212/2001 [21:15<2:57:48,  5.96s/it] 11%|█         | 213/2001 [21:21<2:57:24,  5.95s/it] 11%|█         | 214/2001 [21:27<2:57:24,  5.96s/it] 11%|█         | 215/2001 [21:33<2:57:33,  5.96s/it] 11%|█         | 216/2001 [21:39<2:57:14,  5.96s/it] 11%|█         | 217/2001 [21:45<2:57:13,  5.96s/it] 11%|█         | 218/2001 [21:51<2:57:28,  5.97s/it] 11%|█         | 219/2001 [21:57<2:56:36,  5.95s/it] 11%|█         | 220/2001 [22:03<2:56:27,  5.94s/it] 11%|█         | 221/2001 [22:09<2:56:40,  5.96s/it] 11%|█         | 222/2001 [22:15<2:57:01,  5.97s/it]tensor(0.7682, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7681, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7678, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7733, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7674, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7711, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7623, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7876, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7673, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7775, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7637, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7633, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7721, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7568, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7659, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7660, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7575, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7717, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7550, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7711, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7634, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7579, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7676, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7569, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7685, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7611, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7554, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7594, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7543, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7615, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7535, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7579, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7557, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7545, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7543, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7501, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7553, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7536, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7553, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7512, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7511, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7546, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7491, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7501, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7495, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7487, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7511, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7514, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7553, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7469, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7551, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7530, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7492, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7549, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7467, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7475, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7516, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7487, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7515, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7492, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7520, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7478, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7477, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7532, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7492, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7612, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7446, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7593, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.823125239227903, 'train_f1': 0.8305333646616542, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 200, 'train_macro_f1': 0.8214923042429358, 'train_micro_f1': 0.8219502160049372, 'val_auc': 0.8136156368979679, 'val_f1': 0.8236050812027657, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 200, 'val_macro_f1': 0.8110679216849457, 'val_micro_f1': 0.8118998628257886, 'test_auc': 0.8134842664315554, 'test_f1': 0.8199949079181873, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 200, 'test_macro_f1': 0.8123724884799441, 'test_micro_f1': 0.812682151373311}
loss tensor(0.7517, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7545, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7493, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7464, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7469, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7454, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7492, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7467, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8264110172217752, 'train_f1': 0.834322646151443, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 208, 'train_macro_f1': 0.824945090410417, 'train_micro_f1': 0.8254474387986012, 'val_auc': 0.8140178116842709, 'val_f1': 0.8255795363709032, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 208, 'val_macro_f1': 0.8119393337243682, 'val_micro_f1': 0.8129286694101509, 'test_auc': 0.8156590465394544, 'test_f1': 0.8219108280254778, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 208, 'test_macro_f1': 0.8145061453162068, 'test_micro_f1': 0.8148017309900204}
loss tensor(0.7457, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7476, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7438, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7423, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7390, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8261480578613779, 'train_f1': 0.8348080011680538, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 213, 'train_macro_f1': 0.8248736042043312, 'train_micro_f1': 0.8254371528492079, 'val_auc': 0.815453352240936, 'val_f1': 0.8272117534334078, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 213, 'val_macro_f1': 0.8134577834179256, 'val_micro_f1': 0.8144718792866941, 'test_auc': 0.8140363582929236, 'test_f1': 0.8217211384173634, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 213, 'test_macro_f1': 0.8131743128458867, 'test_micro_f1': 0.8135653095469398}
loss tensor(0.7421, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7392, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7437, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8285551175458226, 'train_f1': 0.8395240159946042, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 216, 'train_macro_f1': 0.8279027614030713, 'train_micro_f1': 0.8286875128574368, 'val_auc': 0.8176654324115799, 'val_f1': 0.8318835995571723, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 216, 'val_macro_f1': 0.8164286000032632, 'val_micro_f1': 0.8177297668038409, 'test_auc': 0.8158595209605979, 'test_f1': 0.8254606365159128, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 216, 'test_macro_f1': 0.8154017174733497, 'test_micro_f1': 0.8159498366157378}
loss tensor(0.7343, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7443, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7397, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7396, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7491, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7356, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7379, grad_fn=<BinaryCrossEntropyBackward0>)
 11%|█         | 223/2001 [22:21<3:00:24,  6.09s/it] 11%|█         | 224/2001 [22:27<2:59:19,  6.05s/it] 11%|█         | 225/2001 [22:33<2:57:55,  6.01s/it] 11%|█▏        | 226/2001 [22:39<2:56:36,  5.97s/it] 11%|█▏        | 227/2001 [22:45<2:56:01,  5.95s/it] 11%|█▏        | 228/2001 [22:51<2:55:05,  5.93s/it] 11%|█▏        | 229/2001 [22:56<2:52:34,  5.84s/it] 11%|█▏        | 230/2001 [23:02<2:53:08,  5.87s/it] 12%|█▏        | 231/2001 [23:08<2:53:57,  5.90s/it] 12%|█▏        | 232/2001 [23:14<2:51:36,  5.82s/it] 12%|█▏        | 233/2001 [23:20<2:52:46,  5.86s/it] 12%|█▏        | 234/2001 [23:26<2:53:05,  5.88s/it] 12%|█▏        | 235/2001 [23:32<2:53:30,  5.89s/it] 12%|█▏        | 236/2001 [23:38<2:53:45,  5.91s/it] 12%|█▏        | 237/2001 [23:44<2:53:52,  5.91s/it] 12%|█▏        | 238/2001 [23:49<2:53:53,  5.92s/it] 12%|█▏        | 239/2001 [23:55<2:54:15,  5.93s/it] 12%|█▏        | 240/2001 [24:01<2:54:11,  5.94s/it] 12%|█▏        | 241/2001 [24:07<2:54:10,  5.94s/it] 12%|█▏        | 242/2001 [24:13<2:53:30,  5.92s/it] 12%|█▏        | 243/2001 [24:19<2:52:13,  5.88s/it] 12%|█▏        | 244/2001 [24:25<2:52:55,  5.91s/it] 12%|█▏        | 245/2001 [24:31<2:53:13,  5.92s/it] 12%|█▏        | 246/2001 [24:37<2:53:04,  5.92s/it]{'train_auc': 0.8334913433048916, 'train_f1': 0.8433497346467274, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 223, 'train_macro_f1': 0.8326295561455808, 'train_micro_f1': 0.8333161900843448, 'val_auc': 0.8182029727657314, 'val_f1': 0.8323315406516926, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 223, 'val_macro_f1': 0.8169519927144647, 'val_micro_f1': 0.8182441700960219, 'test_auc': 0.8185181686504186, 'test_f1': 0.8276729559748428, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 223, 'test_macro_f1': 0.8179965376833452, 'test_micro_f1': 0.8185109953192617}
loss tensor(0.7290, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8336737269111337, 'train_f1': 0.8423486438175177, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 224, 'train_macro_f1': 0.8325006027270837, 'train_micro_f1': 0.8330796132483028, 'val_auc': 0.8184091705358956, 'val_f1': 0.8307594332112721, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 224, 'val_macro_f1': 0.8166429527193273, 'val_micro_f1': 0.8177297668038409, 'test_auc': 0.8192444948254508, 'test_f1': 0.8273829572246549, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 224, 'test_macro_f1': 0.8185197051675736, 'test_micro_f1': 0.8189525744060762}
loss tensor(0.7353, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8363872650914936, 'train_f1': 0.8451775664661362, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 225, 'train_macro_f1': 0.8352830270500958, 'train_micro_f1': 0.8358773914832339, 'val_auc': 0.8192287323935628, 'val_f1': 0.8328845239980993, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 225, 'val_macro_f1': 0.8178625572709615, 'val_micro_f1': 0.8191015089163237, 'test_auc': 0.8202951487289293, 'test_f1': 0.8281210486386242, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 225, 'test_macro_f1': 0.8195135522336217, 'test_micro_f1': 0.819924048397068}
loss tensor(0.7336, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7313, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8372940809115392, 'train_f1': 0.8451521792062333, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 227, 'train_macro_f1': 0.8359472005931455, 'train_micro_f1': 0.8364636905986422, 'val_auc': 0.8204176675478699, 'val_f1': 0.8327764518695308, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 227, 'val_macro_f1': 0.8186934871357321, 'val_micro_f1': 0.8197873799725651, 'test_auc': 0.8223618195940131, 'test_f1': 0.8296884235413324, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 227, 'test_macro_f1': 0.8214905137238273, 'test_micro_f1': 0.8218669963790515}
loss tensor(0.7257, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8385241746197716, 'train_f1': 0.8478750882759822, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 228, 'train_macro_f1': 0.8376038045282361, 'train_micro_f1': 0.8382534457930467, 'val_auc': 0.8217393536585309, 'val_f1': 0.8353909465020576, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 228, 'val_macro_f1': 0.8204264870931537, 'val_micro_f1': 0.821673525377229, 'test_auc': 0.8237892814408968, 'test_f1': 0.832227169621104, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 228, 'test_macro_f1': 0.8231693420478228, 'test_micro_f1': 0.8236333127263092}
loss tensor(0.7201, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7255, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8400994490973098, 'train_f1': 0.8506512245329845, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 230, 'train_macro_f1': 0.8395295423299303, 'train_micro_f1': 0.8403003497222794, 'val_auc': 0.8220783023850485, 'val_f1': 0.836541495739981, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 230, 'val_macro_f1': 0.8210120171152027, 'val_micro_f1': 0.8223593964334706, 'test_auc': 0.8266819908894347, 'test_f1': 0.8359682141363446, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 230, 'test_macro_f1': 0.8262714515635422, 'test_micro_f1': 0.8268126821513733}
loss tensor(0.7188, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8409019391794248, 'train_f1': 0.8496859978291208, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 231, 'train_macro_f1': 0.8398622853176463, 'train_micro_f1': 0.8404649249125694, 'val_auc': 0.8232533325600422, 'val_f1': 0.8360577686081573, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 231, 'val_macro_f1': 0.8217208477573696, 'val_micro_f1': 0.8228737997256516, 'test_auc': 0.8276896110166467, 'test_f1': 0.8356325706594886, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 231, 'test_macro_f1': 0.8270001485013375, 'test_micro_f1': 0.8274308928729135}
loss tensor(0.7167, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8417461387730807, 'train_f1': 0.8499290835260059, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 232, 'train_macro_f1': 0.8405510863194061, 'train_micro_f1': 0.8411026537749434, 'val_auc': 0.8246471581787661, 'val_f1': 0.8364910046170992, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 232, 'val_macro_f1': 0.8228525987231883, 'val_micro_f1': 0.8239026063100138, 'test_auc': 0.8293395889749565, 'test_f1': 0.8364280891289669, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 232, 'test_macro_f1': 0.8284752040384601, 'test_micro_f1': 0.8288439459507198}
loss tensor(0.7162, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7140, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7184, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7151, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8433777709633967, 'train_f1': 0.8541420658007163, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 236, 'train_macro_f1': 0.8429244617914378, 'train_micro_f1': 0.8437255708701914, 'val_auc': 0.8251188578616375, 'val_f1': 0.840301791889343, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 236, 'val_macro_f1': 0.8243379951525176, 'val_micro_f1': 0.8257887517146777, 'test_auc': 0.8283771018326092, 'test_f1': 0.8381174899866488, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 236, 'test_macro_f1': 0.82808144242345, 'test_micro_f1': 0.8286673143159939}
loss tensor(0.7109, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7137, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7105, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8439260180335039, 'train_f1': 0.8527897161884849, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 239, 'train_macro_f1': 0.8429554515191645, 'train_micro_f1': 0.8435712816292945, 'val_auc': 0.825834786027326, 'val_f1': 0.8384639796889877, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 239, 'val_macro_f1': 0.8243047238989512, 'val_micro_f1': 0.8254458161865569, 'test_auc': 0.8291454121796084, 'test_f1': 0.8371858451710514, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 239, 'test_macro_f1': 0.8284915178036856, 'test_micro_f1': 0.8289322617680827}
loss tensor(0.7066, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7076, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7113, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8424251246806218, 'train_f1': 0.846997770279603, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 242, 'train_macro_f1': 0.8401959909175029, 'train_micro_f1': 0.8404854968113556, 'val_auc': 0.8261915616503999, 'val_f1': 0.833764553686934, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 242, 'val_macro_f1': 0.8230866564055108, 'val_micro_f1': 0.8237311385459534, 'test_auc': 0.8287570585889119, 'test_f1': 0.832118040662263, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 242, 'test_macro_f1': 0.8270154312875425, 'test_micro_f1': 0.8271659454208249}
loss tensor(0.7072, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7135, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7042, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7102, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7089, grad_fn=<BinaryCrossEntropyBackward0>)
 12%|█▏        | 247/2001 [24:43<2:53:21,  5.93s/it] 12%|█▏        | 248/2001 [24:49<2:53:33,  5.94s/it] 12%|█▏        | 249/2001 [24:55<2:53:28,  5.94s/it] 12%|█▏        | 250/2001 [25:01<2:53:39,  5.95s/it] 13%|█▎        | 251/2001 [25:07<2:54:04,  5.97s/it] 13%|█▎        | 252/2001 [25:13<2:54:40,  5.99s/it] 13%|█▎        | 253/2001 [25:19<2:54:41,  6.00s/it] 13%|█▎        | 254/2001 [25:25<2:54:08,  5.98s/it] 13%|█▎        | 255/2001 [25:31<2:54:06,  5.98s/it] 13%|█▎        | 256/2001 [25:37<2:55:23,  6.03s/it] 13%|█▎        | 257/2001 [25:43<2:55:18,  6.03s/it] 13%|█▎        | 258/2001 [25:49<2:55:35,  6.04s/it] 13%|█▎        | 259/2001 [25:55<2:54:57,  6.03s/it] 13%|█▎        | 260/2001 [26:01<2:54:18,  6.01s/it] 13%|█▎        | 261/2001 [26:07<2:53:57,  6.00s/it] 13%|█▎        | 262/2001 [26:13<2:53:24,  5.98s/it] 13%|█▎        | 263/2001 [26:19<2:53:18,  5.98s/it] 13%|█▎        | 264/2001 [26:25<2:53:28,  5.99s/it] 13%|█▎        | 265/2001 [26:31<2:53:12,  5.99s/it] 13%|█▎        | 266/2001 [26:37<2:52:58,  5.98s/it] 13%|█▎        | 267/2001 [26:43<2:53:05,  5.99s/it] 13%|█▎        | 268/2001 [26:49<2:53:01,  5.99s/it] 13%|█▎        | 269/2001 [26:55<2:53:21,  6.01s/it] 13%|█▎        | 270/2001 [27:01<2:53:49,  6.03s/it] 14%|█▎        | 271/2001 [27:07<2:53:55,  6.03s/it] 14%|█▎        | 272/2001 [27:13<2:53:38,  6.03s/it] 14%|█▎        | 273/2001 [27:19<2:52:58,  6.01s/it] 14%|█▎        | 274/2001 [27:25<2:51:21,  5.95s/it] 14%|█▎        | 275/2001 [27:31<2:51:06,  5.95s/it] 14%|█▍        | 276/2001 [27:37<2:50:48,  5.94s/it] 14%|█▍        | 277/2001 [27:42<2:50:18,  5.93s/it] 14%|█▍        | 278/2001 [27:48<2:49:39,  5.91s/it] 14%|█▍        | 279/2001 [27:54<2:50:19,  5.93s/it] 14%|█▍        | 280/2001 [28:00<2:50:23,  5.94s/it] 14%|█▍        | 281/2001 [28:06<2:50:39,  5.95s/it] 14%|█▍        | 282/2001 [28:12<2:50:52,  5.96s/it] 14%|█▍        | 283/2001 [28:18<2:50:30,  5.96s/it] 14%|█▍        | 284/2001 [28:24<2:51:17,  5.99s/it] 14%|█▍        | 285/2001 [28:30<2:51:11,  5.99s/it] 14%|█▍        | 286/2001 [28:36<2:50:58,  5.98s/it] 14%|█▍        | 287/2001 [28:42<2:51:00,  5.99s/it] 14%|█▍        | 288/2001 [28:48<2:51:05,  5.99s/it] 14%|█▍        | 289/2001 [28:54<2:50:43,  5.98s/it] 14%|█▍        | 290/2001 [29:00<2:49:56,  5.96s/it] 15%|█▍        | 291/2001 [29:06<2:50:04,  5.97s/it] 15%|█▍        | 292/2001 [29:12<2:49:55,  5.97s/it] 15%|█▍        | 293/2001 [29:18<2:50:33,  5.99s/it] 15%|█▍        | 294/2001 [29:24<2:50:54,  6.01s/it] 15%|█▍        | 295/2001 [29:30<2:50:27,  6.00s/it] 15%|█▍        | 296/2001 [29:36<2:50:29,  6.00s/it] 15%|█▍        | 297/2001 [29:42<2:49:39,  5.97s/it] 15%|█▍        | 298/2001 [29:48<2:49:28,  5.97s/it] 15%|█▍        | 299/2001 [29:54<2:49:15,  5.97s/it] 15%|█▍        | 300/2001 [30:00<2:48:59,  5.96s/it] 15%|█▌        | 301/2001 [30:06<2:49:03,  5.97s/it] 15%|█▌        | 302/2001 [30:12<2:49:00,  5.97s/it] 15%|█▌        | 303/2001 [30:18<2:48:53,  5.97s/it] 15%|█▌        | 304/2001 [30:24<2:49:34,  6.00s/it] 15%|█▌        | 305/2001 [30:30<2:49:22,  5.99s/it] 15%|█▌        | 306/2001 [30:36<2:49:04,  5.99s/it] 15%|█▌        | 307/2001 [30:42<2:48:59,  5.99s/it] 15%|█▌        | 308/2001 [30:48<2:49:00,  5.99s/it]{'train_auc': 0.8421983897418155, 'train_f1': 0.8479285293540152, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 247, 'train_macro_f1': 0.8403068872736807, 'train_micro_f1': 0.8406706439004321, 'val_auc': 0.8264735831539156, 'val_f1': 0.835451182242239, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 247, 'val_macro_f1': 0.8238206893403228, 'val_micro_f1': 0.8245884773662552, 'test_auc': 0.8285093519743056, 'test_f1': 0.8336454963391793, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 247, 'test_macro_f1': 0.8271897206466539, 'test_micro_f1': 0.8274308928729135}
loss tensor(0.7107, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7081, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7172, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8449395961315537, 'train_f1': 0.8562677667282421, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 250, 'train_macro_f1': 0.844669937876632, 'train_micro_f1': 0.845535897963382, 'val_auc': 0.8305713924422515, 'val_f1': 0.8458522816371334, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 250, 'val_macro_f1': 0.8299622671662119, 'val_micro_f1': 0.8314471879286695, 'test_auc': 0.8305581795663035, 'test_f1': 0.8408618251393394, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 250, 'test_macro_f1': 0.8304073831579051, 'test_micro_f1': 0.8310518413847922}
loss tensor(0.7039, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7179, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7074, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7024, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7061, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7056, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7023, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7055, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7001, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.7023, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6950, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6965, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6974, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8477999842967738, 'train_f1': 0.8576214727883624, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 266, 'train_macro_f1': 0.8471658026972209, 'train_micro_f1': 0.8478810944250155, 'val_auc': 0.8319235031230345, 'val_f1': 0.8451816745655608, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 266, 'val_macro_f1': 0.830727320222413, 'val_micro_f1': 0.8319615912208504, 'test_auc': 0.8340722547599555, 'test_f1': 0.8428451882845187, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 266, 'test_macro_f1': 0.8336327661691854, 'test_micro_f1': 0.8341428949924931}
loss tensor(0.6921, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6940, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6894, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6957, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6894, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6944, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6929, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6886, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6889, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6900, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6905, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6875, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6951, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6865, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6878, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6861, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8477264379245287, 'train_f1': 0.857448325017819, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 286, 'train_macro_f1': 0.84706268244976, 'train_micro_f1': 0.847767948981691, 'val_auc': 0.8324749484564998, 'val_f1': 0.8460082044809089, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 286, 'val_macro_f1': 0.8313781165100751, 'val_micro_f1': 0.832647462277092, 'test_auc': 0.8335170140856897, 'test_f1': 0.8423958507612515, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 286, 'test_macro_f1': 0.8330946706107043, 'test_micro_f1': 0.833613000088316}
loss tensor(0.6884, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6936, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6920, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6891, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6952, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8470014563073527, 'train_f1': 0.8579558519199816, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 292, 'train_macro_f1': 0.8466697895236788, 'train_micro_f1': 0.8475005142974696, 'val_auc': 0.8331958681532239, 'val_f1': 0.8473882945248584, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 292, 'val_macro_f1': 0.832322632567629, 'val_micro_f1': 0.8336762688614541, 'test_auc': 0.8308321262883893, 'test_f1': 0.8413793103448277, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 292, 'test_macro_f1': 0.8307358336664294, 'test_micro_f1': 0.8314051046542436}
loss tensor(0.6956, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6913, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6816, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6934, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6803, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6823, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6857, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6829, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6871, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6901, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8480642852235463, 'train_f1': 0.8560669293631229, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 302, 'train_macro_f1': 0.8469118752891802, 'train_micro_f1': 0.8474593704998972, 'val_auc': 0.8339333074407564, 'val_f1': 0.8451869530628481, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 302, 'val_macro_f1': 0.8321491560257539, 'val_micro_f1': 0.8331618655692729, 'test_auc': 0.8332923987656653, 'test_f1': 0.8406065711878686, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 302, 'test_macro_f1': 0.8325156092761912, 'test_micro_f1': 0.8329064735494127}
loss tensor(0.6840, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6849, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6994, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6887, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6992, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6886, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8498587759056744, 'train_f1': 0.8605731916483811, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 308, 'train_macro_f1': 0.8495168099743066, 'train_micro_f1': 0.8503291503805801, 'val_auc': 0.8339737150729502, 'val_f1': 0.8482942933501021, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 308, 'val_macro_f1': 0.8331609124679984, 'val_micro_f1': 0.8345336076817559, 'test_auc': 0.8319405084283225, 'test_f1': 0.8419913419913421, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 308, 'test_macro_f1': 0.83175361720594, 'test_micro_f1': 0.8323765786452354}
loss tensor(0.6849, grad_fn=<BinaryCrossEntropyBackward0>)
 15%|█▌        | 309/2001 [30:54<2:49:00,  5.99s/it] 15%|█▌        | 310/2001 [31:00<2:49:09,  6.00s/it] 16%|█▌        | 311/2001 [31:06<2:49:19,  6.01s/it] 16%|█▌        | 312/2001 [31:12<2:49:43,  6.03s/it] 16%|█▌        | 313/2001 [31:18<2:49:07,  6.01s/it] 16%|█▌        | 314/2001 [31:24<2:48:06,  5.98s/it] 16%|█▌        | 315/2001 [31:30<2:46:50,  5.94s/it] 16%|█▌        | 316/2001 [31:36<2:46:52,  5.94s/it] 16%|█▌        | 317/2001 [31:42<2:47:03,  5.95s/it] 16%|█▌        | 318/2001 [31:47<2:47:07,  5.96s/it] 16%|█▌        | 319/2001 [31:53<2:47:14,  5.97s/it] 16%|█▌        | 320/2001 [31:59<2:47:02,  5.96s/it] 16%|█▌        | 321/2001 [32:05<2:47:13,  5.97s/it] 16%|█▌        | 322/2001 [32:11<2:47:06,  5.97s/it] 16%|█▌        | 323/2001 [32:17<2:47:11,  5.98s/it] 16%|█▌        | 324/2001 [32:23<2:46:44,  5.97s/it] 16%|█▌        | 325/2001 [32:29<2:46:07,  5.95s/it] 16%|█▋        | 326/2001 [32:35<2:43:43,  5.86s/it] 16%|█▋        | 327/2001 [32:41<2:44:48,  5.91s/it] 16%|█▋        | 328/2001 [32:47<2:44:48,  5.91s/it] 16%|█▋        | 329/2001 [32:53<2:44:57,  5.92s/it] 16%|█▋        | 330/2001 [32:59<2:44:47,  5.92s/it] 17%|█▋        | 331/2001 [33:05<2:45:03,  5.93s/it] 17%|█▋        | 332/2001 [33:11<2:45:06,  5.94s/it] 17%|█▋        | 333/2001 [33:17<2:45:06,  5.94s/it] 17%|█▋        | 334/2001 [33:23<2:46:12,  5.98s/it] 17%|█▋        | 335/2001 [33:29<2:46:16,  5.99s/it] 17%|█▋        | 336/2001 [33:35<2:45:52,  5.98s/it] 17%|█▋        | 337/2001 [33:41<2:45:25,  5.96s/it] 17%|█▋        | 338/2001 [33:47<2:46:08,  5.99s/it] 17%|█▋        | 339/2001 [33:53<2:46:12,  6.00s/it] 17%|█▋        | 340/2001 [33:59<2:46:25,  6.01s/it] 17%|█▋        | 341/2001 [34:05<2:46:29,  6.02s/it] 17%|█▋        | 342/2001 [34:11<2:45:23,  5.98s/it] 17%|█▋        | 343/2001 [34:17<2:46:20,  6.02s/it] 17%|█▋        | 344/2001 [34:23<2:47:24,  6.06s/it] 17%|█▋        | 345/2001 [34:29<2:47:38,  6.07s/it] 17%|█▋        | 346/2001 [34:35<2:48:10,  6.10s/it] 17%|█▋        | 347/2001 [34:41<2:48:20,  6.11s/it] 17%|█▋        | 348/2001 [34:47<2:46:58,  6.06s/it] 17%|█▋        | 349/2001 [34:53<2:45:42,  6.02s/it] 17%|█▋        | 350/2001 [34:59<2:44:01,  5.96s/it] 18%|█▊        | 351/2001 [35:05<2:44:44,  5.99s/it] 18%|█▊        | 352/2001 [35:11<2:45:44,  6.03s/it] 18%|█▊        | 353/2001 [35:17<2:46:04,  6.05s/it] 18%|█▊        | 354/2001 [35:23<2:45:34,  6.03s/it] 18%|█▊        | 355/2001 [35:29<2:44:30,  6.00s/it] 18%|█▊        | 356/2001 [35:35<2:43:57,  5.98s/it] 18%|█▊        | 357/2001 [35:41<2:43:15,  5.96s/it] 18%|█▊        | 358/2001 [35:47<2:41:55,  5.91s/it] 18%|█▊        | 359/2001 [35:53<2:42:28,  5.94s/it] 18%|█▊        | 360/2001 [35:59<2:42:44,  5.95s/it] 18%|█▊        | 361/2001 [36:05<2:42:54,  5.96s/it] 18%|█▊        | 362/2001 [36:11<2:43:18,  5.98s/it] 18%|█▊        | 363/2001 [36:17<2:42:40,  5.96s/it] 18%|█▊        | 364/2001 [36:23<2:42:20,  5.95s/it] 18%|█▊        | 365/2001 [36:29<2:42:14,  5.95s/it] 18%|█▊        | 366/2001 [36:34<2:41:53,  5.94s/it] 18%|█▊        | 367/2001 [36:40<2:41:59,  5.95s/it] 18%|█▊        | 368/2001 [36:46<2:41:12,  5.92s/it] 18%|█▊        | 369/2001 [36:52<2:41:59,  5.96s/it] 18%|█▊        | 370/2001 [36:58<2:43:01,  6.00s/it] 19%|█▊        | 371/2001 [37:04<2:43:36,  6.02s/it] 19%|█▊        | 372/2001 [37:10<2:43:23,  6.02s/it] 19%|█▊        | 373/2001 [37:16<2:43:11,  6.01s/it] 19%|█▊        | 374/2001 [37:22<2:42:53,  6.01s/it] 19%|█▊        | 375/2001 [37:28<2:42:35,  6.00s/it] 19%|█▉        | 376/2001 [37:34<2:42:24,  6.00s/it] 19%|█▉        | 377/2001 [37:40<2:42:15,  5.99s/it] 19%|█▉        | 378/2001 [37:47<2:42:50,  6.02s/it] 19%|█▉        | 379/2001 [37:53<2:43:17,  6.04s/it] 19%|█▉        | 380/2001 [37:59<2:43:09,  6.04s/it] 19%|█▉        | 381/2001 [38:05<2:42:32,  6.02s/it] 19%|█▉        | 382/2001 [38:11<2:42:39,  6.03s/it] 19%|█▉        | 383/2001 [38:17<2:43:06,  6.05s/it] 19%|█▉        | 384/2001 [38:23<2:43:12,  6.06s/it] 19%|█▉        | 385/2001 [38:29<2:43:06,  6.06s/it] 19%|█▉        | 386/2001 [38:35<2:42:36,  6.04s/it] 19%|█▉        | 387/2001 [38:41<2:42:00,  6.02s/it] 19%|█▉        | 388/2001 [38:47<2:42:00,  6.03s/it] 19%|█▉        | 389/2001 [38:53<2:41:56,  6.03s/it] 19%|█▉        | 390/2001 [38:59<2:42:05,  6.04s/it] 20%|█▉        | 391/2001 [39:05<2:41:46,  6.03s/it] 20%|█▉        | 392/2001 [39:11<2:42:10,  6.05s/it] 20%|█▉        | 393/2001 [39:17<2:42:12,  6.05s/it] 20%|█▉        | 394/2001 [39:23<2:41:45,  6.04s/it] 20%|█▉        | 395/2001 [39:29<2:41:31,  6.03s/it] 20%|█▉        | 396/2001 [39:35<2:41:30,  6.04s/it] 20%|█▉        | 397/2001 [39:41<2:41:12,  6.03s/it] 20%|█▉        | 398/2001 [39:47<2:41:00,  6.03s/it] 20%|█▉        | 399/2001 [39:53<2:41:07,  6.03s/it] 20%|█▉        | 400/2001 [39:59<2:40:48,  6.03s/it] 20%|██        | 401/2001 [40:05<2:41:24,  6.05s/it] 20%|██        | 402/2001 [40:12<2:42:21,  6.09s/it] 20%|██        | 403/2001 [40:18<2:42:14,  6.09s/it] 20%|██        | 404/2001 [40:24<2:42:00,  6.09s/it] 20%|██        | 405/2001 [40:30<2:41:38,  6.08s/it] 20%|██        | 406/2001 [40:36<2:41:48,  6.09s/it] 20%|██        | 407/2001 [40:42<2:41:41,  6.09s/it] 20%|██        | 408/2001 [40:48<2:40:46,  6.06s/it] 20%|██        | 409/2001 [40:54<2:40:01,  6.03s/it] 20%|██        | 410/2001 [41:00<2:41:36,  6.09s/it] 21%|██        | 411/2001 [41:06<2:42:01,  6.11s/it] 21%|██        | 412/2001 [41:12<2:41:32,  6.10s/it] 21%|██        | 413/2001 [41:19<2:40:59,  6.08s/it] 21%|██        | 414/2001 [41:25<2:40:37,  6.07s/it] 21%|██        | 415/2001 [41:31<2:39:44,  6.04s/it] 21%|██        | 416/2001 [41:37<2:39:32,  6.04s/it] 21%|██        | 417/2001 [41:43<2:39:22,  6.04s/it] 21%|██        | 418/2001 [41:49<2:39:09,  6.03s/it]{'train_auc': 0.8480774679232289, 'train_f1': 0.8608765848330879, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 309, 'train_macro_f1': 0.8482744021254451, 'train_micro_f1': 0.8493211273400535, 'val_auc': 0.8342127143327772, 'val_f1': 0.8506857855361596, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 309, 'val_macro_f1': 0.8340700269144212, 'val_micro_f1': 0.8357338820301783, 'test_auc': 0.8325471797132482, 'test_f1': 0.8445801022933509, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 309, 'test_macro_f1': 0.8327803590144064, 'test_micro_f1': 0.833613000088316}
loss tensor(0.6805, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8495203604639444, 'train_f1': 0.8607001807349889, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 310, 'train_macro_f1': 0.849302542324275, 'train_micro_f1': 0.85016457519029, 'val_auc': 0.8351828540433541, 'val_f1': 0.8497881023387223, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 310, 'val_macro_f1': 0.8344916328810559, 'val_micro_f1': 0.8359053497942387, 'test_auc': 0.8323320108319164, 'test_f1': 0.8425255802345895, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 310, 'test_macro_f1': 0.8321804371761183, 'test_micro_f1': 0.8328181577320498}
loss tensor(0.6810, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6794, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6868, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6816, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6891, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6797, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6885, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6836, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6839, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6807, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6876, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6805, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6878, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6769, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6804, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6818, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6791, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6830, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6776, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6744, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6774, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6808, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6738, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6771, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6717, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6727, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6738, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6894, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6745, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6785, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6734, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6726, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6748, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6730, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6699, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6719, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6728, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6732, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6691, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6726, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6712, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6735, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6714, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6648, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6652, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6683, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6683, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6669, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6678, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6714, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6729, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6678, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6720, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6683, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6739, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6684, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6800, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6742, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6813, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8507407655075861, 'train_f1': 0.8592604059833194, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 369, 'train_macro_f1': 0.8497825864534432, 'train_micro_f1': 0.8503805801275458, 'val_auc': 0.8358279500067266, 'val_f1': 0.8481393507521774, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 369, 'val_macro_f1': 0.8344267514650774, 'val_micro_f1': 0.835562414266118, 'test_auc': 0.8351397023322207, 'test_f1': 0.8426985195154778, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 369, 'test_macro_f1': 0.8344371943180661, 'test_micro_f1': 0.8348494215313963}
loss tensor(0.6697, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6787, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6835, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6891, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6759, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6734, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6706, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6782, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6678, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6689, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6653, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6672, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6670, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6696, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6691, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6674, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6708, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6690, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6657, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6693, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6716, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6654, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6841, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6657, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6750, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6684, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6632, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6668, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6610, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6657, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6634, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6597, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6642, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6629, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6644, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6630, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6637, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6645, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6603, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6659, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6635, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6620, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6627, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6610, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6669, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6602, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6658, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6630, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6647, grad_fn=<BinaryCrossEntropyBackward0>)
loss  21%|██        | 419/2001 [41:55<2:39:21,  6.04s/it] 21%|██        | 420/2001 [42:01<2:39:34,  6.06s/it] 21%|██        | 421/2001 [42:07<2:39:24,  6.05s/it] 21%|██        | 422/2001 [42:13<2:39:37,  6.07s/it] 21%|██        | 423/2001 [42:19<2:40:11,  6.09s/it] 21%|██        | 424/2001 [42:25<2:39:32,  6.07s/it] 21%|██        | 425/2001 [42:31<2:38:56,  6.05s/it] 21%|██▏       | 426/2001 [42:37<2:38:38,  6.04s/it] 21%|██▏       | 427/2001 [42:43<2:38:43,  6.05s/it] 21%|██▏       | 428/2001 [42:49<2:38:25,  6.04s/it] 21%|██▏       | 429/2001 [42:55<2:38:35,  6.05s/it] 21%|██▏       | 430/2001 [43:02<2:39:56,  6.11s/it] 22%|██▏       | 431/2001 [43:08<2:39:35,  6.10s/it] 22%|██▏       | 432/2001 [43:14<2:39:19,  6.09s/it] 22%|██▏       | 433/2001 [43:20<2:39:02,  6.09s/it] 22%|██▏       | 434/2001 [43:26<2:38:42,  6.08s/it] 22%|██▏       | 435/2001 [43:32<2:38:19,  6.07s/it] 22%|██▏       | 436/2001 [43:38<2:38:11,  6.07s/it] 22%|██▏       | 437/2001 [43:44<2:38:13,  6.07s/it] 22%|██▏       | 438/2001 [43:50<2:37:47,  6.06s/it] 22%|██▏       | 439/2001 [43:56<2:36:58,  6.03s/it] 22%|██▏       | 440/2001 [44:02<2:36:58,  6.03s/it] 22%|██▏       | 441/2001 [44:08<2:36:19,  6.01s/it] 22%|██▏       | 442/2001 [44:14<2:35:50,  6.00s/it] 22%|██▏       | 443/2001 [44:20<2:36:11,  6.01s/it] 22%|██▏       | 444/2001 [44:26<2:36:01,  6.01s/it] 22%|██▏       | 445/2001 [44:32<2:36:36,  6.04s/it] 22%|██▏       | 446/2001 [44:38<2:36:23,  6.03s/it] 22%|██▏       | 447/2001 [44:44<2:35:56,  6.02s/it] 22%|██▏       | 448/2001 [44:50<2:35:29,  6.01s/it] 22%|██▏       | 449/2001 [44:56<2:35:08,  6.00s/it] 22%|██▏       | 450/2001 [45:02<2:35:04,  6.00s/it] 23%|██▎       | 451/2001 [45:08<2:35:04,  6.00s/it] 23%|██▎       | 452/2001 [45:14<2:35:26,  6.02s/it] 23%|██▎       | 453/2001 [45:20<2:34:59,  6.01s/it] 23%|██▎       | 454/2001 [45:26<2:35:30,  6.03s/it] 23%|██▎       | 455/2001 [45:32<2:36:14,  6.06s/it] 23%|██▎       | 456/2001 [45:38<2:35:30,  6.04s/it] 23%|██▎       | 457/2001 [45:44<2:35:13,  6.03s/it] 23%|██▎       | 458/2001 [45:51<2:36:04,  6.07s/it] 23%|██▎       | 459/2001 [45:57<2:36:56,  6.11s/it] 23%|██▎       | 460/2001 [46:03<2:37:09,  6.12s/it] 23%|██▎       | 461/2001 [46:09<2:37:14,  6.13s/it] 23%|██▎       | 462/2001 [46:15<2:37:23,  6.14s/it] 23%|██▎       | 463/2001 [46:21<2:37:38,  6.15s/it] 23%|██▎       | 464/2001 [46:28<2:37:44,  6.16s/it] 23%|██▎       | 465/2001 [46:34<2:37:31,  6.15s/it] 23%|██▎       | 466/2001 [46:40<2:37:37,  6.16s/it] 23%|██▎       | 467/2001 [46:46<2:37:30,  6.16s/it] 23%|██▎       | 468/2001 [46:52<2:37:42,  6.17s/it] 23%|██▎       | 469/2001 [46:58<2:38:10,  6.19s/it] 23%|██▎       | 470/2001 [47:05<2:38:04,  6.19s/it] 24%|██▎       | 471/2001 [47:11<2:37:42,  6.18s/it] 24%|██▎       | 472/2001 [47:17<2:37:52,  6.20s/it] 24%|██▎       | 473/2001 [47:23<2:37:29,  6.18s/it] 24%|██▎       | 474/2001 [47:30<2:39:17,  6.26s/it] 24%|██▎       | 475/2001 [47:36<2:38:39,  6.24s/it] 24%|██▍       | 476/2001 [47:42<2:37:28,  6.20s/it] 24%|██▍       | 477/2001 [47:48<2:37:05,  6.18s/it] 24%|██▍       | 478/2001 [47:54<2:36:57,  6.18s/it] 24%|██▍       | 479/2001 [48:01<2:37:40,  6.22s/it] 24%|██▍       | 480/2001 [48:07<2:37:23,  6.21s/it] 24%|██▍       | 481/2001 [48:13<2:37:06,  6.20s/it] 24%|██▍       | 482/2001 [48:19<2:36:43,  6.19s/it] 24%|██▍       | 483/2001 [48:25<2:36:41,  6.19s/it] 24%|██▍       | 484/2001 [48:31<2:34:54,  6.13s/it] 24%|██▍       | 485/2001 [48:37<2:34:05,  6.10s/it] 24%|██▍       | 486/2001 [48:43<2:33:13,  6.07s/it] 24%|██▍       | 487/2001 [48:49<2:32:13,  6.03s/it] 24%|██▍       | 488/2001 [48:55<2:31:58,  6.03s/it] 24%|██▍       | 489/2001 [49:01<2:33:07,  6.08s/it] 24%|██▍       | 490/2001 [49:07<2:32:42,  6.06s/it] 25%|██▍       | 491/2001 [49:14<2:32:39,  6.07s/it] 25%|██▍       | 492/2001 [49:20<2:31:50,  6.04s/it] 25%|██▍       | 493/2001 [49:25<2:31:11,  6.02s/it] 25%|██▍       | 494/2001 [49:32<2:31:28,  6.03s/it] 25%|██▍       | 495/2001 [49:38<2:31:24,  6.03s/it] 25%|██▍       | 496/2001 [49:44<2:31:12,  6.03s/it] 25%|██▍       | 497/2001 [49:50<2:30:42,  6.01s/it] 25%|██▍       | 498/2001 [49:56<2:30:34,  6.01s/it] 25%|██▍       | 499/2001 [50:02<2:30:09,  6.00s/it] 25%|██▍       | 500/2001 [50:08<2:30:10,  6.00s/it] 25%|██▌       | 501/2001 [50:13<2:29:31,  5.98s/it] 25%|██▌       | 502/2001 [50:20<2:30:46,  6.03s/it] 25%|██▌       | 503/2001 [50:26<2:30:03,  6.01s/it] 25%|██▌       | 504/2001 [50:32<2:30:24,  6.03s/it] 25%|██▌       | 505/2001 [50:38<2:29:54,  6.01s/it] 25%|██▌       | 506/2001 [50:44<2:30:00,  6.02s/it] 25%|██▌       | 507/2001 [50:50<2:30:16,  6.04s/it] 25%|██▌       | 508/2001 [50:56<2:29:07,  5.99s/it] 25%|██▌       | 509/2001 [51:02<2:29:59,  6.03s/it] 25%|██▌       | 510/2001 [51:08<2:30:01,  6.04s/it] 26%|██▌       | 511/2001 [51:14<2:29:53,  6.04s/it] 26%|██▌       | 512/2001 [51:20<2:29:30,  6.02s/it] 26%|██▌       | 513/2001 [51:26<2:29:26,  6.03s/it] 26%|██▌       | 514/2001 [51:32<2:29:37,  6.04s/it] 26%|██▌       | 515/2001 [51:38<2:29:45,  6.05s/it] 26%|██▌       | 516/2001 [51:44<2:29:44,  6.05s/it] 26%|██▌       | 517/2001 [51:50<2:29:31,  6.05s/it] 26%|██▌       | 518/2001 [51:56<2:29:36,  6.05s/it] 26%|██▌       | 519/2001 [52:02<2:29:22,  6.05s/it] 26%|██▌       | 520/2001 [52:08<2:29:10,  6.04s/it] 26%|██▌       | 521/2001 [52:14<2:29:03,  6.04s/it] 26%|██▌       | 522/2001 [52:20<2:28:47,  6.04s/it] 26%|██▌       | 523/2001 [52:26<2:28:34,  6.03s/it] 26%|██▌       | 524/2001 [52:32<2:28:30,  6.03s/it] 26%|██▌       | 525/2001 [52:38<2:29:11,  6.06s/it] 26%|██▋       | 526/2001 [52:45<2:28:58,  6.06s/it] 26%|██▋       | 527/2001 [52:51<2:28:41,  6.05s/it]tensor(0.6645, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.851512757740007, 'train_f1': 0.8625283311178479, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 419, 'train_macro_f1': 0.8512902022996581, 'train_micro_f1': 0.8521394774737708, 'val_auc': 0.8362149125079686, 'val_f1': 0.8515099358472852, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 419, 'val_macro_f1': 0.8357682430990646, 'val_micro_f1': 0.8372770919067215, 'test_auc': 0.8346747276276844, 'test_f1': 0.8448877805486285, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 419, 'test_macro_f1': 0.8345576807792126, 'test_micro_f1': 0.8352026848008478}
loss tensor(0.6741, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6719, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6708, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6854, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6667, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6718, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6690, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6688, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6696, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6828, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6606, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6824, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6697, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6710, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6730, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6648, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6696, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6681, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6669, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6631, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6684, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6636, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6742, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6609, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6601, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6662, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6621, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6642, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6683, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6608, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6727, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6572, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6638, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6661, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6601, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6610, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6740, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6566, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6579, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6650, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6600, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6577, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6586, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6613, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6597, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6619, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6555, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6595, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6634, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6602, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6538, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6618, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6570, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6557, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6564, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6537, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6572, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6603, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6554, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6548, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6536, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6548, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6517, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6597, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6534, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6587, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6518, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6542, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6550, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6517, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6544, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6561, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6544, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6532, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6584, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8529380148583577, 'train_f1': 0.8632287640621853, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 494, 'train_macro_f1': 0.8525368515612076, 'train_micro_f1': 0.8533120757045876, 'val_auc': 0.8364274091149161, 'val_f1': 0.8512306004075875, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 494, 'val_macro_f1': 0.8358328971763576, 'val_micro_f1': 0.8372770919067215, 'test_auc': 0.8358681277158511, 'test_f1': 0.8458787324295101, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 494, 'test_macro_f1': 0.8357229490068101, 'test_micro_f1': 0.8363507904265653}
loss tensor(0.6640, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6547, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6542, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6493, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6569, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6514, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6565, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6492, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6546, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6519, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6584, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6495, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6508, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6486, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6507, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6487, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6469, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6502, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6498, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6493, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6499, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6469, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6484, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6472, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6528, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6502, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6509, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6496, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6552, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6472, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6521, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8552063540242795, 'train_f1': 0.8644186964855, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 525, 'train_macro_f1': 0.8545328559072132, 'train_micro_f1': 0.8552046903929232, 'val_auc': 0.8380476363199011, 'val_f1': 0.8517935808684707, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 525, 'val_macro_f1': 0.8371628039986664, 'val_micro_f1': 0.838477366255144, 'test_auc': 0.837430988517329, 'test_f1': 0.8460508701472558, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 525, 'test_macro_f1': 0.8369958857936577, 'test_micro_f1': 0.837498896052283}
loss tensor(0.6480, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6473, grad_fn=<BinaryCrossEntropyBackward0>)
loss  26%|██▋       | 528/2001 [52:57<2:28:58,  6.07s/it] 26%|██▋       | 529/2001 [53:03<2:28:46,  6.06s/it] 26%|██▋       | 530/2001 [53:09<2:28:17,  6.05s/it] 27%|██▋       | 531/2001 [53:15<2:28:24,  6.06s/it] 27%|██▋       | 532/2001 [53:21<2:28:13,  6.05s/it] 27%|██▋       | 533/2001 [53:27<2:27:39,  6.04s/it] 27%|██▋       | 534/2001 [53:33<2:27:32,  6.03s/it] 27%|██▋       | 535/2001 [53:39<2:27:32,  6.04s/it] 27%|██▋       | 536/2001 [53:45<2:27:01,  6.02s/it] 27%|██▋       | 537/2001 [53:51<2:27:26,  6.04s/it] 27%|██▋       | 538/2001 [53:57<2:27:21,  6.04s/it] 27%|██▋       | 539/2001 [54:03<2:27:40,  6.06s/it] 27%|██▋       | 540/2001 [54:09<2:27:36,  6.06s/it] 27%|██▋       | 541/2001 [54:15<2:27:13,  6.05s/it] 27%|██▋       | 542/2001 [54:21<2:27:27,  6.06s/it] 27%|██▋       | 543/2001 [54:27<2:27:49,  6.08s/it] 27%|██▋       | 544/2001 [54:33<2:26:59,  6.05s/it] 27%|██▋       | 545/2001 [54:40<2:27:20,  6.07s/it] 27%|██▋       | 546/2001 [54:46<2:27:05,  6.07s/it] 27%|██▋       | 547/2001 [54:52<2:26:14,  6.03s/it] 27%|██▋       | 548/2001 [54:58<2:26:08,  6.03s/it] 27%|██▋       | 549/2001 [55:04<2:26:01,  6.03s/it] 27%|██▋       | 550/2001 [55:10<2:25:47,  6.03s/it] 28%|██▊       | 551/2001 [55:16<2:25:59,  6.04s/it] 28%|██▊       | 552/2001 [55:22<2:27:05,  6.09s/it] 28%|██▊       | 553/2001 [55:28<2:27:20,  6.11s/it] 28%|██▊       | 554/2001 [55:34<2:27:00,  6.10s/it] 28%|██▊       | 555/2001 [55:40<2:28:21,  6.16s/it] 28%|██▊       | 556/2001 [55:47<2:28:03,  6.15s/it] 28%|██▊       | 557/2001 [55:53<2:28:04,  6.15s/it] 28%|██▊       | 558/2001 [55:59<2:27:35,  6.14s/it] 28%|██▊       | 559/2001 [56:05<2:27:19,  6.13s/it] 28%|██▊       | 560/2001 [56:11<2:26:50,  6.11s/it] 28%|██▊       | 561/2001 [56:17<2:26:12,  6.09s/it] 28%|██▊       | 562/2001 [56:23<2:24:38,  6.03s/it] 28%|██▊       | 563/2001 [56:29<2:24:36,  6.03s/it] 28%|██▊       | 564/2001 [56:35<2:24:44,  6.04s/it] 28%|██▊       | 565/2001 [56:41<2:24:36,  6.04s/it] 28%|██▊       | 566/2001 [56:47<2:24:45,  6.05s/it] 28%|██▊       | 567/2001 [56:53<2:25:31,  6.09s/it] 28%|██▊       | 568/2001 [56:59<2:25:15,  6.08s/it] 28%|██▊       | 569/2001 [57:05<2:24:48,  6.07s/it] 28%|██▊       | 570/2001 [57:11<2:24:19,  6.05s/it] 29%|██▊       | 571/2001 [57:18<2:24:00,  6.04s/it] 29%|██▊       | 572/2001 [57:24<2:23:37,  6.03s/it] 29%|██▊       | 573/2001 [57:30<2:23:21,  6.02s/it] 29%|██▊       | 574/2001 [57:35<2:22:54,  6.01s/it] 29%|██▊       | 575/2001 [57:42<2:23:16,  6.03s/it] 29%|██▉       | 576/2001 [57:48<2:23:28,  6.04s/it] 29%|██▉       | 577/2001 [57:54<2:23:18,  6.04s/it] 29%|██▉       | 578/2001 [58:00<2:23:07,  6.03s/it] 29%|██▉       | 579/2001 [58:06<2:22:35,  6.02s/it] 29%|██▉       | 580/2001 [58:12<2:22:22,  6.01s/it] 29%|██▉       | 581/2001 [58:18<2:22:08,  6.01s/it] 29%|██▉       | 582/2001 [58:24<2:22:15,  6.02s/it] 29%|██▉       | 583/2001 [58:30<2:21:18,  5.98s/it] 29%|██▉       | 584/2001 [58:36<2:21:47,  6.00s/it] 29%|██▉       | 585/2001 [58:42<2:21:52,  6.01s/it] 29%|██▉       | 586/2001 [58:48<2:21:54,  6.02s/it] 29%|██▉       | 587/2001 [58:54<2:21:46,  6.02s/it] 29%|██▉       | 588/2001 [59:00<2:22:24,  6.05s/it] 29%|██▉       | 589/2001 [59:06<2:23:02,  6.08s/it] 29%|██▉       | 590/2001 [59:12<2:22:44,  6.07s/it] 30%|██▉       | 591/2001 [59:18<2:22:29,  6.06s/it] 30%|██▉       | 592/2001 [59:24<2:22:12,  6.06s/it] 30%|██▉       | 593/2001 [59:30<2:21:35,  6.03s/it] 30%|██▉       | 594/2001 [59:36<2:21:59,  6.05s/it] 30%|██▉       | 595/2001 [59:42<2:21:47,  6.05s/it] 30%|██▉       | 596/2001 [59:48<2:21:50,  6.06s/it] 30%|██▉       | 597/2001 [59:54<2:21:29,  6.05s/it] 30%|██▉       | 598/2001 [1:00:00<2:21:02,  6.03s/it] 30%|██▉       | 599/2001 [1:00:06<2:20:49,  6.03s/it] 30%|██▉       | 600/2001 [1:00:12<2:20:31,  6.02s/it] 30%|███       | 601/2001 [1:00:18<2:20:09,  6.01s/it] 30%|███       | 602/2001 [1:00:25<2:23:08,  6.14s/it] 30%|███       | 603/2001 [1:00:31<2:22:40,  6.12s/it] 30%|███       | 604/2001 [1:00:37<2:23:07,  6.15s/it] 30%|███       | 605/2001 [1:00:43<2:23:05,  6.15s/it] 30%|███       | 606/2001 [1:00:49<2:22:57,  6.15s/it] 30%|███       | 607/2001 [1:00:56<2:22:51,  6.15s/it] 30%|███       | 608/2001 [1:01:02<2:22:48,  6.15s/it] 30%|███       | 609/2001 [1:01:08<2:22:16,  6.13s/it] 30%|███       | 610/2001 [1:01:14<2:22:23,  6.14s/it] 31%|███       | 611/2001 [1:01:20<2:21:43,  6.12s/it] 31%|███       | 612/2001 [1:01:26<2:20:41,  6.08s/it] 31%|███       | 613/2001 [1:01:32<2:20:14,  6.06s/it] 31%|███       | 614/2001 [1:01:38<2:20:05,  6.06s/it] 31%|███       | 615/2001 [1:01:44<2:20:05,  6.06s/it] 31%|███       | 616/2001 [1:01:50<2:19:31,  6.04s/it] 31%|███       | 617/2001 [1:01:56<2:19:29,  6.05s/it] 31%|███       | 618/2001 [1:02:02<2:19:25,  6.05s/it] 31%|███       | 619/2001 [1:02:08<2:18:47,  6.03s/it] 31%|███       | 620/2001 [1:02:14<2:17:18,  5.97s/it] 31%|███       | 621/2001 [1:02:20<2:16:47,  5.95s/it] 31%|███       | 622/2001 [1:02:26<2:17:13,  5.97s/it] 31%|███       | 623/2001 [1:02:32<2:17:34,  5.99s/it] 31%|███       | 624/2001 [1:02:38<2:17:47,  6.00s/it] 31%|███       | 625/2001 [1:02:44<2:17:31,  6.00s/it] 31%|███▏      | 626/2001 [1:02:50<2:17:25,  6.00s/it] 31%|███▏      | 627/2001 [1:02:56<2:17:27,  6.00s/it] 31%|███▏      | 628/2001 [1:03:02<2:17:12,  6.00s/it] 31%|███▏      | 629/2001 [1:03:08<2:17:17,  6.00s/it] 31%|███▏      | 630/2001 [1:03:14<2:16:47,  5.99s/it] 32%|███▏      | 631/2001 [1:03:20<2:16:59,  6.00s/it] 32%|███▏      | 632/2001 [1:03:26<2:17:06,  6.01s/it] 32%|███▏      | 633/2001 [1:03:32<2:18:07,  6.06s/it] 32%|███▏      | 634/2001 [1:03:38<2:17:32,  6.04s/it] 32%|███▏      | 635/2001 [1:03:44<2:17:17,  6.03s/it] 32%|███▏      | 636/2001 [1:03:50<2:17:27,  6.04s/it] 32%|███▏      | 637/2001 [1:03:56<2:17:19,  6.04s/it] 32%|███▏      | 638/2001 [1:04:02<2:17:42,  6.06s/it] 32%|███▏      | 639/2001 [1:04:09<2:17:52,  6.07s/it] 32%|███▏      | 640/2001 [1:04:15<2:17:40,  6.07s/it] 32%|███▏      | 641/2001 [1:04:21<2:17:55,  6.09s/it] 32%|███▏      | 642/2001 [1:04:27<2:17:14,  6.06s/it] 32%|███▏      | 643/2001 [1:04:33<2:17:16,  6.07s/it] 32%|███▏      | 644/2001 [1:04:39<2:16:37,  6.04s/it] 32%|███▏      | 645/2001 [1:04:45<2:16:16,  6.03s/it] 32%|███▏      | 646/2001 [1:04:51<2:16:10,  6.03s/it]tensor(0.6508, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6466, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6494, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6465, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6532, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6613, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6462, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6556, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6477, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6459, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6452, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6439, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6440, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6450, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6450, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6474, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6442, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6541, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6632, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6507, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6562, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6476, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6592, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6486, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6553, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6505, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6633, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6510, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6538, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6521, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6539, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6480, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6494, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6460, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6508, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6479, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6497, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6425, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6465, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6477, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6459, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6473, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6463, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6444, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6564, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6468, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6514, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6464, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6496, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6417, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6427, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6431, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6421, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6455, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6422, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6498, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6432, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6452, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6438, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6455, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6428, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8572073650082566, 'train_f1': 0.8671985883616556, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 588, 'train_macro_f1': 0.8568058954851179, 'train_micro_f1': 0.8575601728039498, 'val_auc': 0.8380539351566841, 'val_f1': 0.8529365700861393, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 588, 'val_macro_f1': 0.8375309863122493, 'val_micro_f1': 0.8389917695473251, 'test_auc': 0.8388930873060857, 'test_f1': 0.8484091287689489, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 588, 'test_macro_f1': 0.8386782485950008, 'test_micro_f1': 0.8392652123995408}
loss tensor(0.6420, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6390, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6414, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6397, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6401, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6450, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6393, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6395, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6361, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6405, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6403, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6418, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6381, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6432, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6412, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6367, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6460, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6419, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6398, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6393, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6383, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6414, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6391, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6430, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6429, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6405, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6425, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6380, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6411, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6390, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6417, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6434, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6378, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6388, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6393, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6402, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6352, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6444, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6384, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6388, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6387, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6383, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6344, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6413, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6363, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6369, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6433, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8573778823534399, 'train_f1': 0.8684393813626433, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 635, 'train_macro_f1': 0.8572970428775973, 'train_micro_f1': 0.8581670438181445, 'val_auc': 0.8383713727613578, 'val_f1': 0.854426433915212, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 635, 'val_macro_f1': 0.8382269364698012, 'val_micro_f1': 0.8398491083676269, 'test_auc': 0.8380722967441274, 'test_f1': 0.8485401459854015, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 635, 'test_macro_f1': 0.8380566641164024, 'test_micro_f1': 0.8387353174953635}
loss tensor(0.6370, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6348, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6380, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6387, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6337, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6336, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6368, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6374, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6335, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6388, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6366, grad_fn=<BinaryCrossEntropyBackward0>)
loss  32%|███▏      | 647/2001 [1:04:57<2:16:14,  6.04s/it] 32%|███▏      | 648/2001 [1:05:03<2:15:59,  6.03s/it] 32%|███▏      | 649/2001 [1:05:09<2:16:15,  6.05s/it] 32%|███▏      | 650/2001 [1:05:15<2:16:11,  6.05s/it] 33%|███▎      | 651/2001 [1:05:21<2:15:45,  6.03s/it] 33%|███▎      | 652/2001 [1:05:27<2:15:17,  6.02s/it] 33%|███▎      | 653/2001 [1:05:33<2:15:11,  6.02s/it] 33%|███▎      | 654/2001 [1:05:39<2:14:56,  6.01s/it] 33%|███▎      | 655/2001 [1:05:45<2:14:33,  6.00s/it] 33%|███▎      | 656/2001 [1:05:51<2:14:12,  5.99s/it] 33%|███▎      | 657/2001 [1:05:57<2:13:54,  5.98s/it] 33%|███▎      | 658/2001 [1:06:03<2:13:50,  5.98s/it] 33%|███▎      | 659/2001 [1:06:09<2:13:43,  5.98s/it] 33%|███▎      | 660/2001 [1:06:15<2:13:36,  5.98s/it] 33%|███▎      | 661/2001 [1:06:21<2:13:33,  5.98s/it] 33%|███▎      | 662/2001 [1:06:27<2:13:21,  5.98s/it] 33%|███▎      | 663/2001 [1:06:33<2:13:12,  5.97s/it] 33%|███▎      | 664/2001 [1:06:39<2:13:11,  5.98s/it] 33%|███▎      | 665/2001 [1:06:45<2:13:14,  5.98s/it] 33%|███▎      | 666/2001 [1:06:51<2:13:01,  5.98s/it] 33%|███▎      | 667/2001 [1:06:57<2:13:09,  5.99s/it] 33%|███▎      | 668/2001 [1:07:03<2:12:56,  5.98s/it] 33%|███▎      | 669/2001 [1:07:09<2:12:35,  5.97s/it] 33%|███▎      | 670/2001 [1:07:15<2:12:33,  5.98s/it] 34%|███▎      | 671/2001 [1:07:21<2:12:27,  5.98s/it] 34%|███▎      | 672/2001 [1:07:27<2:12:39,  5.99s/it] 34%|███▎      | 673/2001 [1:07:33<2:12:07,  5.97s/it] 34%|███▎      | 674/2001 [1:07:38<2:11:50,  5.96s/it] 34%|███▎      | 675/2001 [1:07:44<2:11:40,  5.96s/it] 34%|███▍      | 676/2001 [1:07:50<2:11:38,  5.96s/it] 34%|███▍      | 677/2001 [1:07:56<2:11:27,  5.96s/it] 34%|███▍      | 678/2001 [1:08:02<2:11:28,  5.96s/it] 34%|███▍      | 679/2001 [1:08:08<2:11:19,  5.96s/it] 34%|███▍      | 680/2001 [1:08:14<2:11:06,  5.96s/it] 34%|███▍      | 681/2001 [1:08:20<2:11:01,  5.96s/it] 34%|███▍      | 682/2001 [1:08:26<2:09:59,  5.91s/it] 34%|███▍      | 683/2001 [1:08:32<2:09:43,  5.91s/it] 34%|███▍      | 684/2001 [1:08:38<2:10:06,  5.93s/it] 34%|███▍      | 685/2001 [1:08:44<2:09:46,  5.92s/it] 34%|███▍      | 686/2001 [1:08:50<2:09:15,  5.90s/it] 34%|███▍      | 687/2001 [1:08:56<2:09:20,  5.91s/it] 34%|███▍      | 688/2001 [1:09:02<2:09:46,  5.93s/it] 34%|███▍      | 689/2001 [1:09:07<2:09:54,  5.94s/it] 34%|███▍      | 690/2001 [1:09:13<2:09:21,  5.92s/it] 35%|███▍      | 691/2001 [1:09:19<2:09:48,  5.95s/it] 35%|███▍      | 692/2001 [1:09:25<2:09:58,  5.96s/it] 35%|███▍      | 693/2001 [1:09:31<2:10:13,  5.97s/it] 35%|███▍      | 694/2001 [1:09:37<2:09:50,  5.96s/it] 35%|███▍      | 695/2001 [1:09:43<2:10:13,  5.98s/it] 35%|███▍      | 696/2001 [1:09:49<2:09:05,  5.94s/it] 35%|███▍      | 697/2001 [1:09:55<2:08:11,  5.90s/it] 35%|███▍      | 698/2001 [1:10:01<2:08:53,  5.94s/it] 35%|███▍      | 699/2001 [1:10:07<2:09:05,  5.95s/it] 35%|███▍      | 700/2001 [1:10:13<2:08:39,  5.93s/it] 35%|███▌      | 701/2001 [1:10:19<2:08:14,  5.92s/it] 35%|███▌      | 702/2001 [1:10:25<2:08:24,  5.93s/it] 35%|███▌      | 703/2001 [1:10:31<2:09:01,  5.96s/it] 35%|███▌      | 704/2001 [1:10:37<2:08:57,  5.97s/it] 35%|███▌      | 705/2001 [1:10:42<2:07:24,  5.90s/it] 35%|███▌      | 706/2001 [1:10:48<2:06:25,  5.86s/it] 35%|███▌      | 707/2001 [1:10:54<2:07:09,  5.90s/it] 35%|███▌      | 708/2001 [1:11:00<2:07:23,  5.91s/it] 35%|███▌      | 709/2001 [1:11:06<2:07:42,  5.93s/it] 35%|███▌      | 710/2001 [1:11:12<2:07:54,  5.94s/it] 36%|███▌      | 711/2001 [1:11:18<2:07:52,  5.95s/it] 36%|███▌      | 712/2001 [1:11:24<2:07:58,  5.96s/it] 36%|███▌      | 713/2001 [1:11:30<2:08:08,  5.97s/it] 36%|███▌      | 714/2001 [1:11:36<2:08:07,  5.97s/it] 36%|███▌      | 715/2001 [1:11:42<2:08:43,  6.01s/it] 36%|███▌      | 716/2001 [1:11:48<2:08:37,  6.01s/it] 36%|███▌      | 717/2001 [1:11:54<2:08:29,  6.00s/it] 36%|███▌      | 718/2001 [1:12:00<2:08:18,  6.00s/it] 36%|███▌      | 719/2001 [1:12:06<2:08:12,  6.00s/it] 36%|███▌      | 720/2001 [1:12:12<2:07:58,  5.99s/it] 36%|███▌      | 721/2001 [1:12:18<2:07:33,  5.98s/it] 36%|███▌      | 722/2001 [1:12:24<2:08:06,  6.01s/it] 36%|███▌      | 723/2001 [1:12:30<2:08:16,  6.02s/it] 36%|███▌      | 724/2001 [1:12:36<2:08:50,  6.05s/it] 36%|███▌      | 725/2001 [1:12:42<2:08:29,  6.04s/it] 36%|███▋      | 726/2001 [1:12:48<2:08:05,  6.03s/it] 36%|███▋      | 727/2001 [1:12:54<2:07:49,  6.02s/it] 36%|███▋      | 728/2001 [1:13:00<2:07:32,  6.01s/it] 36%|███▋      | 729/2001 [1:13:06<2:07:26,  6.01s/it] 36%|███▋      | 730/2001 [1:13:12<2:07:42,  6.03s/it] 37%|███▋      | 731/2001 [1:13:18<2:07:32,  6.03s/it] 37%|███▋      | 732/2001 [1:13:24<2:07:21,  6.02s/it] 37%|███▋      | 733/2001 [1:13:30<2:07:12,  6.02s/it] 37%|███▋      | 734/2001 [1:13:36<2:07:08,  6.02s/it] 37%|███▋      | 735/2001 [1:13:42<2:06:58,  6.02s/it] 37%|███▋      | 736/2001 [1:13:48<2:06:52,  6.02s/it] 37%|███▋      | 737/2001 [1:13:54<2:06:08,  5.99s/it] 37%|███▋      | 738/2001 [1:14:00<2:06:05,  5.99s/it] 37%|███▋      | 739/2001 [1:14:06<2:06:13,  6.00s/it] 37%|███▋      | 740/2001 [1:14:13<2:07:18,  6.06s/it] 37%|███▋      | 741/2001 [1:14:19<2:06:55,  6.04s/it] 37%|███▋      | 742/2001 [1:14:25<2:06:07,  6.01s/it] 37%|███▋      | 743/2001 [1:14:31<2:05:51,  6.00s/it] 37%|███▋      | 744/2001 [1:14:37<2:05:52,  6.01s/it] 37%|███▋      | 745/2001 [1:14:43<2:05:58,  6.02s/it]tensor(0.6377, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6424, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6375, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6426, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6365, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6413, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6382, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6391, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6356, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6465, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6357, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6391, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6338, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6392, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6339, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6450, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6418, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6406, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6538, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6322, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6422, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6326, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6465, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6355, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6445, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6356, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6394, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6357, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6359, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6338, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6351, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6375, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6378, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6329, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6324, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6332, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6312, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6329, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8613024997746126, 'train_f1': 0.8705737649783313, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 684, 'train_macro_f1': 0.8607679443107275, 'train_micro_f1': 0.8614585476239457, 'val_auc': 0.838938030379884, 'val_f1': 0.8536967418546366, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 684, 'val_macro_f1': 0.8384014012303487, 'val_micro_f1': 0.8398491083676269, 'test_auc': 0.8385477674916557, 'test_f1': 0.8477771290349488, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 684, 'test_macro_f1': 0.8382640923395632, 'test_micro_f1': 0.8388236333127262}
loss tensor(0.6306, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8607550261281679, 'train_f1': 0.8695551659699077, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 685, 'train_macro_f1': 0.8600639246529078, 'train_micro_f1': 0.8607076733182473, 'val_auc': 0.839554009078882, 'val_f1': 0.8532788174241233, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 685, 'val_macro_f1': 0.8387034991927402, 'val_micro_f1': 0.8400205761316873, 'test_auc': 0.8392436551420115, 'test_f1': 0.8481963927855711, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 685, 'test_macro_f1': 0.8389060689326169, 'test_micro_f1': 0.8394418440342666}
loss tensor(0.6344, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6340, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8607672765456934, 'train_f1': 0.8704485285653992, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 687, 'train_macro_f1': 0.8603473405234412, 'train_micro_f1': 0.8610779674963999, 'val_auc': 0.8397728045226123, 'val_f1': 0.8541405269761605, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 687, 'val_macro_f1': 0.8391353164381559, 'val_micro_f1': 0.8405349794238683, 'test_auc': 0.8383840292209835, 'test_f1': 0.8478586902182969, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 687, 'test_macro_f1': 0.8381533210580399, 'test_micro_f1': 0.8387353174953635}
loss tensor(0.6327, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6296, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6308, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6297, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6275, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6289, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6295, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6310, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6293, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6289, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6299, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6283, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6319, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6304, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6261, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8626539251716798, 'train_f1': 0.8725897558640499, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 702, 'train_macro_f1': 0.8623533288710181, 'train_micro_f1': 0.8631145854762393, 'val_auc': 0.8421278564036352, 'val_f1': 0.8564263322884014, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 702, 'val_macro_f1': 0.8415364061139206, 'val_micro_f1': 0.8429355281207133, 'test_auc': 0.8400654953082689, 'test_f1': 0.8497254118821768, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 702, 'test_macro_f1': 0.8398984605515514, 'test_micro_f1': 0.8405016338426212}
loss tensor(0.6237, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6288, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6269, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6273, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6253, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6318, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6328, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6271, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6460, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6302, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6306, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6304, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6285, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6273, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6249, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6288, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6262, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6324, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6298, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6318, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6346, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6254, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6411, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6290, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6360, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6248, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6387, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6247, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6368, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6234, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6242, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6312, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6319, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6318, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6295, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6289, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6307, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6252, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6256, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6255, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6229, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6293, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6220, grad_fn=<BinaryCrossEntropyBackward0>)
loss  37%|███▋      | 746/2001 [1:14:48<2:05:05,  5.98s/it] 37%|███▋      | 747/2001 [1:14:55<2:05:19,  6.00s/it] 37%|███▋      | 748/2001 [1:15:01<2:05:29,  6.01s/it] 37%|███▋      | 749/2001 [1:15:07<2:05:52,  6.03s/it] 37%|███▋      | 750/2001 [1:15:13<2:06:09,  6.05s/it] 38%|███▊      | 751/2001 [1:15:19<2:05:55,  6.04s/it] 38%|███▊      | 752/2001 [1:15:25<2:04:59,  6.00s/it] 38%|███▊      | 753/2001 [1:15:31<2:05:06,  6.01s/it] 38%|███▊      | 754/2001 [1:15:37<2:04:57,  6.01s/it] 38%|███▊      | 755/2001 [1:15:43<2:06:44,  6.10s/it] 38%|███▊      | 756/2001 [1:15:49<2:08:34,  6.20s/it] 38%|███▊      | 757/2001 [1:15:56<2:08:40,  6.21s/it] 38%|███▊      | 758/2001 [1:16:02<2:08:36,  6.21s/it] 38%|███▊      | 759/2001 [1:16:08<2:08:48,  6.22s/it] 38%|███▊      | 760/2001 [1:16:14<2:07:45,  6.18s/it] 38%|███▊      | 761/2001 [1:16:20<2:07:55,  6.19s/it] 38%|███▊      | 762/2001 [1:16:26<2:06:55,  6.15s/it] 38%|███▊      | 763/2001 [1:16:33<2:06:15,  6.12s/it] 38%|███▊      | 764/2001 [1:16:39<2:05:53,  6.11s/it] 38%|███▊      | 765/2001 [1:16:45<2:06:05,  6.12s/it] 38%|███▊      | 766/2001 [1:16:51<2:05:34,  6.10s/it] 38%|███▊      | 767/2001 [1:16:57<2:05:14,  6.09s/it] 38%|███▊      | 768/2001 [1:17:03<2:04:41,  6.07s/it] 38%|███▊      | 769/2001 [1:17:09<2:04:26,  6.06s/it] 38%|███▊      | 770/2001 [1:17:15<2:04:20,  6.06s/it] 39%|███▊      | 771/2001 [1:17:21<2:04:14,  6.06s/it] 39%|███▊      | 772/2001 [1:17:27<2:04:19,  6.07s/it] 39%|███▊      | 773/2001 [1:17:33<2:04:20,  6.08s/it] 39%|███▊      | 774/2001 [1:17:40<2:05:52,  6.16s/it] 39%|███▊      | 775/2001 [1:17:46<2:05:16,  6.13s/it] 39%|███▉      | 776/2001 [1:17:52<2:04:35,  6.10s/it] 39%|███▉      | 777/2001 [1:17:58<2:05:06,  6.13s/it] 39%|███▉      | 778/2001 [1:18:04<2:05:01,  6.13s/it] 39%|███▉      | 779/2001 [1:18:10<2:05:12,  6.15s/it] 39%|███▉      | 780/2001 [1:18:16<2:05:38,  6.17s/it] 39%|███▉      | 781/2001 [1:18:23<2:05:52,  6.19s/it] 39%|███▉      | 782/2001 [1:18:29<2:04:58,  6.15s/it] 39%|███▉      | 783/2001 [1:18:35<2:04:13,  6.12s/it] 39%|███▉      | 784/2001 [1:18:41<2:03:40,  6.10s/it] 39%|███▉      | 785/2001 [1:18:47<2:03:02,  6.07s/it] 39%|███▉      | 786/2001 [1:18:53<2:02:59,  6.07s/it] 39%|███▉      | 787/2001 [1:18:59<2:03:11,  6.09s/it] 39%|███▉      | 788/2001 [1:19:05<2:02:55,  6.08s/it] 39%|███▉      | 789/2001 [1:19:11<2:02:26,  6.06s/it] 39%|███▉      | 790/2001 [1:19:17<2:02:16,  6.06s/it] 40%|███▉      | 791/2001 [1:19:23<2:01:59,  6.05s/it] 40%|███▉      | 792/2001 [1:19:29<2:01:29,  6.03s/it] 40%|███▉      | 793/2001 [1:19:35<2:01:17,  6.02s/it] 40%|███▉      | 794/2001 [1:19:41<2:01:26,  6.04s/it] 40%|███▉      | 795/2001 [1:19:47<2:01:35,  6.05s/it] 40%|███▉      | 796/2001 [1:19:53<2:01:18,  6.04s/it] 40%|███▉      | 797/2001 [1:19:59<2:01:15,  6.04s/it] 40%|███▉      | 798/2001 [1:20:05<2:00:54,  6.03s/it] 40%|███▉      | 799/2001 [1:20:11<2:00:40,  6.02s/it] 40%|███▉      | 800/2001 [1:20:17<2:00:30,  6.02s/it] 40%|████      | 801/2001 [1:20:23<2:00:28,  6.02s/it] 40%|████      | 802/2001 [1:20:30<2:00:54,  6.05s/it] 40%|████      | 803/2001 [1:20:36<2:00:47,  6.05s/it] 40%|████      | 804/2001 [1:20:42<2:01:04,  6.07s/it] 40%|████      | 805/2001 [1:20:48<2:01:15,  6.08s/it] 40%|████      | 806/2001 [1:20:54<2:00:51,  6.07s/it] 40%|████      | 807/2001 [1:21:00<2:00:37,  6.06s/it] 40%|████      | 808/2001 [1:21:06<2:00:29,  6.06s/it] 40%|████      | 809/2001 [1:21:12<2:01:32,  6.12s/it] 40%|████      | 810/2001 [1:21:18<2:01:27,  6.12s/it] 41%|████      | 811/2001 [1:21:24<2:01:07,  6.11s/it] 41%|████      | 812/2001 [1:21:30<2:00:26,  6.08s/it] 41%|████      | 813/2001 [1:21:36<1:59:32,  6.04s/it] 41%|████      | 814/2001 [1:21:42<1:59:26,  6.04s/it] 41%|████      | 815/2001 [1:21:48<1:59:17,  6.03s/it] 41%|████      | 816/2001 [1:21:54<1:59:02,  6.03s/it] 41%|████      | 817/2001 [1:22:00<1:58:40,  6.01s/it] 41%|████      | 818/2001 [1:22:06<1:58:27,  6.01s/it] 41%|████      | 819/2001 [1:22:12<1:58:31,  6.02s/it]tensor(0.6217, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6247, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6249, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6293, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6218, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6280, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6226, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6346, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6213, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6320, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6177, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6217, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6215, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6208, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6187, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6193, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6225, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6224, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6216, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6288, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6196, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6242, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8668264483008421, 'train_f1': 0.8727616559603069, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 767, 'train_macro_f1': 0.8653270790552408, 'train_micro_f1': 0.8657375025714873, 'val_auc': 0.8426465002474374, 'val_f1': 0.8534647171010806, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 767, 'val_macro_f1': 0.840917019756795, 'val_micro_f1': 0.8419067215363513, 'test_auc': 0.8387272498268152, 'test_f1': 0.8451204055766792, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 767, 'test_macro_f1': 0.8377854363467523, 'test_micro_f1': 0.8381171067738232}
loss tensor(0.6256, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6256, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6194, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6266, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6212, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6220, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6350, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6184, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6217, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6196, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6191, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6131, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8683523944475124, 'train_f1': 0.8744145284580553, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 779, 'train_macro_f1': 0.8669200551168145, 'train_micro_f1': 0.8673421106768154, 'val_auc': 0.8428868068130121, 'val_f1': 0.8539218799618925, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 779, 'val_macro_f1': 0.84123600520644, 'val_micro_f1': 0.8422496570644719, 'test_auc': 0.8438188802821338, 'test_f1': 0.8492964909306663, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 779, 'test_macro_f1': 0.8426976554948316, 'test_micro_f1': 0.8429744767287822}
loss tensor(0.6151, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6146, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6128, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6150, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8686363580525048, 'train_f1': 0.8790898869981134, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 783, 'train_macro_f1': 0.8686399974739801, 'train_micro_f1': 0.8694713022011932, 'val_auc': 0.8441350461098622, 'val_f1': 0.8602518265195087, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 783, 'val_macro_f1': 0.844195880761188, 'val_micro_f1': 0.8458504801097394, 'test_auc': 0.8437139198522157, 'test_f1': 0.8539214060686454, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 783, 'test_macro_f1': 0.8437218519383287, 'test_micro_f1': 0.8443875298065884}
loss tensor(0.6122, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6172, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6135, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6197, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6173, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6132, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6166, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6113, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6145, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6149, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6131, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6110, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6138, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6087, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6080, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6086, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6144, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8698405292912228, 'train_f1': 0.8790370498150385, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 800, 'train_macro_f1': 0.8694694650367176, 'train_micro_f1': 0.8701707467599259, 'val_auc': 0.8449635214158072, 'val_f1': 0.8595997498436523, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 800, 'val_macro_f1': 0.844568287981811, 'val_micro_f1': 0.8460219478737997, 'test_auc': 0.8433045741755358, 'test_f1': 0.8526228143213987, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 800, 'test_macro_f1': 0.8431034342385482, 'test_micro_f1': 0.8436810032676852}
loss tensor(0.6099, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6278, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6055, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6218, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6129, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6225, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6089, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8687910909110264, 'train_f1': 0.8778316142959941, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 807, 'train_macro_f1': 0.8683455028748717, 'train_micro_f1': 0.8690290063772886, 'val_auc': 0.8451266969422833, 'val_f1': 0.8590246197271445, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 807, 'val_macro_f1': 0.8444924498295264, 'val_micro_f1': 0.8458504801097394, 'test_auc': 0.84553708251989, 'test_f1': 0.8544029352901934, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 807, 'test_macro_f1': 0.8452604126422809, 'test_micro_f1': 0.8458005828843946}
loss tensor(0.6142, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8706188426436867, 'train_f1': 0.878053023786281, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 808, 'train_macro_f1': 0.8696848101443468, 'train_micro_f1': 0.8702221765068915, 'val_auc': 0.846323238239121, 'val_f1': 0.8582714488860801, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 808, 'val_macro_f1': 0.8450682455302003, 'val_micro_f1': 0.8461934156378601, 'test_auc': 0.845156076159288, 'test_f1': 0.8522163344267811, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 808, 'test_macro_f1': 0.8444404159816346, 'test_micro_f1': 0.8448291088934028}
loss tensor(0.6074, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6132, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6083, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6215, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6078, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6083, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6086, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6120, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6078, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6112, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6061, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6046, grad_fn=<BinaryCrossEntropyBackward0>)
 41%|████      | 820/2001 [1:22:18<1:58:09,  6.00s/it] 41%|████      | 821/2001 [1:22:24<1:58:09,  6.01s/it] 41%|████      | 822/2001 [1:22:31<1:58:30,  6.03s/it] 41%|████      | 823/2001 [1:22:37<1:58:22,  6.03s/it] 41%|████      | 824/2001 [1:22:43<1:58:15,  6.03s/it] 41%|████      | 825/2001 [1:22:49<1:58:08,  6.03s/it] 41%|████▏     | 826/2001 [1:22:55<1:58:05,  6.03s/it] 41%|████▏     | 827/2001 [1:23:01<1:57:54,  6.03s/it] 41%|████▏     | 828/2001 [1:23:07<1:57:55,  6.03s/it] 41%|████▏     | 829/2001 [1:23:13<1:58:42,  6.08s/it] 41%|████▏     | 830/2001 [1:23:19<1:58:46,  6.09s/it] 42%|████▏     | 831/2001 [1:23:25<1:58:32,  6.08s/it] 42%|████▏     | 832/2001 [1:23:31<1:58:14,  6.07s/it] 42%|████▏     | 833/2001 [1:23:37<1:58:07,  6.07s/it] 42%|████▏     | 834/2001 [1:23:43<1:58:05,  6.07s/it] 42%|████▏     | 835/2001 [1:23:49<1:58:02,  6.07s/it] 42%|████▏     | 836/2001 [1:23:55<1:57:50,  6.07s/it] 42%|████▏     | 837/2001 [1:24:01<1:57:13,  6.04s/it] 42%|████▏     | 838/2001 [1:24:08<1:57:51,  6.08s/it] 42%|████▏     | 839/2001 [1:24:14<1:58:44,  6.13s/it] 42%|████▏     | 840/2001 [1:24:20<2:00:10,  6.21s/it] 42%|████▏     | 841/2001 [1:24:27<2:02:00,  6.31s/it] 42%|████▏     | 842/2001 [1:24:33<2:03:06,  6.37s/it] 42%|████▏     | 843/2001 [1:24:40<2:04:03,  6.43s/it] 42%|████▏     | 844/2001 [1:24:46<2:04:29,  6.46s/it] 42%|████▏     | 845/2001 [1:24:53<2:05:02,  6.49s/it] 42%|████▏     | 846/2001 [1:25:00<2:05:38,  6.53s/it] 42%|████▏     | 847/2001 [1:25:06<2:05:36,  6.53s/it] 42%|████▏     | 848/2001 [1:25:13<2:05:35,  6.54s/it] 42%|████▏     | 849/2001 [1:25:19<2:05:43,  6.55s/it] 42%|████▏     | 850/2001 [1:25:26<2:05:22,  6.54s/it] 43%|████▎     | 851/2001 [1:25:32<2:04:56,  6.52s/it] 43%|████▎     | 852/2001 [1:25:39<2:04:24,  6.50s/it] 43%|████▎     | 853/2001 [1:25:45<2:05:57,  6.58s/it] 43%|████▎     | 854/2001 [1:25:52<2:05:44,  6.58s/it] 43%|████▎     | 855/2001 [1:25:59<2:05:27,  6.57s/it] 43%|████▎     | 856/2001 [1:26:05<2:04:36,  6.53s/it] 43%|████▎     | 857/2001 [1:26:11<2:04:26,  6.53s/it] 43%|████▎     | 858/2001 [1:26:18<2:01:49,  6.40s/it] 43%|████▎     | 859/2001 [1:26:24<1:59:28,  6.28s/it] 43%|████▎     | 860/2001 [1:26:29<1:56:35,  6.13s/it] 43%|████▎     | 861/2001 [1:26:35<1:54:17,  6.02s/it] 43%|████▎     | 862/2001 [1:26:41<1:53:26,  5.98s/it] 43%|████▎     | 863/2001 [1:26:47<1:52:55,  5.95s/it] 43%|████▎     | 864/2001 [1:26:53<1:54:55,  6.06s/it] 43%|████▎     | 865/2001 [1:26:59<1:54:55,  6.07s/it] 43%|████▎     | 866/2001 [1:27:05<1:54:25,  6.05s/it] 43%|████▎     | 867/2001 [1:27:11<1:52:34,  5.96s/it] 43%|████▎     | 868/2001 [1:27:17<1:52:05,  5.94s/it] 43%|████▎     | 869/2001 [1:27:23<1:52:11,  5.95s/it] 43%|████▎     | 870/2001 [1:27:29<1:52:39,  5.98s/it] 44%|████▎     | 871/2001 [1:27:35<1:52:46,  5.99s/it] 44%|████▎     | 872/2001 [1:27:41<1:52:19,  5.97s/it] 44%|████▎     | 873/2001 [1:27:47<1:51:49,  5.95s/it] 44%|████▎     | 874/2001 [1:27:53<1:52:36,  5.99s/it] 44%|████▎     | 875/2001 [1:27:59<1:52:11,  5.98s/it] 44%|████▍     | 876/2001 [1:28:05<1:53:24,  6.05s/it] 44%|████▍     | 877/2001 [1:28:11<1:53:42,  6.07s/it] 44%|████▍     | 878/2001 [1:28:17<1:52:28,  6.01s/it] 44%|████▍     | 879/2001 [1:28:23<1:51:46,  5.98s/it] 44%|████▍     | 880/2001 [1:28:29<1:50:38,  5.92s/it] 44%|████▍     | 881/2001 [1:28:34<1:49:13,  5.85s/it] 44%|████▍     | 882/2001 [1:28:40<1:49:34,  5.88s/it] 44%|████▍     | 883/2001 [1:28:46<1:49:50,  5.90s/it] 44%|████▍     | 884/2001 [1:28:52<1:50:01,  5.91s/it] 44%|████▍     | 885/2001 [1:28:58<1:50:27,  5.94s/it] 44%|████▍     | 886/2001 [1:29:04<1:50:42,  5.96s/it] 44%|████▍     | 887/2001 [1:29:10<1:50:46,  5.97s/it] 44%|████▍     | 888/2001 [1:29:16<1:50:43,  5.97s/it] 44%|████▍     | 889/2001 [1:29:22<1:50:43,  5.97s/it] 44%|████▍     | 890/2001 [1:29:28<1:51:16,  6.01s/it] 45%|████▍     | 891/2001 [1:29:34<1:50:55,  6.00s/it] 45%|████▍     | 892/2001 [1:29:40<1:50:38,  5.99s/it] 45%|████▍     | 893/2001 [1:29:46<1:50:33,  5.99s/it] 45%|████▍     | 894/2001 [1:29:52<1:50:22,  5.98s/it] 45%|████▍     | 895/2001 [1:29:58<1:50:16,  5.98s/it] 45%|████▍     | 896/2001 [1:30:04<1:50:01,  5.97s/it] 45%|████▍     | 897/2001 [1:30:10<1:49:25,  5.95s/it] 45%|████▍     | 898/2001 [1:30:16<1:49:33,  5.96s/it] 45%|████▍     | 899/2001 [1:30:22<1:49:31,  5.96s/it] 45%|████▍     | 900/2001 [1:30:28<1:49:16,  5.96s/it] 45%|████▌     | 901/2001 [1:30:34<1:49:28,  5.97s/it] 45%|████▌     | 902/2001 [1:30:40<1:47:55,  5.89s/it] 45%|████▌     | 903/2001 [1:30:45<1:46:00,  5.79s/it] 45%|████▌     | 904/2001 [1:30:51<1:46:20,  5.82s/it] 45%|████▌     | 905/2001 [1:30:57<1:46:54,  5.85s/it] 45%|████▌     | 906/2001 [1:31:03<1:47:18,  5.88s/it] 45%|████▌     | 907/2001 [1:31:09<1:47:36,  5.90s/it] 45%|████▌     | 908/2001 [1:31:15<1:47:47,  5.92s/it] 45%|████▌     | 909/2001 [1:31:21<1:47:56,  5.93s/it] 45%|████▌     | 910/2001 [1:31:27<1:47:59,  5.94s/it] 46%|████▌     | 911/2001 [1:31:33<1:47:10,  5.90s/it] 46%|████▌     | 912/2001 [1:31:39<1:47:37,  5.93s/it] 46%|████▌     | 913/2001 [1:31:44<1:47:27,  5.93s/it] 46%|████▌     | 914/2001 [1:31:50<1:47:30,  5.93s/it] 46%|████▌     | 915/2001 [1:31:56<1:47:30,  5.94s/it] 46%|████▌     | 916/2001 [1:32:02<1:47:30,  5.95s/it] 46%|████▌     | 917/2001 [1:32:08<1:46:51,  5.91s/it] 46%|████▌     | 918/2001 [1:32:14<1:47:59,  5.98s/it] 46%|████▌     | 919/2001 [1:32:20<1:47:29,  5.96s/it]{'train_auc': 0.8702849974714072, 'train_f1': 0.879666858127513, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 820, 'train_macro_f1': 0.8699845737625784, 'train_micro_f1': 0.8707056161283686, 'val_auc': 0.8468872812461523, 'val_f1': 0.8612978889757623, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 820, 'val_macro_f1': 0.8464773749300902, 'val_micro_f1': 0.8479080932784636, 'test_auc': 0.843744358376892, 'test_f1': 0.8533178114086147, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 820, 'test_macro_f1': 0.8436080582466803, 'test_micro_f1': 0.8442108981718626}
loss tensor(0.6086, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6098, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6073, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6104, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6069, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6047, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6067, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6109, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.872020531209143, 'train_f1': 0.8806093437836175, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 828, 'train_macro_f1': 0.8714998716083973, 'train_micro_f1': 0.8721456490434067, 'val_auc': 0.8479484569751417, 'val_f1': 0.861842105263158, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 828, 'val_macro_f1': 0.8473983253588517, 'val_micro_f1': 0.8487654320987654, 'test_auc': 0.8425929424606922, 'test_f1': 0.8516882034180909, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 828, 'test_macro_f1': 0.8423308165714997, 'test_micro_f1': 0.8428861609114192}
loss tensor(0.6056, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.872726475786513, 'train_f1': 0.8806589912808902, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 829, 'train_macro_f1': 0.8720025057347691, 'train_micro_f1': 0.8725879448673113, 'val_auc': 0.8485075084511374, 'val_f1': 0.8618957940991839, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 829, 'val_macro_f1': 0.8478035281909374, 'val_micro_f1': 0.8491083676268861, 'test_auc': 0.8444203035455634, 'test_f1': 0.8526976160602259, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 829, 'test_macro_f1': 0.8439898144841397, 'test_micro_f1': 0.8444758456239513}
loss tensor(0.6044, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6089, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6022, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8727603637531416, 'train_f1': 0.8811167297967659, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 832, 'train_macro_f1': 0.8721789881980224, 'train_micro_f1': 0.872803949804567, 'val_auc': 0.8502402827963792, 'val_f1': 0.8634651600753295, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 832, 'val_macro_f1': 0.8495330335524041, 'val_micro_f1': 0.8508230452674898, 'test_auc': 0.844740432856813, 'test_f1': 0.8531059275980268, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 832, 'test_macro_f1': 0.8443349010942872, 'test_micro_f1': 0.8448291088934028}
loss tensor(0.6015, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6026, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6005, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6005, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6033, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6005, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6000, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6065, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5982, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5996, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6016, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6012, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6007, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6030, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5985, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5990, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5989, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6017, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6016, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6046, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5983, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5990, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6013, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5989, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5954, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5960, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6025, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6026, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5958, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6020, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5984, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5973, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5953, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5954, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5951, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5952, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5968, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5946, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5960, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5915, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6038, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5887, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5967, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5936, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5960, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5944, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5925, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5947, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5915, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5904, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5912, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5931, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5919, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5927, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5988, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5899, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5930, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5901, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5920, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5929, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5919, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5894, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5996, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5917, grad_fn=<BinaryCrossEntropyBackward0>)
loss  46%|████▌     | 920/2001 [1:32:26<1:47:07,  5.95s/it] 46%|████▌     | 921/2001 [1:32:32<1:47:14,  5.96s/it] 46%|████▌     | 922/2001 [1:32:38<1:47:16,  5.97s/it] 46%|████▌     | 923/2001 [1:32:44<1:47:53,  6.01s/it] 46%|████▌     | 924/2001 [1:32:51<1:51:57,  6.24s/it] 46%|████▌     | 925/2001 [1:32:57<1:52:23,  6.27s/it] 46%|████▋     | 926/2001 [1:33:04<1:53:43,  6.35s/it] 46%|████▋     | 927/2001 [1:33:10<1:53:39,  6.35s/it] 46%|████▋     | 928/2001 [1:33:17<1:53:50,  6.37s/it] 46%|████▋     | 929/2001 [1:33:23<1:54:37,  6.42s/it] 46%|████▋     | 930/2001 [1:33:30<1:55:29,  6.47s/it] 47%|████▋     | 931/2001 [1:33:36<1:56:04,  6.51s/it] 47%|████▋     | 932/2001 [1:33:43<1:56:00,  6.51s/it] 47%|████▋     | 933/2001 [1:33:49<1:55:46,  6.50s/it] 47%|████▋     | 934/2001 [1:33:56<1:55:41,  6.51s/it] 47%|████▋     | 935/2001 [1:34:02<1:55:08,  6.48s/it] 47%|████▋     | 936/2001 [1:34:08<1:53:21,  6.39s/it] 47%|████▋     | 937/2001 [1:34:15<1:51:46,  6.30s/it] 47%|████▋     | 938/2001 [1:34:21<1:50:52,  6.26s/it] 47%|████▋     | 939/2001 [1:34:27<1:50:06,  6.22s/it] 47%|████▋     | 940/2001 [1:34:33<1:49:42,  6.20s/it] 47%|████▋     | 941/2001 [1:34:39<1:49:18,  6.19s/it] 47%|████▋     | 942/2001 [1:34:45<1:49:08,  6.18s/it] 47%|████▋     | 943/2001 [1:34:51<1:48:44,  6.17s/it] 47%|████▋     | 944/2001 [1:34:58<1:48:38,  6.17s/it] 47%|████▋     | 945/2001 [1:35:04<1:48:17,  6.15s/it] 47%|████▋     | 946/2001 [1:35:10<1:48:03,  6.15s/it] 47%|████▋     | 947/2001 [1:35:16<1:48:13,  6.16s/it] 47%|████▋     | 948/2001 [1:35:22<1:48:03,  6.16s/it] 47%|████▋     | 949/2001 [1:35:28<1:47:49,  6.15s/it] 47%|████▋     | 950/2001 [1:35:34<1:47:19,  6.13s/it] 48%|████▊     | 951/2001 [1:35:40<1:46:52,  6.11s/it] 48%|████▊     | 952/2001 [1:35:47<1:46:36,  6.10s/it] 48%|████▊     | 953/2001 [1:35:53<1:46:07,  6.08s/it] 48%|████▊     | 954/2001 [1:35:59<1:45:57,  6.07s/it] 48%|████▊     | 955/2001 [1:36:05<1:45:39,  6.06s/it] 48%|████▊     | 956/2001 [1:36:11<1:45:26,  6.05s/it] 48%|████▊     | 957/2001 [1:36:17<1:45:19,  6.05s/it] 48%|████▊     | 958/2001 [1:36:23<1:45:27,  6.07s/it] 48%|████▊     | 959/2001 [1:36:29<1:44:32,  6.02s/it] 48%|████▊     | 960/2001 [1:36:35<1:45:41,  6.09s/it] 48%|████▊     | 961/2001 [1:36:41<1:45:19,  6.08s/it] 48%|████▊     | 962/2001 [1:36:47<1:44:41,  6.05s/it] 48%|████▊     | 963/2001 [1:36:53<1:44:49,  6.06s/it] 48%|████▊     | 964/2001 [1:36:59<1:45:10,  6.08s/it] 48%|████▊     | 965/2001 [1:37:05<1:44:54,  6.08s/it] 48%|████▊     | 966/2001 [1:37:12<1:45:15,  6.10s/it] 48%|████▊     | 967/2001 [1:37:18<1:45:13,  6.11s/it] 48%|████▊     | 968/2001 [1:37:24<1:48:34,  6.31s/it] 48%|████▊     | 969/2001 [1:37:31<1:50:39,  6.43s/it] 48%|████▊     | 970/2001 [1:37:38<1:51:00,  6.46s/it] 49%|████▊     | 971/2001 [1:37:44<1:50:49,  6.46s/it] 49%|████▊     | 972/2001 [1:37:50<1:49:51,  6.41s/it] 49%|████▊     | 973/2001 [1:37:56<1:48:09,  6.31s/it] 49%|████▊     | 974/2001 [1:38:03<1:47:24,  6.28s/it] 49%|████▊     | 975/2001 [1:38:09<1:46:36,  6.23s/it] 49%|████▉     | 976/2001 [1:38:15<1:45:14,  6.16s/it] 49%|████▉     | 977/2001 [1:38:21<1:46:02,  6.21s/it] 49%|████▉     | 978/2001 [1:38:27<1:46:09,  6.23s/it] 49%|████▉     | 979/2001 [1:38:34<1:46:25,  6.25s/it] 49%|████▉     | 980/2001 [1:38:40<1:45:40,  6.21s/it] 49%|████▉     | 981/2001 [1:38:46<1:46:04,  6.24s/it] 49%|████▉     | 982/2001 [1:38:52<1:46:18,  6.26s/it] 49%|████▉     | 983/2001 [1:38:59<1:46:19,  6.27s/it] 49%|████▉     | 984/2001 [1:39:05<1:46:05,  6.26s/it] 49%|████▉     | 985/2001 [1:39:11<1:47:17,  6.34s/it] 49%|████▉     | 986/2001 [1:39:18<1:47:51,  6.38s/it] 49%|████▉     | 987/2001 [1:39:24<1:46:23,  6.30s/it] 49%|████▉     | 988/2001 [1:39:30<1:43:50,  6.15s/it] 49%|████▉     | 989/2001 [1:39:36<1:42:26,  6.07s/it] 49%|████▉     | 990/2001 [1:39:42<1:41:35,  6.03s/it] 50%|████▉     | 991/2001 [1:39:48<1:40:50,  5.99s/it] 50%|████▉     | 992/2001 [1:39:54<1:40:35,  5.98s/it] 50%|████▉     | 993/2001 [1:39:59<1:40:09,  5.96s/it] 50%|████▉     | 994/2001 [1:40:05<1:39:39,  5.94s/it] 50%|████▉     | 995/2001 [1:40:11<1:39:29,  5.93s/it] 50%|████▉     | 996/2001 [1:40:17<1:38:57,  5.91s/it] 50%|████▉     | 997/2001 [1:40:23<1:37:16,  5.81s/it] 50%|████▉     | 998/2001 [1:40:28<1:37:02,  5.80s/it] 50%|████▉     | 999/2001 [1:40:35<1:38:01,  5.87s/it] 50%|████▉     | 1000/2001 [1:40:40<1:37:44,  5.86s/it] 50%|█████     | 1001/2001 [1:40:46<1:37:59,  5.88s/it] 50%|█████     | 1002/2001 [1:40:52<1:37:24,  5.85s/it] 50%|█████     | 1003/2001 [1:40:58<1:36:55,  5.83s/it] 50%|█████     | 1004/2001 [1:41:03<1:35:48,  5.77s/it] 50%|█████     | 1005/2001 [1:41:09<1:36:32,  5.82s/it] 50%|█████     | 1006/2001 [1:41:15<1:36:41,  5.83s/it] 50%|█████     | 1007/2001 [1:41:21<1:36:46,  5.84s/it] 50%|█████     | 1008/2001 [1:41:27<1:37:30,  5.89s/it] 50%|█████     | 1009/2001 [1:41:33<1:37:33,  5.90s/it] 50%|█████     | 1010/2001 [1:41:39<1:36:27,  5.84s/it] 51%|█████     | 1011/2001 [1:41:45<1:36:02,  5.82s/it] 51%|█████     | 1012/2001 [1:41:50<1:35:44,  5.81s/it] 51%|█████     | 1013/2001 [1:41:56<1:35:52,  5.82s/it] 51%|█████     | 1014/2001 [1:42:02<1:35:17,  5.79s/it] 51%|█████     | 1015/2001 [1:42:08<1:35:21,  5.80s/it] 51%|█████     | 1016/2001 [1:42:13<1:34:49,  5.78s/it] 51%|█████     | 1017/2001 [1:42:19<1:36:03,  5.86s/it] 51%|█████     | 1018/2001 [1:42:25<1:35:58,  5.86s/it] 51%|█████     | 1019/2001 [1:42:31<1:36:00,  5.87s/it] 51%|█████     | 1020/2001 [1:42:37<1:36:08,  5.88s/it] 51%|█████     | 1021/2001 [1:42:43<1:35:21,  5.84s/it] 51%|█████     | 1022/2001 [1:42:49<1:35:20,  5.84s/it] 51%|█████     | 1023/2001 [1:42:55<1:35:16,  5.85s/it] 51%|█████     | 1024/2001 [1:43:00<1:35:25,  5.86s/it] 51%|█████     | 1025/2001 [1:43:06<1:35:21,  5.86s/it] 51%|█████▏    | 1026/2001 [1:43:12<1:35:20,  5.87s/it] 51%|█████▏    | 1027/2001 [1:43:18<1:34:36,  5.83s/it] 51%|█████▏    | 1028/2001 [1:43:24<1:34:55,  5.85s/it] 51%|█████▏    | 1029/2001 [1:43:30<1:34:47,  5.85s/it] 51%|█████▏    | 1030/2001 [1:43:36<1:34:27,  5.84s/it] 52%|█████▏    | 1031/2001 [1:43:41<1:34:51,  5.87s/it] 52%|█████▏    | 1032/2001 [1:43:47<1:35:31,  5.91s/it] 52%|█████▏    | 1033/2001 [1:43:53<1:35:18,  5.91s/it] 52%|█████▏    | 1034/2001 [1:43:59<1:35:06,  5.90s/it] 52%|█████▏    | 1035/2001 [1:44:05<1:35:09,  5.91s/it] 52%|█████▏    | 1036/2001 [1:44:11<1:35:07,  5.91s/it] 52%|█████▏    | 1037/2001 [1:44:17<1:34:41,  5.89s/it] 52%|█████▏    | 1038/2001 [1:44:23<1:34:36,  5.89s/it] 52%|█████▏    | 1039/2001 [1:44:29<1:34:39,  5.90s/it] 52%|█████▏    | 1040/2001 [1:44:35<1:34:26,  5.90s/it] 52%|█████▏    | 1041/2001 [1:44:41<1:34:37,  5.91s/it] 52%|█████▏    | 1042/2001 [1:44:46<1:34:13,  5.90s/it] 52%|█████▏    | 1043/2001 [1:44:52<1:33:46,  5.87s/it] 52%|█████▏    | 1044/2001 [1:44:58<1:33:32,  5.87s/it] 52%|█████▏    | 1045/2001 [1:45:04<1:33:09,  5.85s/it] 52%|█████▏    | 1046/2001 [1:45:10<1:32:40,  5.82s/it] 52%|█████▏    | 1047/2001 [1:45:16<1:33:08,  5.86s/it] 52%|█████▏    | 1048/2001 [1:45:22<1:33:47,  5.90s/it]tensor(0.5932, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5995, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5980, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5992, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5993, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5925, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6009, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5891, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.6031, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5860, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5922, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5871, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5972, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5899, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5942, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5897, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5909, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5911, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5926, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5851, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5959, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5818, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5957, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5881, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5885, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5869, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5857, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5874, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5839, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5855, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5863, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5872, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5907, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5840, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5821, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5859, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5858, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5813, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5836, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5828, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5848, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5831, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5819, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5944, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5810, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5824, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5801, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5963, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5936, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5875, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5892, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5816, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5866, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5838, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5876, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5895, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5914, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5841, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5887, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5948, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5899, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5915, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5817, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5879, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5763, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5846, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5806, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5803, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5787, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5808, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5796, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5807, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5779, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5768, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5716, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5769, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5744, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.880210048612897, 'train_f1': 0.8880429139989617, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 1034, 'train_macro_f1': 0.8796205633721058, 'train_micro_f1': 0.8802098333676197, 'val_auc': 0.8523828380704548, 'val_f1': 0.8659987476518473, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 1034, 'val_macro_f1': 0.8518773116576144, 'val_micro_f1': 0.8532235939643347, 'test_auc': 0.8506287129752084, 'test_f1': 0.8585529067335842, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 1034, 'test_macro_f1': 0.8501912415063487, 'test_micro_f1': 0.8506579528393535}
loss tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5793, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5775, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5762, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5843, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5815, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5788, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5789, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5780, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5748, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5799, grad_fn=<BinaryCrossEntropyBackward0>)
 52%|█████▏    | 1049/2001 [1:45:27<1:33:23,  5.89s/it] 52%|█████▏    | 1050/2001 [1:45:33<1:33:03,  5.87s/it] 53%|█████▎    | 1051/2001 [1:45:39<1:32:48,  5.86s/it] 53%|█████▎    | 1052/2001 [1:45:45<1:33:01,  5.88s/it] 53%|█████▎    | 1053/2001 [1:45:51<1:32:48,  5.87s/it] 53%|█████▎    | 1054/2001 [1:45:57<1:32:40,  5.87s/it] 53%|█████▎    | 1055/2001 [1:46:03<1:32:32,  5.87s/it] 53%|█████▎    | 1056/2001 [1:46:09<1:32:17,  5.86s/it] 53%|█████▎    | 1057/2001 [1:46:14<1:32:19,  5.87s/it] 53%|█████▎    | 1058/2001 [1:46:20<1:32:16,  5.87s/it] 53%|█████▎    | 1059/2001 [1:46:26<1:32:25,  5.89s/it] 53%|█████▎    | 1060/2001 [1:46:32<1:32:13,  5.88s/it] 53%|█████▎    | 1061/2001 [1:46:38<1:32:25,  5.90s/it] 53%|█████▎    | 1062/2001 [1:46:44<1:32:25,  5.91s/it] 53%|█████▎    | 1063/2001 [1:46:50<1:32:06,  5.89s/it] 53%|█████▎    | 1064/2001 [1:46:56<1:31:56,  5.89s/it] 53%|█████▎    | 1065/2001 [1:47:02<1:31:43,  5.88s/it] 53%|█████▎    | 1066/2001 [1:47:07<1:31:42,  5.88s/it] 53%|█████▎    | 1067/2001 [1:47:13<1:31:13,  5.86s/it] 53%|█████▎    | 1068/2001 [1:47:19<1:30:59,  5.85s/it] 53%|█████▎    | 1069/2001 [1:47:25<1:30:57,  5.86s/it] 53%|█████▎    | 1070/2001 [1:47:31<1:31:15,  5.88s/it] 54%|█████▎    | 1071/2001 [1:47:37<1:31:15,  5.89s/it] 54%|█████▎    | 1072/2001 [1:47:43<1:31:13,  5.89s/it] 54%|█████▎    | 1073/2001 [1:47:49<1:31:17,  5.90s/it] 54%|█████▎    | 1074/2001 [1:47:54<1:30:21,  5.85s/it] 54%|█████▎    | 1075/2001 [1:48:00<1:29:59,  5.83s/it] 54%|█████▍    | 1076/2001 [1:48:06<1:30:05,  5.84s/it] 54%|█████▍    | 1077/2001 [1:48:12<1:30:21,  5.87s/it] 54%|█████▍    | 1078/2001 [1:48:18<1:30:22,  5.87s/it] 54%|█████▍    | 1079/2001 [1:48:24<1:31:04,  5.93s/it] 54%|█████▍    | 1080/2001 [1:48:30<1:31:00,  5.93s/it] 54%|█████▍    | 1081/2001 [1:48:36<1:30:38,  5.91s/it] 54%|█████▍    | 1082/2001 [1:48:42<1:30:29,  5.91s/it] 54%|█████▍    | 1083/2001 [1:48:47<1:30:04,  5.89s/it] 54%|█████▍    | 1084/2001 [1:48:53<1:29:40,  5.87s/it] 54%|█████▍    | 1085/2001 [1:48:59<1:30:12,  5.91s/it] 54%|█████▍    | 1086/2001 [1:49:05<1:30:01,  5.90s/it] 54%|█████▍    | 1087/2001 [1:49:11<1:29:46,  5.89s/it] 54%|█████▍    | 1088/2001 [1:49:17<1:29:43,  5.90s/it] 54%|█████▍    | 1089/2001 [1:49:23<1:29:45,  5.91s/it] 54%|█████▍    | 1090/2001 [1:49:29<1:29:43,  5.91s/it] 55%|█████▍    | 1091/2001 [1:49:35<1:29:35,  5.91s/it] 55%|█████▍    | 1092/2001 [1:49:41<1:29:22,  5.90s/it] 55%|█████▍    | 1093/2001 [1:49:46<1:29:02,  5.88s/it] 55%|█████▍    | 1094/2001 [1:49:52<1:28:56,  5.88s/it] 55%|█████▍    | 1095/2001 [1:49:58<1:28:47,  5.88s/it] 55%|█████▍    | 1096/2001 [1:50:04<1:28:35,  5.87s/it] 55%|█████▍    | 1097/2001 [1:50:10<1:28:39,  5.88s/it] 55%|█████▍    | 1098/2001 [1:50:16<1:28:28,  5.88s/it] 55%|█████▍    | 1099/2001 [1:50:22<1:28:22,  5.88s/it] 55%|█████▍    | 1100/2001 [1:50:28<1:28:23,  5.89s/it] 55%|█████▌    | 1101/2001 [1:50:33<1:28:24,  5.89s/it] 55%|█████▌    | 1102/2001 [1:50:39<1:28:23,  5.90s/it] 55%|█████▌    | 1103/2001 [1:50:45<1:28:11,  5.89s/it] 55%|█████▌    | 1104/2001 [1:50:51<1:28:20,  5.91s/it] 55%|█████▌    | 1105/2001 [1:50:57<1:28:24,  5.92s/it] 55%|█████▌    | 1106/2001 [1:51:03<1:27:56,  5.90s/it] 55%|█████▌    | 1107/2001 [1:51:09<1:27:15,  5.86s/it] 55%|█████▌    | 1108/2001 [1:51:15<1:27:09,  5.86s/it] 55%|█████▌    | 1109/2001 [1:51:20<1:26:45,  5.84s/it] 55%|█████▌    | 1110/2001 [1:51:26<1:27:00,  5.86s/it] 56%|█████▌    | 1111/2001 [1:51:32<1:27:10,  5.88s/it] 56%|█████▌    | 1112/2001 [1:51:38<1:27:38,  5.91s/it] 56%|█████▌    | 1113/2001 [1:51:44<1:27:30,  5.91s/it] 56%|█████▌    | 1114/2001 [1:51:50<1:27:16,  5.90s/it] 56%|█████▌    | 1115/2001 [1:51:56<1:27:21,  5.92s/it] 56%|█████▌    | 1116/2001 [1:52:02<1:27:21,  5.92s/it] 56%|█████▌    | 1117/2001 [1:52:08<1:26:47,  5.89s/it] 56%|█████▌    | 1118/2001 [1:52:14<1:27:06,  5.92s/it] 56%|█████▌    | 1119/2001 [1:52:20<1:27:08,  5.93s/it] 56%|█████▌    | 1120/2001 [1:52:25<1:26:23,  5.88s/it] 56%|█████▌    | 1121/2001 [1:52:31<1:25:18,  5.82s/it] 56%|█████▌    | 1122/2001 [1:52:37<1:25:33,  5.84s/it] 56%|█████▌    | 1123/2001 [1:52:43<1:25:48,  5.86s/it] 56%|█████▌    | 1124/2001 [1:52:49<1:28:07,  6.03s/it] 56%|█████▌    | 1125/2001 [1:52:55<1:28:27,  6.06s/it] 56%|█████▋    | 1126/2001 [1:53:01<1:27:57,  6.03s/it] 56%|█████▋    | 1127/2001 [1:53:08<1:29:37,  6.15s/it] 56%|█████▋    | 1128/2001 [1:53:14<1:29:36,  6.16s/it] 56%|█████▋    | 1129/2001 [1:53:20<1:29:14,  6.14s/it] 56%|█████▋    | 1130/2001 [1:53:26<1:27:40,  6.04s/it] 57%|█████▋    | 1131/2001 [1:53:32<1:27:35,  6.04s/it] 57%|█████▋    | 1132/2001 [1:53:38<1:27:42,  6.06s/it] 57%|█████▋    | 1133/2001 [1:53:44<1:27:09,  6.02s/it] 57%|█████▋    | 1134/2001 [1:53:50<1:27:39,  6.07s/it] 57%|█████▋    | 1135/2001 [1:53:56<1:27:00,  6.03s/it] 57%|█████▋    | 1136/2001 [1:54:02<1:26:14,  5.98s/it] 57%|█████▋    | 1137/2001 [1:54:08<1:26:07,  5.98s/it] 57%|█████▋    | 1138/2001 [1:54:14<1:25:55,  5.97s/it] 57%|█████▋    | 1139/2001 [1:54:20<1:26:19,  6.01s/it] 57%|█████▋    | 1140/2001 [1:54:26<1:26:01,  6.00s/it] 57%|█████▋    | 1141/2001 [1:54:32<1:25:30,  5.97s/it] 57%|█████▋    | 1142/2001 [1:54:38<1:25:27,  5.97s/it] 57%|█████▋    | 1143/2001 [1:54:44<1:25:15,  5.96s/it] 57%|█████▋    | 1144/2001 [1:54:50<1:25:11,  5.96s/it] 57%|█████▋    | 1145/2001 [1:54:56<1:25:19,  5.98s/it] 57%|█████▋    | 1146/2001 [1:55:02<1:24:44,  5.95s/it] 57%|█████▋    | 1147/2001 [1:55:08<1:24:29,  5.94s/it] 57%|█████▋    | 1148/2001 [1:55:13<1:24:17,  5.93s/it] 57%|█████▋    | 1149/2001 [1:55:20<1:24:57,  5.98s/it] 57%|█████▋    | 1150/2001 [1:55:26<1:24:49,  5.98s/it] 58%|█████▊    | 1151/2001 [1:55:31<1:24:26,  5.96s/it] 58%|█████▊    | 1152/2001 [1:55:37<1:24:36,  5.98s/it] 58%|█████▊    | 1153/2001 [1:55:43<1:24:11,  5.96s/it] 58%|█████▊    | 1154/2001 [1:55:49<1:24:06,  5.96s/it] 58%|█████▊    | 1155/2001 [1:55:55<1:24:01,  5.96s/it] 58%|█████▊    | 1156/2001 [1:56:01<1:24:04,  5.97s/it] 58%|█████▊    | 1157/2001 [1:56:07<1:23:58,  5.97s/it] 58%|█████▊    | 1158/2001 [1:56:13<1:23:48,  5.96s/it] 58%|█████▊    | 1159/2001 [1:56:19<1:23:35,  5.96s/it] 58%|█████▊    | 1160/2001 [1:56:25<1:23:20,  5.95s/it] 58%|█████▊    | 1161/2001 [1:56:31<1:23:22,  5.95s/it] 58%|█████▊    | 1162/2001 [1:56:37<1:23:15,  5.95s/it] 58%|█████▊    | 1163/2001 [1:56:43<1:23:31,  5.98s/it] 58%|█████▊    | 1164/2001 [1:56:49<1:23:34,  5.99s/it] 58%|█████▊    | 1165/2001 [1:56:55<1:23:21,  5.98s/it] 58%|█████▊    | 1166/2001 [1:57:01<1:23:01,  5.97s/it] 58%|█████▊    | 1167/2001 [1:57:07<1:23:06,  5.98s/it] 58%|█████▊    | 1168/2001 [1:57:13<1:22:38,  5.95s/it] 58%|█████▊    | 1169/2001 [1:57:19<1:22:22,  5.94s/it] 58%|█████▊    | 1170/2001 [1:57:25<1:21:52,  5.91s/it] 59%|█████▊    | 1171/2001 [1:57:31<1:22:12,  5.94s/it] 59%|█████▊    | 1172/2001 [1:57:37<1:22:01,  5.94s/it] 59%|█████▊    | 1173/2001 [1:57:42<1:21:53,  5.93s/it] 59%|█████▊    | 1174/2001 [1:57:48<1:21:37,  5.92s/it] 59%|█████▊    | 1175/2001 [1:57:54<1:21:25,  5.92s/it] 59%|█████▉    | 1176/2001 [1:58:00<1:21:25,  5.92s/it] 59%|█████▉    | 1177/2001 [1:58:06<1:21:40,  5.95s/it] 59%|█████▉    | 1178/2001 [1:58:12<1:21:33,  5.95s/it] 59%|█████▉    | 1179/2001 [1:58:18<1:21:12,  5.93s/it] 59%|█████▉    | 1180/2001 [1:58:24<1:21:20,  5.94s/it] 59%|█████▉    | 1181/2001 [1:58:30<1:21:23,  5.96s/it] 59%|█████▉    | 1182/2001 [1:58:36<1:21:18,  5.96s/it] 59%|█████▉    | 1183/2001 [1:58:42<1:21:17,  5.96s/it] 59%|█████▉    | 1184/2001 [1:58:48<1:21:09,  5.96s/it] 59%|█████▉    | 1185/2001 [1:58:54<1:21:46,  6.01s/it] 59%|█████▉    | 1186/2001 [1:59:00<1:21:04,  5.97s/it]loss tensor(0.5846, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5850, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5865, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5781, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5757, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5747, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5729, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5809, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5730, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5702, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5745, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5764, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5736, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5723, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5779, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5742, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5731, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5717, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5825, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5726, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5728, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5735, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5753, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5795, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5721, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5755, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5670, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5733, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5709, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5709, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5759, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5727, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5683, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5718, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5638, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5740, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5822, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5724, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5722, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5760, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5699, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5720, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5752, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5678, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5754, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5711, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5675, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5640, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5650, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5616, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5655, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5700, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5631, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5678, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5647, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5663, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5642, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5693, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5687, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5680, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5652, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5612, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5572, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5579, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5619, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5601, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5555, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5591, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5577, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5575, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5551, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5576, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5544, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5587, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5597, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5599, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5600, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)
loss  59%|█████▉    | 1187/2001 [1:59:06<1:21:33,  6.01s/it] 59%|█████▉    | 1188/2001 [1:59:12<1:20:59,  5.98s/it] 59%|█████▉    | 1189/2001 [1:59:18<1:20:31,  5.95s/it] 59%|█████▉    | 1190/2001 [1:59:24<1:20:25,  5.95s/it] 60%|█████▉    | 1191/2001 [1:59:30<1:20:23,  5.96s/it] 60%|█████▉    | 1192/2001 [1:59:36<1:20:12,  5.95s/it] 60%|█████▉    | 1193/2001 [1:59:42<1:20:07,  5.95s/it] 60%|█████▉    | 1194/2001 [1:59:48<1:20:09,  5.96s/it] 60%|█████▉    | 1195/2001 [1:59:53<1:19:40,  5.93s/it] 60%|█████▉    | 1196/2001 [1:59:59<1:19:42,  5.94s/it] 60%|█████▉    | 1197/2001 [2:00:05<1:19:54,  5.96s/it] 60%|█████▉    | 1198/2001 [2:00:11<1:19:46,  5.96s/it] 60%|█████▉    | 1199/2001 [2:00:17<1:19:52,  5.98s/it] 60%|█████▉    | 1200/2001 [2:00:23<1:19:38,  5.97s/it] 60%|██████    | 1201/2001 [2:00:29<1:19:15,  5.94s/it] 60%|██████    | 1202/2001 [2:00:35<1:20:05,  6.01s/it] 60%|██████    | 1203/2001 [2:00:41<1:19:25,  5.97s/it] 60%|██████    | 1204/2001 [2:00:47<1:18:40,  5.92s/it] 60%|██████    | 1205/2001 [2:00:53<1:18:18,  5.90s/it] 60%|██████    | 1206/2001 [2:00:59<1:17:54,  5.88s/it] 60%|██████    | 1207/2001 [2:01:05<1:18:19,  5.92s/it] 60%|██████    | 1208/2001 [2:01:11<1:18:02,  5.91s/it] 60%|██████    | 1209/2001 [2:01:17<1:18:25,  5.94s/it] 60%|██████    | 1210/2001 [2:01:23<1:18:43,  5.97s/it] 61%|██████    | 1211/2001 [2:01:29<1:18:35,  5.97s/it] 61%|██████    | 1212/2001 [2:01:35<1:18:33,  5.97s/it] 61%|██████    | 1213/2001 [2:01:41<1:18:35,  5.98s/it] 61%|██████    | 1214/2001 [2:01:47<1:17:59,  5.95s/it] 61%|██████    | 1215/2001 [2:01:52<1:17:46,  5.94s/it] 61%|██████    | 1216/2001 [2:01:58<1:17:40,  5.94s/it] 61%|██████    | 1217/2001 [2:02:04<1:17:41,  5.95s/it] 61%|██████    | 1218/2001 [2:02:10<1:17:39,  5.95s/it] 61%|██████    | 1219/2001 [2:02:16<1:17:26,  5.94s/it] 61%|██████    | 1220/2001 [2:02:22<1:17:17,  5.94s/it] 61%|██████    | 1221/2001 [2:02:28<1:17:06,  5.93s/it] 61%|██████    | 1222/2001 [2:02:34<1:16:58,  5.93s/it] 61%|██████    | 1223/2001 [2:02:40<1:17:07,  5.95s/it] 61%|██████    | 1224/2001 [2:02:46<1:16:31,  5.91s/it] 61%|██████    | 1225/2001 [2:02:52<1:15:43,  5.85s/it] 61%|██████▏   | 1226/2001 [2:02:57<1:15:47,  5.87s/it] 61%|██████▏   | 1227/2001 [2:03:03<1:16:06,  5.90s/it] 61%|██████▏   | 1228/2001 [2:03:09<1:16:21,  5.93s/it] 61%|██████▏   | 1229/2001 [2:03:15<1:16:27,  5.94s/it] 61%|██████▏   | 1230/2001 [2:03:21<1:16:23,  5.94s/it] 62%|██████▏   | 1231/2001 [2:03:27<1:16:07,  5.93s/it] 62%|██████▏   | 1232/2001 [2:03:33<1:16:00,  5.93s/it] 62%|██████▏   | 1233/2001 [2:03:39<1:15:51,  5.93s/it] 62%|██████▏   | 1234/2001 [2:03:45<1:15:55,  5.94s/it] 62%|██████▏   | 1235/2001 [2:03:51<1:16:06,  5.96s/it] 62%|██████▏   | 1236/2001 [2:03:57<1:16:02,  5.96s/it] 62%|██████▏   | 1237/2001 [2:04:03<1:15:53,  5.96s/it] 62%|██████▏   | 1238/2001 [2:04:09<1:15:42,  5.95s/it] 62%|██████▏   | 1239/2001 [2:04:15<1:15:23,  5.94s/it] 62%|██████▏   | 1240/2001 [2:04:21<1:15:15,  5.93s/it] 62%|██████▏   | 1241/2001 [2:04:27<1:15:04,  5.93s/it] 62%|██████▏   | 1242/2001 [2:04:33<1:14:56,  5.92s/it] 62%|██████▏   | 1243/2001 [2:04:39<1:15:07,  5.95s/it] 62%|██████▏   | 1244/2001 [2:04:45<1:15:19,  5.97s/it] 62%|██████▏   | 1245/2001 [2:04:51<1:15:20,  5.98s/it] 62%|██████▏   | 1246/2001 [2:04:57<1:15:10,  5.97s/it] 62%|██████▏   | 1247/2001 [2:05:02<1:14:40,  5.94s/it] 62%|██████▏   | 1248/2001 [2:05:08<1:14:49,  5.96s/it] 62%|██████▏   | 1249/2001 [2:05:14<1:14:39,  5.96s/it] 62%|██████▏   | 1250/2001 [2:05:20<1:14:41,  5.97s/it] 63%|██████▎   | 1251/2001 [2:05:26<1:14:26,  5.96s/it] 63%|██████▎   | 1252/2001 [2:05:32<1:14:24,  5.96s/it] 63%|██████▎   | 1253/2001 [2:05:38<1:15:13,  6.03s/it] 63%|██████▎   | 1254/2001 [2:05:44<1:14:52,  6.01s/it] 63%|██████▎   | 1255/2001 [2:05:50<1:14:31,  5.99s/it] 63%|██████▎   | 1256/2001 [2:05:56<1:14:11,  5.98s/it] 63%|██████▎   | 1257/2001 [2:06:02<1:14:08,  5.98s/it] 63%|██████▎   | 1258/2001 [2:06:08<1:14:10,  5.99s/it] 63%|██████▎   | 1259/2001 [2:06:14<1:13:46,  5.97s/it] 63%|██████▎   | 1260/2001 [2:06:20<1:13:29,  5.95s/it] 63%|██████▎   | 1261/2001 [2:06:26<1:13:33,  5.96s/it] 63%|██████▎   | 1262/2001 [2:06:32<1:13:16,  5.95s/it] 63%|██████▎   | 1263/2001 [2:06:38<1:13:14,  5.95s/it] 63%|██████▎   | 1264/2001 [2:06:44<1:13:09,  5.96s/it] 63%|██████▎   | 1265/2001 [2:06:50<1:13:11,  5.97s/it] 63%|██████▎   | 1266/2001 [2:06:56<1:12:51,  5.95s/it] 63%|██████▎   | 1267/2001 [2:07:02<1:12:43,  5.94s/it] 63%|██████▎   | 1268/2001 [2:07:08<1:12:50,  5.96s/it] 63%|██████▎   | 1269/2001 [2:07:14<1:12:40,  5.96s/it] 63%|██████▎   | 1270/2001 [2:07:20<1:12:28,  5.95s/it] 64%|██████▎   | 1271/2001 [2:07:26<1:12:09,  5.93s/it] 64%|██████▎   | 1272/2001 [2:07:32<1:12:20,  5.95s/it] 64%|██████▎   | 1273/2001 [2:07:38<1:12:22,  5.97s/it] 64%|██████▎   | 1274/2001 [2:07:44<1:12:17,  5.97s/it] 64%|██████▎   | 1275/2001 [2:07:50<1:12:07,  5.96s/it] 64%|██████▍   | 1276/2001 [2:07:55<1:11:53,  5.95s/it] 64%|██████▍   | 1277/2001 [2:08:01<1:11:39,  5.94s/it] 64%|██████▍   | 1278/2001 [2:08:08<1:12:35,  6.02s/it] 64%|██████▍   | 1279/2001 [2:08:14<1:12:12,  6.00s/it] 64%|██████▍   | 1280/2001 [2:08:19<1:11:44,  5.97s/it] 64%|██████▍   | 1281/2001 [2:08:25<1:11:28,  5.96s/it] 64%|██████▍   | 1282/2001 [2:08:31<1:11:22,  5.96s/it] 64%|██████▍   | 1283/2001 [2:08:37<1:11:47,  6.00s/it] 64%|██████▍   | 1284/2001 [2:08:43<1:11:19,  5.97s/it] 64%|██████▍   | 1285/2001 [2:08:49<1:10:58,  5.95s/it] 64%|██████▍   | 1286/2001 [2:08:55<1:10:44,  5.94s/it] 64%|██████▍   | 1287/2001 [2:09:01<1:10:38,  5.94s/it] 64%|██████▍   | 1288/2001 [2:09:07<1:10:09,  5.90s/it] 64%|██████▍   | 1289/2001 [2:09:13<1:10:08,  5.91s/it] 64%|██████▍   | 1290/2001 [2:09:19<1:10:22,  5.94s/it] 65%|██████▍   | 1291/2001 [2:09:25<1:10:31,  5.96s/it] 65%|██████▍   | 1292/2001 [2:09:31<1:10:27,  5.96s/it] 65%|██████▍   | 1293/2001 [2:09:37<1:10:18,  5.96s/it] 65%|██████▍   | 1294/2001 [2:09:43<1:10:14,  5.96s/it] 65%|██████▍   | 1295/2001 [2:09:49<1:10:08,  5.96s/it]tensor(0.5588, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5636, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5611, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5608, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5625, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5582, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5694, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5594, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5664, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5676, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5610, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5570, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5605, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5629, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5766, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5562, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5571, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5767, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5584, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5639, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5614, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5621, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5656, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5696, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5564, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5627, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8869587871882901, 'train_f1': 0.8943336377180756, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 1222, 'train_macro_f1': 0.8863681904645906, 'train_micro_f1': 0.886926558321333, 'val_auc': 0.8532037072338694, 'val_f1': 0.8661120703186314, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 1222, 'val_macro_f1': 0.8524779131113278, 'val_micro_f1': 0.8537379972565158, 'test_auc': 0.8508795684027122, 'test_f1': 0.8590996408585985, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 1222, 'test_macro_f1': 0.8505186202044328, 'test_micro_f1': 0.851011216108805}
loss tensor(0.5569, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5618, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8879669415251388, 'train_f1': 0.8962140555220854, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 1224, 'train_macro_f1': 0.88772469347447, 'train_micro_f1': 0.8883665912363711, 'val_auc': 0.8542989917582691, 'val_f1': 0.8684251599812705, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 1224, 'val_macro_f1': 0.8540337707838633, 'val_micro_f1': 0.8554526748971193, 'test_auc': 0.8506140185150198, 'test_f1': 0.8596389050669773, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 1224, 'test_macro_f1': 0.8504461580947947, 'test_micro_f1': 0.851011216108805}
loss tensor(0.5540, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5573, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5641, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5574, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5545, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5547, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5535, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5533, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5530, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5563, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5595, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5530, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5567, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5565, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5538, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5529, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5580, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5523, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5565, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5536, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5496, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5490, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5543, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5542, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5472, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.889316722545135, 'train_f1': 0.8963506739659601, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 1267, 'train_macro_f1': 0.8886579729177004, 'train_micro_f1': 0.8891894671878214, 'val_auc': 0.8550212187607408, 'val_f1': 0.8679422835633627, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 1267, 'val_macro_f1': 0.854356920904223, 'val_micro_f1': 0.8556241426611797, 'test_auc': 0.8525935722232718, 'test_f1': 0.8606283422459893, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 1267, 'test_macro_f1': 0.8522096571690707, 'test_micro_f1': 0.8526892166387}
loss tensor(0.5540, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5528, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5511, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5500, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5438, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5541, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5435, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5515, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5481, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5496, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5457, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5462, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5433, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5525, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5508, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5501, grad_fn=<BinaryCrossEntropyBackward0>)
loss  65%|██████▍   | 1296/2001 [2:09:55<1:10:00,  5.96s/it] 65%|██████▍   | 1297/2001 [2:10:01<1:09:48,  5.95s/it] 65%|██████▍   | 1298/2001 [2:10:06<1:09:27,  5.93s/it] 65%|██████▍   | 1299/2001 [2:10:12<1:09:14,  5.92s/it] 65%|██████▍   | 1300/2001 [2:10:18<1:09:07,  5.92s/it] 65%|██████▌   | 1301/2001 [2:10:24<1:09:01,  5.92s/it] 65%|██████▌   | 1302/2001 [2:10:30<1:09:02,  5.93s/it] 65%|██████▌   | 1303/2001 [2:10:36<1:09:08,  5.94s/it] 65%|██████▌   | 1304/2001 [2:10:42<1:08:58,  5.94s/it] 65%|██████▌   | 1305/2001 [2:10:48<1:09:02,  5.95s/it] 65%|██████▌   | 1306/2001 [2:10:54<1:08:56,  5.95s/it] 65%|██████▌   | 1307/2001 [2:11:00<1:08:58,  5.96s/it] 65%|██████▌   | 1308/2001 [2:11:06<1:09:16,  6.00s/it] 65%|██████▌   | 1309/2001 [2:11:12<1:09:08,  5.99s/it] 65%|██████▌   | 1310/2001 [2:11:18<1:08:56,  5.99s/it] 66%|██████▌   | 1311/2001 [2:11:24<1:08:39,  5.97s/it] 66%|██████▌   | 1312/2001 [2:11:30<1:08:21,  5.95s/it] 66%|██████▌   | 1313/2001 [2:11:36<1:08:08,  5.94s/it] 66%|██████▌   | 1314/2001 [2:11:42<1:08:00,  5.94s/it] 66%|██████▌   | 1315/2001 [2:11:48<1:07:54,  5.94s/it] 66%|██████▌   | 1316/2001 [2:11:53<1:07:43,  5.93s/it] 66%|██████▌   | 1317/2001 [2:11:59<1:07:36,  5.93s/it] 66%|██████▌   | 1318/2001 [2:12:05<1:07:34,  5.94s/it] 66%|██████▌   | 1319/2001 [2:12:11<1:07:34,  5.95s/it] 66%|██████▌   | 1320/2001 [2:12:17<1:07:54,  5.98s/it] 66%|██████▌   | 1321/2001 [2:12:23<1:07:53,  5.99s/it] 66%|██████▌   | 1322/2001 [2:12:29<1:07:48,  5.99s/it] 66%|██████▌   | 1323/2001 [2:12:35<1:07:40,  5.99s/it] 66%|██████▌   | 1324/2001 [2:12:41<1:07:26,  5.98s/it] 66%|██████▌   | 1325/2001 [2:12:47<1:07:09,  5.96s/it] 66%|██████▋   | 1326/2001 [2:12:53<1:07:21,  5.99s/it] 66%|██████▋   | 1327/2001 [2:12:59<1:07:01,  5.97s/it] 66%|██████▋   | 1328/2001 [2:13:05<1:06:42,  5.95s/it] 66%|██████▋   | 1329/2001 [2:13:11<1:06:47,  5.96s/it] 66%|██████▋   | 1330/2001 [2:13:17<1:06:43,  5.97s/it] 67%|██████▋   | 1331/2001 [2:13:23<1:06:55,  5.99s/it] 67%|██████▋   | 1332/2001 [2:13:29<1:06:57,  6.01s/it] 67%|██████▋   | 1333/2001 [2:13:35<1:06:58,  6.02s/it] 67%|██████▋   | 1334/2001 [2:13:41<1:07:05,  6.04s/it] 67%|██████▋   | 1335/2001 [2:13:47<1:06:46,  6.02s/it] 67%|██████▋   | 1336/2001 [2:13:53<1:06:53,  6.04s/it] 67%|██████▋   | 1337/2001 [2:13:59<1:06:35,  6.02s/it] 67%|██████▋   | 1338/2001 [2:14:05<1:06:17,  6.00s/it] 67%|██████▋   | 1339/2001 [2:14:11<1:05:49,  5.97s/it] 67%|██████▋   | 1340/2001 [2:14:17<1:05:34,  5.95s/it] 67%|██████▋   | 1341/2001 [2:14:23<1:05:23,  5.95s/it] 67%|██████▋   | 1342/2001 [2:14:29<1:05:19,  5.95s/it] 67%|██████▋   | 1343/2001 [2:14:35<1:05:10,  5.94s/it] 67%|██████▋   | 1344/2001 [2:14:41<1:05:11,  5.95s/it] 67%|██████▋   | 1345/2001 [2:14:47<1:05:04,  5.95s/it] 67%|██████▋   | 1346/2001 [2:14:53<1:05:08,  5.97s/it] 67%|██████▋   | 1347/2001 [2:14:59<1:04:55,  5.96s/it] 67%|██████▋   | 1348/2001 [2:15:05<1:04:47,  5.95s/it] 67%|██████▋   | 1349/2001 [2:15:11<1:04:09,  5.90s/it] 67%|██████▋   | 1350/2001 [2:15:17<1:04:58,  5.99s/it] 68%|██████▊   | 1351/2001 [2:15:23<1:04:47,  5.98s/it] 68%|██████▊   | 1352/2001 [2:15:29<1:04:53,  6.00s/it] 68%|██████▊   | 1353/2001 [2:15:35<1:04:40,  5.99s/it] 68%|██████▊   | 1354/2001 [2:15:41<1:04:29,  5.98s/it] 68%|██████▊   | 1355/2001 [2:15:47<1:04:20,  5.98s/it] 68%|██████▊   | 1356/2001 [2:15:53<1:04:30,  6.00s/it] 68%|██████▊   | 1357/2001 [2:15:59<1:04:30,  6.01s/it] 68%|██████▊   | 1358/2001 [2:16:05<1:04:31,  6.02s/it] 68%|██████▊   | 1359/2001 [2:16:11<1:04:12,  6.00s/it] 68%|██████▊   | 1360/2001 [2:16:17<1:03:59,  5.99s/it] 68%|██████▊   | 1361/2001 [2:16:23<1:04:18,  6.03s/it] 68%|██████▊   | 1362/2001 [2:16:29<1:04:08,  6.02s/it] 68%|██████▊   | 1363/2001 [2:16:35<1:03:53,  6.01s/it] 68%|██████▊   | 1364/2001 [2:16:41<1:03:32,  5.99s/it] 68%|██████▊   | 1365/2001 [2:16:47<1:03:19,  5.97s/it] 68%|██████▊   | 1366/2001 [2:16:53<1:03:23,  5.99s/it] 68%|██████▊   | 1367/2001 [2:16:59<1:03:02,  5.97s/it] 68%|██████▊   | 1368/2001 [2:17:04<1:02:40,  5.94s/it] 68%|██████▊   | 1369/2001 [2:17:11<1:02:58,  5.98s/it] 68%|██████▊   | 1370/2001 [2:17:17<1:03:06,  6.00s/it] 69%|██████▊   | 1371/2001 [2:17:23<1:03:00,  6.00s/it] 69%|██████▊   | 1372/2001 [2:17:29<1:02:44,  5.99s/it] 69%|██████▊   | 1373/2001 [2:17:34<1:02:09,  5.94s/it] 69%|██████▊   | 1374/2001 [2:17:40<1:02:00,  5.93s/it] 69%|██████▊   | 1375/2001 [2:17:46<1:01:45,  5.92s/it] 69%|██████▉   | 1376/2001 [2:17:52<1:01:09,  5.87s/it] 69%|██████▉   | 1377/2001 [2:17:58<1:01:08,  5.88s/it] 69%|██████▉   | 1378/2001 [2:18:04<1:01:39,  5.94s/it] 69%|██████▉   | 1379/2001 [2:18:10<1:01:29,  5.93s/it] 69%|██████▉   | 1380/2001 [2:18:16<1:01:19,  5.93s/it] 69%|██████▉   | 1381/2001 [2:18:22<1:01:12,  5.92s/it] 69%|██████▉   | 1382/2001 [2:18:28<1:01:16,  5.94s/it] 69%|██████▉   | 1383/2001 [2:18:34<1:01:08,  5.94s/it] 69%|██████▉   | 1384/2001 [2:18:40<1:01:09,  5.95s/it] 69%|██████▉   | 1385/2001 [2:18:45<1:01:03,  5.95s/it] 69%|██████▉   | 1386/2001 [2:18:51<1:00:57,  5.95s/it] 69%|██████▉   | 1387/2001 [2:18:57<1:00:48,  5.94s/it] 69%|██████▉   | 1388/2001 [2:19:03<1:00:18,  5.90s/it] 69%|██████▉   | 1389/2001 [2:19:09<1:00:21,  5.92s/it] 69%|██████▉   | 1390/2001 [2:19:15<1:00:17,  5.92s/it] 70%|██████▉   | 1391/2001 [2:19:21<1:00:27,  5.95s/it] 70%|██████▉   | 1392/2001 [2:19:27<1:00:39,  5.98s/it] 70%|██████▉   | 1393/2001 [2:19:33<1:00:20,  5.95s/it] 70%|██████▉   | 1394/2001 [2:19:39<1:00:43,  6.00s/it] 70%|██████▉   | 1395/2001 [2:19:45<1:00:21,  5.98s/it] 70%|██████▉   | 1396/2001 [2:19:51<1:00:09,  5.97s/it] 70%|██████▉   | 1397/2001 [2:19:57<1:00:00,  5.96s/it] 70%|██████▉   | 1398/2001 [2:20:03<59:38,  5.93s/it]   70%|██████▉   | 1399/2001 [2:20:09<59:35,  5.94s/it] 70%|██████▉   | 1400/2001 [2:20:15<59:27,  5.94s/it] 70%|███████   | 1401/2001 [2:20:21<59:24,  5.94s/it] 70%|███████   | 1402/2001 [2:20:27<59:32,  5.96s/it] 70%|███████   | 1403/2001 [2:20:33<59:18,  5.95s/it] 70%|███████   | 1404/2001 [2:20:39<59:12,  5.95s/it] 70%|███████   | 1405/2001 [2:20:44<58:56,  5.93s/it] 70%|███████   | 1406/2001 [2:20:50<58:53,  5.94s/it] 70%|███████   | 1407/2001 [2:20:56<58:36,  5.92s/it] 70%|███████   | 1408/2001 [2:21:02<58:05,  5.88s/it] 70%|███████   | 1409/2001 [2:21:08<57:17,  5.81s/it] 70%|███████   | 1410/2001 [2:21:13<57:04,  5.79s/it] 71%|███████   | 1411/2001 [2:21:19<57:15,  5.82s/it] 71%|███████   | 1412/2001 [2:21:25<57:27,  5.85s/it] 71%|███████   | 1413/2001 [2:21:31<57:44,  5.89s/it] 71%|███████   | 1414/2001 [2:21:37<57:47,  5.91s/it]tensor(0.5509, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5581, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5499, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5618, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5470, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5513, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5426, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8916796962290321, 'train_f1': 0.8986722302877637, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 1305, 'train_macro_f1': 0.8910651682340832, 'train_micro_f1': 0.8915963793458136, 'val_auc': 0.8558205768023112, 'val_f1': 0.8684458398744113, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 1305, 'val_macro_f1': 0.8550767166882445, 'val_micro_f1': 0.856310013717421, 'test_auc': 0.8519512143921742, 'test_f1': 0.8595595008793233, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 1305, 'test_macro_f1': 0.8514518662733842, 'test_micro_f1': 0.851894374282434}
loss tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5443, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5494, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5484, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5426, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5430, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5483, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5421, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5463, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5447, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5477, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5464, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5577, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5461, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5615, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5550, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5460, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5504, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5473, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5519, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5480, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5518, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5467, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5438, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5495, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5440, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5418, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5437, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5459, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5412, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5457, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8923365765298686, 'train_f1': 0.8979769709764577, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 1354, 'train_macro_f1': 0.8912175075218112, 'train_micro_f1': 0.8916375231433862, 'val_auc': 0.8571157602600921, 'val_f1': 0.8683712121212123, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 1354, 'val_macro_f1': 0.8559198402948403, 'val_micro_f1': 0.8569958847736625, 'test_auc': 0.8510422570690849, 'test_f1': 0.8574317492416582, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 1354, 'test_macro_f1': 0.8502226476770547, 'test_micro_f1': 0.8505696370219905}
loss tensor(0.5436, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5485, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5434, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5442, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5415, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5420, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5422, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5417, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5498, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5510, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5476, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5475, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5441, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5472, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5432, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5465, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5522, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5377, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5437, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5454, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5471, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5400, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5398, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5417, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5384, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5415, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5413, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5429, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5386, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5387, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5342, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5397, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5396, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5385, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)
loss  71%|███████   | 1415/2001 [2:21:43<57:46,  5.92s/it] 71%|███████   | 1416/2001 [2:21:49<57:40,  5.92s/it] 71%|███████   | 1417/2001 [2:21:55<57:41,  5.93s/it] 71%|███████   | 1418/2001 [2:22:01<57:54,  5.96s/it] 71%|███████   | 1419/2001 [2:22:07<57:47,  5.96s/it] 71%|███████   | 1420/2001 [2:22:13<57:41,  5.96s/it] 71%|███████   | 1421/2001 [2:22:19<57:24,  5.94s/it] 71%|███████   | 1422/2001 [2:22:25<57:13,  5.93s/it] 71%|███████   | 1423/2001 [2:22:31<57:08,  5.93s/it] 71%|███████   | 1424/2001 [2:22:37<57:03,  5.93s/it] 71%|███████   | 1425/2001 [2:22:43<57:07,  5.95s/it] 71%|███████▏  | 1426/2001 [2:22:49<57:07,  5.96s/it] 71%|███████▏  | 1427/2001 [2:22:54<56:57,  5.95s/it] 71%|███████▏  | 1428/2001 [2:23:00<56:45,  5.94s/it] 71%|███████▏  | 1429/2001 [2:23:06<56:42,  5.95s/it] 71%|███████▏  | 1430/2001 [2:23:12<56:36,  5.95s/it] 72%|███████▏  | 1431/2001 [2:23:18<56:40,  5.97s/it] 72%|███████▏  | 1432/2001 [2:23:24<56:43,  5.98s/it] 72%|███████▏  | 1433/2001 [2:23:30<56:36,  5.98s/it] 72%|███████▏  | 1434/2001 [2:23:36<56:20,  5.96s/it] 72%|███████▏  | 1435/2001 [2:23:42<55:58,  5.93s/it] 72%|███████▏  | 1436/2001 [2:23:48<55:18,  5.87s/it] 72%|███████▏  | 1437/2001 [2:23:54<55:38,  5.92s/it] 72%|███████▏  | 1438/2001 [2:24:00<55:27,  5.91s/it] 72%|███████▏  | 1439/2001 [2:24:06<55:22,  5.91s/it] 72%|███████▏  | 1440/2001 [2:24:12<55:27,  5.93s/it] 72%|███████▏  | 1441/2001 [2:24:18<55:20,  5.93s/it] 72%|███████▏  | 1442/2001 [2:24:23<54:51,  5.89s/it] 72%|███████▏  | 1443/2001 [2:24:29<54:18,  5.84s/it] 72%|███████▏  | 1444/2001 [2:24:35<54:54,  5.91s/it] 72%|███████▏  | 1445/2001 [2:24:41<55:18,  5.97s/it] 72%|███████▏  | 1446/2001 [2:24:47<55:11,  5.97s/it] 72%|███████▏  | 1447/2001 [2:24:53<54:18,  5.88s/it] 72%|███████▏  | 1448/2001 [2:24:59<54:47,  5.94s/it] 72%|███████▏  | 1449/2001 [2:25:05<54:47,  5.96s/it] 72%|███████▏  | 1450/2001 [2:25:11<54:41,  5.96s/it] 73%|███████▎  | 1451/2001 [2:25:17<54:24,  5.94s/it] 73%|███████▎  | 1452/2001 [2:25:23<54:06,  5.91s/it] 73%|███████▎  | 1453/2001 [2:25:29<54:12,  5.93s/it] 73%|███████▎  | 1454/2001 [2:25:35<54:08,  5.94s/it] 73%|███████▎  | 1455/2001 [2:25:40<53:34,  5.89s/it] 73%|███████▎  | 1456/2001 [2:25:46<53:53,  5.93s/it] 73%|███████▎  | 1457/2001 [2:25:52<54:04,  5.96s/it] 73%|███████▎  | 1458/2001 [2:25:58<53:52,  5.95s/it] 73%|███████▎  | 1459/2001 [2:26:04<53:32,  5.93s/it] 73%|███████▎  | 1460/2001 [2:26:10<52:55,  5.87s/it] 73%|███████▎  | 1461/2001 [2:26:16<52:58,  5.89s/it] 73%|███████▎  | 1462/2001 [2:26:22<52:57,  5.89s/it] 73%|███████▎  | 1463/2001 [2:26:28<53:06,  5.92s/it] 73%|███████▎  | 1464/2001 [2:26:34<52:54,  5.91s/it] 73%|███████▎  | 1465/2001 [2:26:40<53:07,  5.95s/it] 73%|███████▎  | 1466/2001 [2:26:46<53:13,  5.97s/it] 73%|███████▎  | 1467/2001 [2:26:52<53:21,  6.00s/it] 73%|███████▎  | 1468/2001 [2:26:58<53:19,  6.00s/it] 73%|███████▎  | 1469/2001 [2:27:04<53:01,  5.98s/it] 73%|███████▎  | 1470/2001 [2:27:10<52:27,  5.93s/it] 74%|███████▎  | 1471/2001 [2:27:16<52:31,  5.95s/it] 74%|███████▎  | 1472/2001 [2:27:22<52:31,  5.96s/it] 74%|███████▎  | 1473/2001 [2:27:27<52:21,  5.95s/it] 74%|███████▎  | 1474/2001 [2:27:34<52:51,  6.02s/it] 74%|███████▎  | 1475/2001 [2:27:40<52:51,  6.03s/it] 74%|███████▍  | 1476/2001 [2:27:46<52:37,  6.02s/it] 74%|███████▍  | 1477/2001 [2:27:52<52:59,  6.07s/it] 74%|███████▍  | 1478/2001 [2:27:58<52:25,  6.01s/it] 74%|███████▍  | 1479/2001 [2:28:04<52:31,  6.04s/it] 74%|███████▍  | 1480/2001 [2:28:10<52:19,  6.03s/it] 74%|███████▍  | 1481/2001 [2:28:16<52:02,  6.01s/it] 74%|███████▍  | 1482/2001 [2:28:22<52:05,  6.02s/it] 74%|███████▍  | 1483/2001 [2:28:28<51:53,  6.01s/it] 74%|███████▍  | 1484/2001 [2:28:34<51:38,  5.99s/it] 74%|███████▍  | 1485/2001 [2:28:40<51:18,  5.97s/it] 74%|███████▍  | 1486/2001 [2:28:46<51:08,  5.96s/it] 74%|███████▍  | 1487/2001 [2:28:52<51:03,  5.96s/it] 74%|███████▍  | 1488/2001 [2:28:58<51:08,  5.98s/it] 74%|███████▍  | 1489/2001 [2:29:04<51:36,  6.05s/it] 74%|███████▍  | 1490/2001 [2:29:10<51:22,  6.03s/it] 75%|███████▍  | 1491/2001 [2:29:16<51:05,  6.01s/it] 75%|███████▍  | 1492/2001 [2:29:22<50:52,  6.00s/it] 75%|███████▍  | 1493/2001 [2:29:28<50:42,  5.99s/it] 75%|███████▍  | 1494/2001 [2:29:34<50:42,  6.00s/it] 75%|███████▍  | 1495/2001 [2:29:40<50:27,  5.98s/it] 75%|███████▍  | 1496/2001 [2:29:46<50:15,  5.97s/it] 75%|███████▍  | 1497/2001 [2:29:52<50:08,  5.97s/it] 75%|███████▍  | 1498/2001 [2:29:58<49:57,  5.96s/it] 75%|███████▍  | 1499/2001 [2:30:04<50:01,  5.98s/it] 75%|███████▍  | 1500/2001 [2:30:10<49:48,  5.97s/it] 75%|███████▌  | 1501/2001 [2:30:15<49:27,  5.93s/it] 75%|███████▌  | 1502/2001 [2:30:21<49:04,  5.90s/it] 75%|███████▌  | 1503/2001 [2:30:27<49:03,  5.91s/it] 75%|███████▌  | 1504/2001 [2:30:33<48:55,  5.91s/it] 75%|███████▌  | 1505/2001 [2:30:39<48:54,  5.92s/it] 75%|███████▌  | 1506/2001 [2:30:45<48:55,  5.93s/it] 75%|███████▌  | 1507/2001 [2:30:51<48:55,  5.94s/it] 75%|███████▌  | 1508/2001 [2:30:57<48:56,  5.96s/it] 75%|███████▌  | 1509/2001 [2:31:03<48:49,  5.95s/it] 75%|███████▌  | 1510/2001 [2:31:09<48:47,  5.96s/it] 76%|███████▌  | 1511/2001 [2:31:15<48:45,  5.97s/it] 76%|███████▌  | 1512/2001 [2:31:21<48:39,  5.97s/it] 76%|███████▌  | 1513/2001 [2:31:27<48:27,  5.96s/it] 76%|███████▌  | 1514/2001 [2:31:33<48:19,  5.95s/it] 76%|███████▌  | 1515/2001 [2:31:39<48:02,  5.93s/it] 76%|███████▌  | 1516/2001 [2:31:44<47:46,  5.91s/it] 76%|███████▌  | 1517/2001 [2:31:50<47:55,  5.94s/it] 76%|███████▌  | 1518/2001 [2:31:56<47:42,  5.93s/it] 76%|███████▌  | 1519/2001 [2:32:02<47:33,  5.92s/it] 76%|███████▌  | 1520/2001 [2:32:08<47:33,  5.93s/it] 76%|███████▌  | 1521/2001 [2:32:14<47:31,  5.94s/it] 76%|███████▌  | 1522/2001 [2:32:20<47:19,  5.93s/it] 76%|███████▌  | 1523/2001 [2:32:26<47:15,  5.93s/it] 76%|███████▌  | 1524/2001 [2:32:32<47:15,  5.94s/it] 76%|███████▌  | 1525/2001 [2:32:38<47:27,  5.98s/it] 76%|███████▋  | 1526/2001 [2:32:44<47:08,  5.96s/it] 76%|███████▋  | 1527/2001 [2:32:50<47:07,  5.96s/it] 76%|███████▋  | 1528/2001 [2:32:56<46:55,  5.95s/it] 76%|███████▋  | 1529/2001 [2:33:02<46:45,  5.94s/it] 76%|███████▋  | 1530/2001 [2:33:08<46:42,  5.95s/it] 77%|███████▋  | 1531/2001 [2:33:14<46:53,  5.99s/it] 77%|███████▋  | 1532/2001 [2:33:20<46:56,  6.00s/it] 77%|███████▋  | 1533/2001 [2:33:26<46:40,  5.98s/it] 77%|███████▋  | 1534/2001 [2:33:32<46:23,  5.96s/it] 77%|███████▋  | 1535/2001 [2:33:38<46:18,  5.96s/it] 77%|███████▋  | 1536/2001 [2:33:44<46:14,  5.97s/it] 77%|███████▋  | 1537/2001 [2:33:50<46:16,  5.98s/it] 77%|███████▋  | 1538/2001 [2:33:56<46:09,  5.98s/it] 77%|███████▋  | 1539/2001 [2:34:02<46:03,  5.98s/it] 77%|███████▋  | 1540/2001 [2:34:08<45:59,  5.98s/it] 77%|███████▋  | 1541/2001 [2:34:13<45:40,  5.96s/it] 77%|███████▋  | 1542/2001 [2:34:19<45:33,  5.96s/it] 77%|███████▋  | 1543/2001 [2:34:25<45:23,  5.95s/it]tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5353, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5385, grad_fn=<BinaryCrossEntropyBackward0>)
{'train_auc': 0.8933979412221901, 'train_f1': 0.8986055718901924, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 1419, 'train_macro_f1': 0.89213382318234, 'train_micro_f1': 0.8925221147911953, 'val_auc': 0.857603979533772, 'val_f1': 0.8685208596713022, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 1419, 'val_macro_f1': 0.8562994103453963, 'val_micro_f1': 0.8573388203017831, 'test_auc': 0.8532558725360538, 'test_f1': 0.8598115112756648, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 1419, 'test_macro_f1': 0.8525037857437606, 'test_micro_f1': 0.8528658482734258}
loss tensor(0.5390, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5438, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5403, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5364, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5372, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5396, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5363, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5385, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5416, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5457, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5448, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5337, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5323, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5354, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5327, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5339, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5370, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5312, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5371, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5388, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5395, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5357, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5379, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5356, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5389, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5405, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5337, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5339, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5466, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5349, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5382, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5350, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5333, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5297, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5361, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5356, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5388, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5315, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5444, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5309, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5428, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5321, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5356, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5365, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5443, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5340, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5309, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5374, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5319, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5373, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5366, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5308, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5356, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5419, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5376, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5450, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5423, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5332, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5443, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5451, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5367, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5410, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5388, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5417, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5403, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5314, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5408, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5407, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5346, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5339, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5320, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5328, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5326, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5292, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5314, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5293, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5306, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5283, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5350, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5286, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5318, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5344, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5237, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)
 77%|███████▋  | 1544/2001 [2:34:31<45:36,  5.99s/it] 77%|███████▋  | 1545/2001 [2:34:37<44:48,  5.90s/it] 77%|███████▋  | 1546/2001 [2:34:43<44:13,  5.83s/it] 77%|███████▋  | 1547/2001 [2:34:49<43:55,  5.81s/it] 77%|███████▋  | 1548/2001 [2:34:54<44:01,  5.83s/it] 77%|███████▋  | 1549/2001 [2:35:00<44:09,  5.86s/it] 77%|███████▋  | 1550/2001 [2:35:06<44:13,  5.88s/it] 78%|███████▊  | 1551/2001 [2:35:12<44:12,  5.90s/it] 78%|███████▊  | 1552/2001 [2:35:18<44:07,  5.90s/it] 78%|███████▊  | 1553/2001 [2:35:24<44:08,  5.91s/it] 78%|███████▊  | 1554/2001 [2:35:30<44:30,  5.97s/it] 78%|███████▊  | 1555/2001 [2:35:36<44:07,  5.93s/it] 78%|███████▊  | 1556/2001 [2:35:42<44:05,  5.94s/it] 78%|███████▊  | 1557/2001 [2:35:48<44:05,  5.96s/it] 78%|███████▊  | 1558/2001 [2:35:54<43:49,  5.94s/it] 78%|███████▊  | 1559/2001 [2:36:00<43:43,  5.94s/it] 78%|███████▊  | 1560/2001 [2:36:06<44:00,  5.99s/it] 78%|███████▊  | 1561/2001 [2:36:12<43:57,  5.99s/it] 78%|███████▊  | 1562/2001 [2:36:18<43:42,  5.97s/it] 78%|███████▊  | 1563/2001 [2:36:24<43:29,  5.96s/it] 78%|███████▊  | 1564/2001 [2:36:30<43:17,  5.94s/it] 78%|███████▊  | 1565/2001 [2:36:36<43:30,  5.99s/it] 78%|███████▊  | 1566/2001 [2:36:42<43:15,  5.97s/it] 78%|███████▊  | 1567/2001 [2:36:48<42:57,  5.94s/it] 78%|███████▊  | 1568/2001 [2:36:53<42:43,  5.92s/it] 78%|███████▊  | 1569/2001 [2:36:59<42:47,  5.94s/it] 78%|███████▊  | 1570/2001 [2:37:05<42:36,  5.93s/it] 79%|███████▊  | 1571/2001 [2:37:11<42:29,  5.93s/it] 79%|███████▊  | 1572/2001 [2:37:17<42:06,  5.89s/it] 79%|███████▊  | 1573/2001 [2:37:23<41:56,  5.88s/it] 79%|███████▊  | 1574/2001 [2:37:29<41:55,  5.89s/it] 79%|███████▊  | 1575/2001 [2:37:35<41:48,  5.89s/it] 79%|███████▉  | 1576/2001 [2:37:41<41:47,  5.90s/it] 79%|███████▉  | 1577/2001 [2:37:47<41:48,  5.92s/it] 79%|███████▉  | 1578/2001 [2:37:53<41:45,  5.92s/it] 79%|███████▉  | 1579/2001 [2:37:59<41:41,  5.93s/it] 79%|███████▉  | 1580/2001 [2:38:04<41:32,  5.92s/it] 79%|███████▉  | 1581/2001 [2:38:11<41:57,  6.00s/it] 79%|███████▉  | 1582/2001 [2:38:17<41:49,  5.99s/it] 79%|███████▉  | 1583/2001 [2:38:22<41:37,  5.98s/it] 79%|███████▉  | 1584/2001 [2:38:28<41:29,  5.97s/it] 79%|███████▉  | 1585/2001 [2:38:34<41:23,  5.97s/it] 79%|███████▉  | 1586/2001 [2:38:40<41:12,  5.96s/it] 79%|███████▉  | 1587/2001 [2:38:46<41:03,  5.95s/it] 79%|███████▉  | 1588/2001 [2:38:52<41:02,  5.96s/it] 79%|███████▉  | 1589/2001 [2:38:58<41:02,  5.98s/it] 79%|███████▉  | 1590/2001 [2:39:04<41:06,  6.00s/it] 80%|███████▉  | 1591/2001 [2:39:10<41:02,  6.01s/it] 80%|███████▉  | 1592/2001 [2:39:16<41:02,  6.02s/it] 80%|███████▉  | 1593/2001 [2:39:23<42:42,  6.28s/it] 80%|███████▉  | 1594/2001 [2:39:30<44:24,  6.55s/it] 80%|███████▉  | 1595/2001 [2:39:37<43:37,  6.45s/it] 80%|███████▉  | 1596/2001 [2:39:43<42:24,  6.28s/it] 80%|███████▉  | 1597/2001 [2:39:49<41:34,  6.17s/it] 80%|███████▉  | 1598/2001 [2:39:54<40:59,  6.10s/it] 80%|███████▉  | 1599/2001 [2:40:00<40:29,  6.04s/it] 80%|███████▉  | 1600/2001 [2:40:06<40:08,  6.01s/it] 80%|████████  | 1601/2001 [2:40:12<39:55,  5.99s/it] 80%|████████  | 1602/2001 [2:40:18<39:33,  5.95s/it] 80%|████████  | 1603/2001 [2:40:24<39:33,  5.96s/it] 80%|████████  | 1604/2001 [2:40:30<39:33,  5.98s/it] 80%|████████  | 1605/2001 [2:40:36<39:33,  5.99s/it] 80%|████████  | 1606/2001 [2:40:42<39:25,  5.99s/it] 80%|████████  | 1607/2001 [2:40:48<39:25,  6.00s/it] 80%|████████  | 1608/2001 [2:40:54<39:17,  6.00s/it] 80%|████████  | 1609/2001 [2:41:00<39:07,  5.99s/it] 80%|████████  | 1610/2001 [2:41:06<38:58,  5.98s/it] 81%|████████  | 1611/2001 [2:41:12<38:47,  5.97s/it] 81%|████████  | 1612/2001 [2:41:18<38:59,  6.01s/it] 81%|████████  | 1613/2001 [2:41:24<38:54,  6.02s/it] 81%|████████  | 1614/2001 [2:41:30<38:43,  6.00s/it] 81%|████████  | 1615/2001 [2:41:36<38:30,  5.99s/it] 81%|████████  | 1616/2001 [2:41:42<38:29,  6.00s/it] 81%|████████  | 1617/2001 [2:41:48<38:15,  5.98s/it] 81%|████████  | 1618/2001 [2:41:54<38:02,  5.96s/it] 81%|████████  | 1619/2001 [2:42:00<37:37,  5.91s/it] 81%|████████  | 1620/2001 [2:42:06<37:48,  5.95s/it] 81%|████████  | 1621/2001 [2:42:12<37:36,  5.94s/it] 81%|████████  | 1622/2001 [2:42:18<37:44,  5.97s/it] 81%|████████  | 1623/2001 [2:42:24<37:45,  5.99s/it] 81%|████████  | 1624/2001 [2:42:30<37:41,  6.00s/it] 81%|████████  | 1625/2001 [2:42:36<37:46,  6.03s/it] 81%|████████▏ | 1626/2001 [2:42:42<38:02,  6.09s/it] 81%|████████▏ | 1627/2001 [2:42:48<37:36,  6.03s/it] 81%|████████▏ | 1628/2001 [2:42:54<37:23,  6.01s/it] 81%|████████▏ | 1629/2001 [2:43:00<37:08,  5.99s/it] 81%|████████▏ | 1630/2001 [2:43:06<37:04,  6.00s/it] 82%|████████▏ | 1631/2001 [2:43:12<36:56,  5.99s/it] 82%|████████▏ | 1632/2001 [2:43:18<36:45,  5.98s/it] 82%|████████▏ | 1633/2001 [2:43:24<36:37,  5.97s/it] 82%|████████▏ | 1634/2001 [2:43:30<36:30,  5.97s/it] 82%|████████▏ | 1635/2001 [2:43:36<36:28,  5.98s/it] 82%|████████▏ | 1636/2001 [2:43:42<36:16,  5.96s/it] 82%|████████▏ | 1637/2001 [2:43:48<36:14,  5.97s/it] 82%|████████▏ | 1638/2001 [2:43:54<36:04,  5.96s/it] 82%|████████▏ | 1639/2001 [2:44:00<35:53,  5.95s/it] 82%|████████▏ | 1640/2001 [2:44:06<35:50,  5.96s/it] 82%|████████▏ | 1641/2001 [2:44:11<35:43,  5.95s/it] 82%|████████▏ | 1642/2001 [2:44:17<35:37,  5.95s/it] 82%|████████▏ | 1643/2001 [2:44:23<35:32,  5.96s/it] 82%|████████▏ | 1644/2001 [2:44:29<35:26,  5.96s/it] 82%|████████▏ | 1645/2001 [2:44:35<35:23,  5.97s/it] 82%|████████▏ | 1646/2001 [2:44:41<35:18,  5.97s/it] 82%|████████▏ | 1647/2001 [2:44:47<35:07,  5.95s/it] 82%|████████▏ | 1648/2001 [2:44:53<34:57,  5.94s/it] 82%|████████▏ | 1649/2001 [2:44:59<34:49,  5.94s/it] 82%|████████▏ | 1650/2001 [2:45:05<34:41,  5.93s/it] 83%|████████▎ | 1651/2001 [2:45:11<34:34,  5.93s/it] 83%|████████▎ | 1652/2001 [2:45:17<34:30,  5.93s/it] 83%|████████▎ | 1653/2001 [2:45:23<34:53,  6.02s/it] 83%|████████▎ | 1654/2001 [2:45:29<34:37,  5.99s/it] 83%|████████▎ | 1655/2001 [2:45:35<34:23,  5.96s/it] 83%|████████▎ | 1656/2001 [2:45:41<34:14,  5.96s/it] 83%|████████▎ | 1657/2001 [2:45:47<34:11,  5.96s/it] 83%|████████▎ | 1658/2001 [2:45:53<34:10,  5.98s/it] 83%|████████▎ | 1659/2001 [2:45:59<34:06,  5.98s/it] 83%|████████▎ | 1660/2001 [2:46:05<34:00,  5.98s/it] 83%|████████▎ | 1661/2001 [2:46:11<33:53,  5.98s/it] 83%|████████▎ | 1662/2001 [2:46:17<33:48,  5.98s/it] 83%|████████▎ | 1663/2001 [2:46:23<33:49,  6.00s/it] 83%|████████▎ | 1664/2001 [2:46:29<33:47,  6.02s/it] 83%|████████▎ | 1665/2001 [2:46:35<33:33,  5.99s/it] 83%|████████▎ | 1666/2001 [2:46:41<33:23,  5.98s/it] 83%|████████▎ | 1667/2001 [2:46:47<33:26,  6.01s/it] 83%|████████▎ | 1668/2001 [2:46:53<32:57,  5.94s/it] 83%|████████▎ | 1669/2001 [2:46:58<32:43,  5.91s/it] 83%|████████▎ | 1670/2001 [2:47:04<32:41,  5.92s/it] 84%|████████▎ | 1671/2001 [2:47:10<32:41,  5.94s/it] 84%|████████▎ | 1672/2001 [2:47:16<32:33,  5.94s/it] 84%|████████▎ | 1673/2001 [2:47:22<32:21,  5.92s/it] 84%|████████▎ | 1674/2001 [2:47:28<32:15,  5.92s/it]loss tensor(0.5280, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5304, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5350, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5289, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5293, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5269, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5341, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5256, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5279, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5274, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5325, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5317, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5236, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5241, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5234, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5267, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5288, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5299, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5295, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5283, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5304, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5258, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5271, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5317, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5231, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5269, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5290, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5290, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5296, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5310, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5264, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5272, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5224, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5272, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5216, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5307, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5292, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5273, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5280, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5270, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5280, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5237, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5287, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5260, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5217, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5245, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5261, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5220, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5227, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5217, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5218, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5161, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5201, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5282, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5249, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5220, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5248, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5203, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5180, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5153, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5194, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5192, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5183, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5250, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5207, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5191, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5170, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5154, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5200, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5216, grad_fn=<BinaryCrossEntropyBackward0>)
 84%|████████▎ | 1675/2001 [2:47:34<32:08,  5.92s/it] 84%|████████▍ | 1676/2001 [2:47:40<32:02,  5.92s/it] 84%|████████▍ | 1677/2001 [2:47:46<32:03,  5.94s/it] 84%|████████▍ | 1678/2001 [2:47:52<32:06,  5.96s/it] 84%|████████▍ | 1679/2001 [2:47:58<31:59,  5.96s/it] 84%|████████▍ | 1680/2001 [2:48:04<31:48,  5.95s/it] 84%|████████▍ | 1681/2001 [2:48:10<31:39,  5.94s/it] 84%|████████▍ | 1682/2001 [2:48:16<31:41,  5.96s/it] 84%|████████▍ | 1683/2001 [2:48:22<31:42,  5.98s/it] 84%|████████▍ | 1684/2001 [2:48:28<31:31,  5.97s/it] 84%|████████▍ | 1685/2001 [2:48:34<31:26,  5.97s/it] 84%|████████▍ | 1686/2001 [2:48:40<31:14,  5.95s/it] 84%|████████▍ | 1687/2001 [2:48:46<31:08,  5.95s/it] 84%|████████▍ | 1688/2001 [2:48:51<30:56,  5.93s/it] 84%|████████▍ | 1689/2001 [2:48:57<30:56,  5.95s/it] 84%|████████▍ | 1690/2001 [2:49:03<30:47,  5.94s/it] 85%|████████▍ | 1691/2001 [2:49:09<30:40,  5.94s/it] 85%|████████▍ | 1692/2001 [2:49:15<30:34,  5.94s/it] 85%|████████▍ | 1693/2001 [2:49:21<30:36,  5.96s/it] 85%|████████▍ | 1694/2001 [2:49:27<30:24,  5.94s/it] 85%|████████▍ | 1695/2001 [2:49:33<30:12,  5.92s/it] 85%|████████▍ | 1696/2001 [2:49:39<30:06,  5.92s/it] 85%|████████▍ | 1697/2001 [2:49:45<30:08,  5.95s/it] 85%|████████▍ | 1698/2001 [2:49:51<30:16,  5.99s/it] 85%|████████▍ | 1699/2001 [2:49:57<30:10,  5.99s/it] 85%|████████▍ | 1700/2001 [2:50:03<29:56,  5.97s/it] 85%|████████▌ | 1701/2001 [2:50:09<29:43,  5.95s/it] 85%|████████▌ | 1702/2001 [2:50:15<30:05,  6.04s/it] 85%|████████▌ | 1703/2001 [2:50:22<31:30,  6.35s/it] 85%|████████▌ | 1704/2001 [2:50:28<31:10,  6.30s/it] 85%|████████▌ | 1705/2001 [2:50:34<30:31,  6.19s/it] 85%|████████▌ | 1706/2001 [2:50:40<29:59,  6.10s/it] 85%|████████▌ | 1707/2001 [2:50:46<30:02,  6.13s/it] 85%|████████▌ | 1708/2001 [2:50:52<29:39,  6.07s/it] 85%|████████▌ | 1709/2001 [2:50:58<29:20,  6.03s/it] 85%|████████▌ | 1710/2001 [2:51:04<29:05,  6.00s/it] 86%|████████▌ | 1711/2001 [2:51:10<28:55,  5.99s/it] 86%|████████▌ | 1712/2001 [2:51:16<28:51,  5.99s/it] 86%|████████▌ | 1713/2001 [2:51:22<28:41,  5.98s/it] 86%|████████▌ | 1714/2001 [2:51:28<28:34,  5.97s/it] 86%|████████▌ | 1715/2001 [2:51:34<28:17,  5.94s/it] 86%|████████▌ | 1716/2001 [2:51:40<27:57,  5.89s/it] 86%|████████▌ | 1717/2001 [2:51:46<27:57,  5.91s/it] 86%|████████▌ | 1718/2001 [2:51:52<28:01,  5.94s/it] 86%|████████▌ | 1719/2001 [2:51:58<27:54,  5.94s/it] 86%|████████▌ | 1720/2001 [2:52:03<27:44,  5.92s/it] 86%|████████▌ | 1721/2001 [2:52:09<27:40,  5.93s/it] 86%|████████▌ | 1722/2001 [2:52:15<27:42,  5.96s/it] 86%|████████▌ | 1723/2001 [2:52:21<27:35,  5.95s/it] 86%|████████▌ | 1724/2001 [2:52:27<27:28,  5.95s/it] 86%|████████▌ | 1725/2001 [2:52:33<27:26,  5.97s/it] 86%|████████▋ | 1726/2001 [2:52:39<27:10,  5.93s/it] 86%|████████▋ | 1727/2001 [2:52:45<27:09,  5.95s/it] 86%|████████▋ | 1728/2001 [2:52:51<27:09,  5.97s/it] 86%|████████▋ | 1729/2001 [2:52:57<27:01,  5.96s/it] 86%|████████▋ | 1730/2001 [2:53:03<27:01,  5.98s/it] 87%|████████▋ | 1731/2001 [2:53:09<26:53,  5.98s/it] 87%|████████▋ | 1732/2001 [2:53:15<26:50,  5.99s/it] 87%|████████▋ | 1733/2001 [2:53:21<26:50,  6.01s/it] 87%|████████▋ | 1734/2001 [2:53:27<27:03,  6.08s/it] 87%|████████▋ | 1735/2001 [2:53:34<27:01,  6.10s/it] 87%|████████▋ | 1736/2001 [2:53:40<26:48,  6.07s/it] 87%|████████▋ | 1737/2001 [2:53:45<26:27,  6.01s/it] 87%|████████▋ | 1738/2001 [2:53:51<26:13,  5.98s/it] 87%|████████▋ | 1739/2001 [2:53:57<26:08,  5.99s/it] 87%|████████▋ | 1740/2001 [2:54:03<26:13,  6.03s/it] 87%|████████▋ | 1741/2001 [2:54:10<26:13,  6.05s/it] 87%|████████▋ | 1742/2001 [2:54:16<26:03,  6.04s/it] 87%|████████▋ | 1743/2001 [2:54:22<25:49,  6.01s/it] 87%|████████▋ | 1744/2001 [2:54:27<25:35,  5.97s/it] 87%|████████▋ | 1745/2001 [2:54:33<25:30,  5.98s/it] 87%|████████▋ | 1746/2001 [2:54:40<25:44,  6.06s/it] 87%|████████▋ | 1747/2001 [2:54:46<26:02,  6.15s/it] 87%|████████▋ | 1748/2001 [2:54:52<25:50,  6.13s/it] 87%|████████▋ | 1749/2001 [2:54:58<25:32,  6.08s/it] 87%|████████▋ | 1750/2001 [2:55:04<25:23,  6.07s/it] 88%|████████▊ | 1751/2001 [2:55:10<25:30,  6.12s/it] 88%|████████▊ | 1752/2001 [2:55:16<25:19,  6.10s/it] 88%|████████▊ | 1753/2001 [2:55:22<25:09,  6.09s/it] 88%|████████▊ | 1754/2001 [2:55:28<24:52,  6.04s/it] 88%|████████▊ | 1755/2001 [2:55:34<24:43,  6.03s/it] 88%|████████▊ | 1756/2001 [2:55:40<24:34,  6.02s/it] 88%|████████▊ | 1757/2001 [2:55:46<24:25,  6.01s/it] 88%|████████▊ | 1758/2001 [2:55:52<24:16,  6.00s/it] 88%|████████▊ | 1759/2001 [2:55:58<23:59,  5.95s/it] 88%|████████▊ | 1760/2001 [2:56:04<23:51,  5.94s/it] 88%|████████▊ | 1761/2001 [2:56:10<23:52,  5.97s/it] 88%|████████▊ | 1762/2001 [2:56:16<23:47,  5.97s/it] 88%|████████▊ | 1763/2001 [2:56:22<23:42,  5.98s/it] 88%|████████▊ | 1764/2001 [2:56:28<23:45,  6.01s/it] 88%|████████▊ | 1765/2001 [2:56:34<23:38,  6.01s/it] 88%|████████▊ | 1766/2001 [2:56:40<23:27,  5.99s/it] 88%|████████▊ | 1767/2001 [2:56:46<23:24,  6.00s/it] 88%|████████▊ | 1768/2001 [2:56:52<23:15,  5.99s/it] 88%|████████▊ | 1769/2001 [2:56:58<23:09,  5.99s/it] 88%|████████▊ | 1770/2001 [2:57:04<23:04,  5.99s/it] 89%|████████▊ | 1771/2001 [2:57:10<22:56,  5.98s/it] 89%|████████▊ | 1772/2001 [2:57:16<22:50,  5.98s/it] 89%|████████▊ | 1773/2001 [2:57:22<22:45,  5.99s/it] 89%|████████▊ | 1774/2001 [2:57:28<22:37,  5.98s/it] 89%|████████▊ | 1775/2001 [2:57:34<22:24,  5.95s/it] 89%|████████▉ | 1776/2001 [2:57:40<22:00,  5.87s/it] 89%|████████▉ | 1777/2001 [2:57:46<21:59,  5.89s/it] 89%|████████▉ | 1778/2001 [2:57:52<22:00,  5.92s/it] 89%|████████▉ | 1779/2001 [2:57:58<22:04,  5.97s/it] 89%|████████▉ | 1780/2001 [2:58:04<21:59,  5.97s/it] 89%|████████▉ | 1781/2001 [2:58:09<21:48,  5.95s/it] 89%|████████▉ | 1782/2001 [2:58:15<21:48,  5.97s/it] 89%|████████▉ | 1783/2001 [2:58:22<21:44,  5.99s/it] 89%|████████▉ | 1784/2001 [2:58:28<21:41,  6.00s/it] 89%|████████▉ | 1785/2001 [2:58:34<21:35,  6.00s/it] 89%|████████▉ | 1786/2001 [2:58:40<21:27,  5.99s/it] 89%|████████▉ | 1787/2001 [2:58:45<21:06,  5.92s/it] 89%|████████▉ | 1788/2001 [2:58:51<20:59,  5.91s/it] 89%|████████▉ | 1789/2001 [2:58:57<20:56,  5.93s/it] 89%|████████▉ | 1790/2001 [2:59:03<20:52,  5.94s/it] 90%|████████▉ | 1791/2001 [2:59:09<20:54,  5.97s/it] 90%|████████▉ | 1792/2001 [2:59:15<20:49,  5.98s/it] 90%|████████▉ | 1793/2001 [2:59:21<20:43,  5.98s/it] 90%|████████▉ | 1794/2001 [2:59:27<20:35,  5.97s/it] 90%|████████▉ | 1795/2001 [2:59:33<20:24,  5.94s/it] 90%|████████▉ | 1796/2001 [2:59:39<20:18,  5.94s/it] 90%|████████▉ | 1797/2001 [2:59:45<20:22,  5.99s/it] 90%|████████▉ | 1798/2001 [2:59:51<20:14,  5.99s/it] 90%|████████▉ | 1799/2001 [2:59:57<20:04,  5.96s/it] 90%|████████▉ | 1800/2001 [3:00:03<20:08,  6.01s/it] 90%|█████████ | 1801/2001 [3:00:09<20:06,  6.03s/it] 90%|█████████ | 1802/2001 [3:00:15<20:01,  6.04s/it] 90%|█████████ | 1803/2001 [3:00:21<19:48,  6.00s/it]{'train_auc': 0.9018452144123833, 'train_f1': 0.9091638795986621, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 1675, 'train_macro_f1': 0.9016473145626677, 'train_micro_f1': 0.9022217650689158, 'val_auc': 0.8576152699015906, 'val_f1': 0.8724164724164725, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 1675, 'val_macro_f1': 0.8577037420410915, 'val_micro_f1': 0.8592249657064474, 'test_auc': 0.8485704389445179, 'test_f1': 0.8579975072704612, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 1675, 'test_macro_f1': 0.8484691145814185, 'test_micro_f1': 0.8490682681268216}
loss tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5230, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5185, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5158, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5214, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5147, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5135, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5235, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5210, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5197, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5196, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5174, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5151, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5176, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5166, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5172, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5155, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5202, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5162, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5195, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5213, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5178, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5222, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5204, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5206, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5208, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5242, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5184, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5156, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5216, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5179, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5169, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5179, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5241, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5181, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5226, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5238, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5262, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5240, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5313, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5212, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5219, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5179, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5285, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5227, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5209, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5190, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5128, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5144, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5188, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5207, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5136, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5157, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5178, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5175, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5244, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5177, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5210, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5223, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5175, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5215, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5198, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5106, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5120, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5127, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5142, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5119, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5124, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5142, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5058, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5108, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5122, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5133, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5073, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5178, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5106, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5142, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5104, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5122, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5152, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5119, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5102, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5166, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5135, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5122, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5135, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)
loss  90%|█████████ | 1804/2001 [3:00:27<19:36,  5.97s/it] 90%|█████████ | 1805/2001 [3:00:33<19:29,  5.97s/it] 90%|█████████ | 1806/2001 [3:00:39<19:19,  5.94s/it] 90%|█████████ | 1807/2001 [3:00:45<19:15,  5.96s/it] 90%|█████████ | 1808/2001 [3:00:51<19:11,  5.97s/it] 90%|█████████ | 1809/2001 [3:00:57<19:07,  5.98s/it] 90%|█████████ | 1810/2001 [3:01:03<18:58,  5.96s/it] 91%|█████████ | 1811/2001 [3:01:09<18:55,  5.97s/it] 91%|█████████ | 1812/2001 [3:01:15<18:50,  5.98s/it] 91%|█████████ | 1813/2001 [3:01:21<18:44,  5.98s/it] 91%|█████████ | 1814/2001 [3:01:27<18:36,  5.97s/it] 91%|█████████ | 1815/2001 [3:01:33<18:26,  5.95s/it] 91%|█████████ | 1816/2001 [3:01:38<18:20,  5.95s/it] 91%|█████████ | 1817/2001 [3:01:44<18:15,  5.95s/it] 91%|█████████ | 1818/2001 [3:01:50<18:08,  5.95s/it] 91%|█████████ | 1819/2001 [3:01:56<18:07,  5.98s/it] 91%|█████████ | 1820/2001 [3:02:02<18:03,  5.99s/it] 91%|█████████ | 1821/2001 [3:02:08<17:50,  5.95s/it] 91%|█████████ | 1822/2001 [3:02:14<17:44,  5.95s/it] 91%|█████████ | 1823/2001 [3:02:20<17:38,  5.94s/it] 91%|█████████ | 1824/2001 [3:02:26<17:31,  5.94s/it] 91%|█████████ | 1825/2001 [3:02:32<17:25,  5.94s/it] 91%|█████████▏| 1826/2001 [3:02:38<17:18,  5.93s/it] 91%|█████████▏| 1827/2001 [3:02:44<17:14,  5.95s/it] 91%|█████████▏| 1828/2001 [3:02:50<17:13,  5.97s/it] 91%|█████████▏| 1829/2001 [3:02:56<17:07,  5.97s/it] 91%|█████████▏| 1830/2001 [3:03:02<17:01,  5.97s/it] 92%|█████████▏| 1831/2001 [3:03:08<16:53,  5.96s/it] 92%|█████████▏| 1832/2001 [3:03:14<16:47,  5.96s/it] 92%|█████████▏| 1833/2001 [3:03:20<16:41,  5.96s/it] 92%|█████████▏| 1834/2001 [3:03:26<16:35,  5.96s/it] 92%|█████████▏| 1835/2001 [3:03:32<16:28,  5.95s/it] 92%|█████████▏| 1836/2001 [3:03:38<16:23,  5.96s/it] 92%|█████████▏| 1837/2001 [3:03:44<16:18,  5.97s/it] 92%|█████████▏| 1838/2001 [3:03:50<16:14,  5.98s/it] 92%|█████████▏| 1839/2001 [3:03:56<16:09,  5.98s/it] 92%|█████████▏| 1840/2001 [3:04:02<16:03,  5.98s/it] 92%|█████████▏| 1841/2001 [3:04:08<15:59,  6.00s/it] 92%|█████████▏| 1842/2001 [3:04:14<15:53,  5.99s/it] 92%|█████████▏| 1843/2001 [3:04:19<15:41,  5.96s/it] 92%|█████████▏| 1844/2001 [3:04:25<15:34,  5.95s/it] 92%|█████████▏| 1845/2001 [3:04:31<15:31,  5.97s/it] 92%|█████████▏| 1846/2001 [3:04:37<15:23,  5.96s/it] 92%|█████████▏| 1847/2001 [3:04:43<15:16,  5.95s/it] 92%|█████████▏| 1848/2001 [3:04:49<15:09,  5.94s/it] 92%|█████████▏| 1849/2001 [3:04:55<15:03,  5.94s/it] 92%|█████████▏| 1850/2001 [3:05:01<14:57,  5.94s/it] 93%|█████████▎| 1851/2001 [3:05:07<14:55,  5.97s/it] 93%|█████████▎| 1852/2001 [3:05:13<14:51,  5.99s/it] 93%|█████████▎| 1853/2001 [3:05:19<14:47,  5.99s/it] 93%|█████████▎| 1854/2001 [3:05:25<14:35,  5.95s/it] 93%|█████████▎| 1855/2001 [3:05:31<14:24,  5.92s/it] 93%|█████████▎| 1856/2001 [3:05:37<14:16,  5.91s/it] 93%|█████████▎| 1857/2001 [3:05:43<14:11,  5.91s/it] 93%|█████████▎| 1858/2001 [3:05:49<14:07,  5.93s/it] 93%|█████████▎| 1859/2001 [3:05:55<13:59,  5.91s/it] 93%|█████████▎| 1860/2001 [3:06:00<13:54,  5.92s/it] 93%|█████████▎| 1861/2001 [3:06:07<13:55,  5.97s/it] 93%|█████████▎| 1862/2001 [3:06:13<13:51,  5.98s/it] 93%|█████████▎| 1863/2001 [3:06:18<13:43,  5.96s/it] 93%|█████████▎| 1864/2001 [3:06:25<13:44,  6.01s/it] 93%|█████████▎| 1865/2001 [3:06:30<13:32,  5.98s/it] 93%|█████████▎| 1866/2001 [3:06:37<13:31,  6.01s/it] 93%|█████████▎| 1867/2001 [3:06:43<13:23,  5.99s/it] 93%|█████████▎| 1868/2001 [3:06:48<13:13,  5.97s/it] 93%|█████████▎| 1869/2001 [3:06:54<13:06,  5.96s/it] 93%|█████████▎| 1870/2001 [3:07:00<12:50,  5.88s/it] 94%|█████████▎| 1871/2001 [3:07:06<12:46,  5.90s/it] 94%|█████████▎| 1872/2001 [3:07:12<12:39,  5.89s/it] 94%|█████████▎| 1873/2001 [3:07:18<12:35,  5.90s/it] 94%|█████████▎| 1874/2001 [3:07:24<12:30,  5.91s/it] 94%|█████████▎| 1875/2001 [3:07:30<12:26,  5.92s/it] 94%|█████████▍| 1876/2001 [3:07:36<12:21,  5.93s/it] 94%|█████████▍| 1877/2001 [3:07:42<12:17,  5.95s/it] 94%|█████████▍| 1878/2001 [3:07:48<12:09,  5.93s/it] 94%|█████████▍| 1879/2001 [3:07:53<12:02,  5.92s/it] 94%|█████████▍| 1880/2001 [3:07:59<11:57,  5.93s/it] 94%|█████████▍| 1881/2001 [3:08:05<11:51,  5.93s/it] 94%|█████████▍| 1882/2001 [3:08:11<11:47,  5.94s/it] 94%|█████████▍| 1883/2001 [3:08:17<11:42,  5.96s/it] 94%|█████████▍| 1884/2001 [3:08:23<11:37,  5.96s/it] 94%|█████████▍| 1885/2001 [3:08:29<11:33,  5.98s/it] 94%|█████████▍| 1886/2001 [3:08:35<11:26,  5.97s/it] 94%|█████████▍| 1887/2001 [3:08:41<11:19,  5.96s/it] 94%|█████████▍| 1888/2001 [3:08:47<11:11,  5.94s/it] 94%|█████████▍| 1889/2001 [3:08:53<11:03,  5.92s/it] 94%|█████████▍| 1890/2001 [3:08:59<11:01,  5.96s/it] 95%|█████████▍| 1891/2001 [3:09:05<10:55,  5.96s/it] 95%|█████████▍| 1892/2001 [3:09:11<10:47,  5.94s/it] 95%|█████████▍| 1893/2001 [3:09:17<10:40,  5.93s/it] 95%|█████████▍| 1894/2001 [3:09:23<10:35,  5.94s/it] 95%|█████████▍| 1895/2001 [3:09:29<10:28,  5.93s/it] 95%|█████████▍| 1896/2001 [3:09:35<10:22,  5.93s/it] 95%|█████████▍| 1897/2001 [3:09:40<10:17,  5.94s/it] 95%|█████████▍| 1898/2001 [3:09:46<10:13,  5.96s/it] 95%|█████████▍| 1899/2001 [3:09:52<10:08,  5.96s/it] 95%|█████████▍| 1900/2001 [3:09:58<10:03,  5.98s/it] 95%|█████████▌| 1901/2001 [3:10:05<10:00,  6.01s/it] 95%|█████████▌| 1902/2001 [3:10:11<09:56,  6.02s/it] 95%|█████████▌| 1903/2001 [3:10:17<09:46,  5.98s/it] 95%|█████████▌| 1904/2001 [3:10:22<09:36,  5.94s/it] 95%|█████████▌| 1905/2001 [3:10:29<09:36,  6.01s/it] 95%|█████████▌| 1906/2001 [3:10:34<09:28,  5.98s/it] 95%|█████████▌| 1907/2001 [3:10:40<09:19,  5.95s/it] 95%|█████████▌| 1908/2001 [3:10:46<09:13,  5.95s/it] 95%|█████████▌| 1909/2001 [3:10:52<09:08,  5.96s/it] 95%|█████████▌| 1910/2001 [3:10:58<09:02,  5.96s/it] 96%|█████████▌| 1911/2001 [3:11:04<08:56,  5.96s/it] 96%|█████████▌| 1912/2001 [3:11:10<08:49,  5.95s/it] 96%|█████████▌| 1913/2001 [3:11:16<08:43,  5.95s/it] 96%|█████████▌| 1914/2001 [3:11:22<08:37,  5.95s/it] 96%|█████████▌| 1915/2001 [3:11:28<08:30,  5.94s/it] 96%|█████████▌| 1916/2001 [3:11:34<08:26,  5.95s/it] 96%|█████████▌| 1917/2001 [3:11:40<08:20,  5.96s/it] 96%|█████████▌| 1918/2001 [3:11:46<08:15,  5.97s/it] 96%|█████████▌| 1919/2001 [3:11:52<08:10,  5.98s/it] 96%|█████████▌| 1920/2001 [3:11:58<08:03,  5.97s/it] 96%|█████████▌| 1921/2001 [3:12:04<07:57,  5.97s/it] 96%|█████████▌| 1922/2001 [3:12:10<07:54,  6.00s/it] 96%|█████████▌| 1923/2001 [3:12:16<07:47,  6.00s/it] 96%|█████████▌| 1924/2001 [3:12:22<07:42,  6.00s/it] 96%|█████████▌| 1925/2001 [3:12:28<07:36,  6.01s/it] 96%|█████████▋| 1926/2001 [3:12:34<07:28,  5.99s/it] 96%|█████████▋| 1927/2001 [3:12:40<07:21,  5.96s/it] 96%|█████████▋| 1928/2001 [3:12:46<07:15,  5.96s/it] 96%|█████████▋| 1929/2001 [3:12:52<07:07,  5.94s/it] 96%|█████████▋| 1930/2001 [3:12:58<07:02,  5.94s/it] 97%|█████████▋| 1931/2001 [3:13:03<06:55,  5.94s/it] 97%|█████████▋| 1932/2001 [3:13:09<06:50,  5.95s/it] 97%|█████████▋| 1933/2001 [3:13:15<06:44,  5.95s/it] 97%|█████████▋| 1934/2001 [3:13:21<06:40,  5.98s/it] 97%|█████████▋| 1935/2001 [3:13:27<06:34,  5.98s/it] 97%|█████████▋| 1936/2001 [3:13:33<06:28,  5.98s/it] 97%|█████████▋| 1937/2001 [3:13:39<06:21,  5.97s/it] 97%|█████████▋| 1938/2001 [3:13:45<06:16,  5.97s/it] 97%|█████████▋| 1939/2001 [3:13:51<06:11,  5.99s/it] 97%|█████████▋| 1940/2001 [3:13:57<06:04,  5.97s/it] 97%|█████████▋| 1941/2001 [3:14:03<05:57,  5.96s/it]tensor(0.5068, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5119, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5108, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5093, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5143, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5054, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5058, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5063, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5064, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5105, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5060, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5070, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5075, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5059, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5145, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5133, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5129, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5067, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5088, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5092, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5098, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5097, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5075, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5107, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5096, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5068, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5072, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5123, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5031, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5083, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5054, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5089, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5090, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5109, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5070, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5070, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5057, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5044, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5039, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5101, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5144, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5166, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5124, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5122, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5192, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5120, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5150, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5144, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5101, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5178, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5167, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5132, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5166, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5105, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5111, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5114, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5187, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5105, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5082, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5112, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5110, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5081, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5108, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5082, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5093, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5053, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5034, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5055, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5027, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5062, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5069, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5061, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5117, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5064, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5039, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5048, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5077, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5074, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5017, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4974, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5015, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5038, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5000, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5018, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5041, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5005, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5047, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5059, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5012, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5007, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5065, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5021, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5068, grad_fn=<BinaryCrossEntropyBackward0>)
loss  97%|█████████▋| 1942/2001 [3:14:09<05:51,  5.97s/it] 97%|█████████▋| 1943/2001 [3:14:15<05:44,  5.94s/it] 97%|█████████▋| 1944/2001 [3:14:21<05:34,  5.87s/it] 97%|█████████▋| 1945/2001 [3:14:27<05:29,  5.88s/it] 97%|█████████▋| 1946/2001 [3:14:33<05:24,  5.90s/it] 97%|█████████▋| 1947/2001 [3:14:39<05:19,  5.91s/it] 97%|█████████▋| 1948/2001 [3:14:44<05:13,  5.92s/it] 97%|█████████▋| 1949/2001 [3:14:50<05:08,  5.93s/it] 97%|█████████▋| 1950/2001 [3:14:56<05:03,  5.95s/it] 98%|█████████▊| 1951/2001 [3:15:02<04:58,  5.97s/it] 98%|█████████▊| 1952/2001 [3:15:08<04:52,  5.96s/it] 98%|█████████▊| 1953/2001 [3:15:14<04:46,  5.97s/it] 98%|█████████▊| 1954/2001 [3:15:20<04:39,  5.96s/it] 98%|█████████▊| 1955/2001 [3:15:26<04:32,  5.92s/it] 98%|█████████▊| 1956/2001 [3:15:32<04:28,  5.96s/it] 98%|█████████▊| 1957/2001 [3:15:38<04:22,  5.96s/it] 98%|█████████▊| 1958/2001 [3:15:44<04:16,  5.97s/it] 98%|█████████▊| 1959/2001 [3:15:50<04:11,  5.98s/it] 98%|█████████▊| 1960/2001 [3:15:56<04:05,  5.98s/it] 98%|█████████▊| 1961/2001 [3:16:02<03:59,  5.99s/it] 98%|█████████▊| 1962/2001 [3:16:08<03:52,  5.97s/it] 98%|█████████▊| 1963/2001 [3:16:14<03:46,  5.95s/it] 98%|█████████▊| 1964/2001 [3:16:20<03:41,  5.98s/it] 98%|█████████▊| 1965/2001 [3:16:26<03:35,  5.98s/it] 98%|█████████▊| 1966/2001 [3:16:32<03:29,  5.98s/it] 98%|█████████▊| 1967/2001 [3:16:38<03:22,  5.96s/it] 98%|█████████▊| 1968/2001 [3:16:44<03:14,  5.91s/it] 98%|█████████▊| 1969/2001 [3:16:50<03:08,  5.90s/it] 98%|█████████▊| 1970/2001 [3:16:56<03:03,  5.91s/it] 99%|█████████▊| 1971/2001 [3:17:01<02:57,  5.91s/it] 99%|█████████▊| 1972/2001 [3:17:07<02:51,  5.91s/it] 99%|█████████▊| 1973/2001 [3:17:13<02:45,  5.91s/it] 99%|█████████▊| 1974/2001 [3:17:19<02:39,  5.92s/it] 99%|█████████▊| 1975/2001 [3:17:25<02:33,  5.91s/it] 99%|█████████▉| 1976/2001 [3:17:31<02:27,  5.92s/it] 99%|█████████▉| 1977/2001 [3:17:37<02:22,  5.92s/it] 99%|█████████▉| 1978/2001 [3:17:43<02:16,  5.93s/it] 99%|█████████▉| 1979/2001 [3:17:49<02:10,  5.92s/it] 99%|█████████▉| 1980/2001 [3:17:55<02:04,  5.91s/it] 99%|█████████▉| 1981/2001 [3:18:01<01:58,  5.91s/it] 99%|█████████▉| 1982/2001 [3:18:07<01:52,  5.93s/it] 99%|█████████▉| 1983/2001 [3:18:12<01:46,  5.89s/it] 99%|█████████▉| 1984/2001 [3:18:18<01:40,  5.91s/it] 99%|█████████▉| 1985/2001 [3:18:24<01:34,  5.88s/it] 99%|█████████▉| 1986/2001 [3:18:30<01:27,  5.86s/it] 99%|█████████▉| 1987/2001 [3:18:36<01:22,  5.87s/it] 99%|█████████▉| 1988/2001 [3:18:42<01:16,  5.88s/it] 99%|█████████▉| 1989/2001 [3:18:48<01:10,  5.90s/it] 99%|█████████▉| 1990/2001 [3:18:54<01:05,  5.92s/it]100%|█████████▉| 1991/2001 [3:19:00<00:59,  5.94s/it]100%|█████████▉| 1992/2001 [3:19:06<00:53,  5.95s/it]100%|█████████▉| 1993/2001 [3:19:12<00:47,  5.94s/it]100%|█████████▉| 1994/2001 [3:19:17<00:41,  5.92s/it]100%|█████████▉| 1995/2001 [3:19:23<00:35,  5.91s/it]100%|█████████▉| 1996/2001 [3:19:29<00:29,  5.91s/it]100%|█████████▉| 1997/2001 [3:19:35<00:23,  5.91s/it]100%|█████████▉| 1998/2001 [3:19:41<00:17,  5.90s/it]100%|█████████▉| 1999/2001 [3:19:47<00:11,  5.91s/it]100%|█████████▉| 2000/2001 [3:19:53<00:05,  5.95s/it]100%|██████████| 2001/2001 [3:19:59<00:00,  5.97s/it]100%|██████████| 2001/2001 [3:19:59<00:00,  6.00s/it]
tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5056, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5025, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5031, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5066, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4983, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5026, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5046, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5076, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5035, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5040, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5004, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4997, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5028, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4984, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5002, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5014, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5007, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4991, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4981, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5002, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4960, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4979, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5050, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5033, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4942, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5004, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5045, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5002, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5038, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4999, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5004, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5010, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4978, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4981, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4987, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4989, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4990, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4904, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4986, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5011, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4985, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4966, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5008, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5019, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5011, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5042, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.4974, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5025, grad_fn=<BinaryCrossEntropyBackward0>)
loss tensor(0.5022, grad_fn=<BinaryCrossEntropyBackward0>)
Done! Best Results:
{'train_auc': 0.9018452144123833, 'train_f1': 0.9091638795986621, 'train_pos_ratio': 0.5397449084550504, 'train_epoch': 1675, 'train_macro_f1': 0.9016473145626677, 'train_micro_f1': 0.9022217650689158, 'val_auc': 0.8576152699015906, 'val_f1': 0.8724164724164725, 'val_pos_ratio': 0.5510973936899863, 'val_epoch': 1675, 'val_macro_f1': 0.8577037420410915, 'val_micro_f1': 0.8592249657064474, 'test_auc': 0.8485704389445179, 'test_f1': 0.8579975072704612, 'test_pos_ratio': 0.5325443786982249, 'test_epoch': 1675, 'test_macro_f1': 0.8484691145814185, 'test_micro_f1': 0.8490682681268216}
test_auc 0.8485704389445179 test_f1 0.8579975072704612 test_macro_f1 0.8484691145814185 test_micro_f1 0.8490682681268216 